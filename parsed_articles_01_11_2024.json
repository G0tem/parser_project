{
    "Импортозамещение Data Quality стека в нефтегазохимии: опыт СИБУРа": "В СИБУРе много данных, которые текут в режиме реального времени с многочисленных датчиков на разных производствах, эти данные нужно собирать, хранить, обрабатывать и анализировать, чтобы компания могла принимать правильные бизнес-решения. И от качества инфраструктуры для работы с данными зависит рентабельность производств и прибыль компании в целом, а это жизненно важные показатели.В небольшом цикле из двух статей мы разберём опыт СИБУРа в создании, поддержке и развитии DQ (Data Quality — качество данных) сервиса для DWH (Data Warehouse — хранилище данных) в условиях санкций и исчезающих вендоров проверенных и привычных решений.Рассказывать об этом опыте будет Александр Бергер, Lead DQ Analyst в Цифровом СИБУРе, которому посчастливилось лидить процесс создания DQ-сервиса на решениях вендора, который решил покинуть рынок РФ в разгар рабочего процесса.Что такое Data Quality?Если вкратце, то DQ-сервис — это набор инструментов для проверки качества данных, поступающих в хранилище, передающихся между слоями хранилища или уже хранящихся в DWH.Качество данных необходимо проверять, чтобы понимать, можно тем или иным данным доверять или нет — это критично, потому что на основе этих данных принимаются управленческие решения и цена ошибки в этом процессе очень высока, особенно в промышленном секторе, ярким представителем которого и является компания СИБУР.В производственных процессах в СИБУРе повсеместно задействованы современные информационные технологии, и в наших производственных контурах постоянно генерируются данные — оборудование, датчики, всевозможные автоматизации, IoT — отправляют данные 24/7, которые нужно передавать, собирать, обрабатывать, хранить.СИБУРу важно следить за качеством данных, от этого зависит рентабельность бизнеса. Поэтому компания выделяет ресурсы на развитие DQ-сервиса для DWH.Первые шаги после ухода вендора. Архитектура приложения DQ  Суть нашего DQ-сервиса можно увидеть на этой схеме, выкладываем её здесь в качестве тизера, а чтобы погрузиться в детали её архитектуры.В этой статье мы поговорим о животрепещущем вопросе импортозамещения решений, которые мы применяли в нашем DQ-сервисе до ухода вендора.Срочное импортозамещение До широко известных событий 2022 мы строили DQ на SAS Data Quality. На SAS у нас был выстроен процесс проверки качества данных, мы определили зоны ответственности и планировали начать процесс обучения коллег из бизнеса взаимодействию с сервисом. Проверки поступающих данных настраивались инженером качества над Vertica. И к февралю мы начали внедрение SAS Decision Management — инструмента для self-service проверок качества данных.Но что случилось, то случилось, и мы начали поиск замены. Нам нужно было найти то, что удовлетворяло бы нашим требованиям и при этом не исчезло бы в одночасье из-за санкций, не перешло бы на подписку, которую мы бы не смогли оплатить из России.Анализ рынка Первое, с чем мы столкнулись, — отсутствие готовых коммерческих отечественных решений на рынке РФ для нашего стека. Поэтому назвать то, что мы делали, «импортозамещением» можно с оговорками: мы замещали, да, но не отечественными решениями, а тем, чем могли.Ситуацию осложнял факт, что мы не понимали, в какие сроки сможем решить задачу в таких условиях. Воспользоваться опытом коллег из российских компаний, которые использовали OpenMetadata, мы не могли: там много чего нужно было допиливать, а у нас уже был свой работающий каталог.Первые шагиМы провели анализ рынка, и самым подходящим под наши потребности решением оказалась опенсорсная библиотека Great Expectations (GX), которая сделана на Python.Достоинства GX, важные для нас:Есть множество кастомных проверок.Высокая степень гибкости настроек и сценариев.Достаточно живое комьюнити.Бесплатный доступ.Взвесив все за и против, мы сделали выбор в пользу GX.И сразу на граблиУ нас уже была команда, которая разрабатывала каталог данных. И мы начали разработку DQ-инструмента как микросервиса для каталога данных. Но не своими силами, а привлекли подрядчиков.СИБУР, как большая компания, может себе позволить иметь отдельную команду, чтобы развивать собственные сервисы. Но в условиях хаоса мы приняли решение привлечь подрядчиков с релевантным опытом.С нашей стороны, как сейчас уже понятно, было ошибкой отдавать разработку микросервиса на аутсорс. Нет, они всё хорошо разработали, но подрядчики рано или поздно заканчиваются, и нам пришлось попрощаться с ними.В процессе передачи дел возникли проблемы, и в итоге мы потеряли часть экспертизы по разработке. Со временем удалось нарастить эту экспертизу, но на это потребовалось время.Однако неприятности на этом не закончились. И если историю с подрядчиками можно отнести в категорию рисков, которые мы осознавали и оценивали как «Возможные» при принятии решения, то события, которые развернулись дальше, мы отнесли в категорию «Вряд ли такое может произойти».Чистый Open Source или форкДело в том, что в работе с Open Source библиотеками есть нюансы, связанные с обновлениями. В целом это классическая история с опенсорсными решениями, что они тоже развиваются (обнаруживаются различные уязвимости в безопасности, архитектурные недочёты).И комьюнити, которые связаны с этими решениями, могут увести разработку в какую-нибудь сторону, которая нам не нужна. И возможна ситуация, что после очередного обновления какие-то шаблонные проверки или сервисы у нас перестанут работать. Так и произошло.Никогда такого не было, и вот опятьВ какой-то момент мы обнаружили, что в новых версиях GX отвалилась поддержка Vertica и Oracle, а это для нас критично. И на множество вопросов «Когда это всё закончится?» они перестали отвечать, потому что сфокусировались на развитии своего облачного продукта, который будет распространяться по подписке.То есть перед нами возникла дилемма:Пользоваться старой версией GX, в которой есть поддержка нужных нам решений.Делать форк и оптимизировать его под наши нужды.Искать замену.Проблема первого варианта заключается в том, что рано или поздно нам всё равно пришлось бы делать форк. Потому что мы хотим подключаться к большему количеству систем, хотим масштабировать, оптимизировать и так далее.А пайплайн с созданием форка — это нетривиальная история. Если даже разработчики оригинальной версии не настроили в новых версиях Vertica, у нас шансов на реализацию этого было явно меньше. Вдобавок у нас не было ресурсов, чтобы пилить такое решение самостоятельно, стандартизировать и поддерживать. СИБУР — большая компания, но не настолько.Выбор решенияМы начали анализировать, что есть на рынке. Снова. Пообщавшись с коллегами из других компаний, поняли, что мы не одиноки в истории с GX и проблемы у нас похожие.В России пользуется популярностью Arenadata Catalog, он в плане написания проверок качества данных тоже базируется на GX. И его разработчики пошли по второму пути — сделали форк. Но у них компания, которая заточена на разработку каталога и проверок качества данных. А у нас немного другой профиль.И так как в решениях на базе Great Expectations теперь нет поддержки Vertica и Oracle, нам они, как уже упоминалось выше, не подходят. Поэтому мы начали анализировать другие популярные решения.Поняли, что многие решения зачастую сфокусированы на проверках данных в режиме реального времени — во время загрузки, а мы в СИБУРе валидируем уже собранные данные. В некоторых случаях решения работают напрямую со Spark, что нам не подходит. Какие-то инструменты мы отмели, потому что там недостаточно живое комьюнити, а какие-то нас не устроили по множеству причин.Soda vs Great ExpectationsВ нашу выборку попал DQ-инструмент SODA — это Open Source. Мы проанализировали SODA, сравнили c GX и подумали, что он будет лучше. Потому что его проще поддерживать, он подключается к Vertica и Oracle — а это то, что нам нужно.В SODA нет проблем с подключениями, потому в GX идёт подключение с помощью SQLAlchemy, а в SODA по-другому — отдельные коннекторы написаны.  В общем, протестировали, проанализировали, посоветовались с коллегами в других компаниях и поняли, что у многие переключаются на работу с SODA. Там активное комьюнити, люди пользуются, проблем нет.Вместо заключенияНаше текущее положение можно увидеть на этом графике. Он шуточный, но, кажется, в нём есть доля правды. Чем больше опыта ты набираешься в работе с данными, тем больше приходишь к тому, что проверки SQL-скриптами и разработка собственного DQ-инструмента с нуля выглядят более правильно.Риски использования Open Source есть и никуда не денутся, в чём мы убедились на собственном опыте, когда разработчик:убрал нужную нам функциональность;ушёл в сторону платной модели.Нам потребовался год, чтобы попробовать на себе всю эту специфику и понять, что нам не подходит и куда мы хотим двигаться дальше.Сейчас мы занимаемся миграцией с GX на SODA, так как этот вариант нам подошёл больше всего. Но и здесь сохраняются риски: разработчик может перестать поддерживать это решение, что-то может отвалиться либо переведено в какую-то платную подписку, а мы её купить не сможем, потому что мы в России.Также не стоит забывать, что SODA разрабатывает компания, которая находится на Западе. И мы снова можем оказаться в затруднительном положении. Если такое случится, будем искать что-то на нашем рынке либо разрабатывать своё решение.Но разработка собственного решения не выглядит привлекательной идеей для нас, как и для многих других компаний. Поэтому сейчас единственное, что остаётся, — это внедрять продукты с открытым исходным кодом.Подводя итоги по импортозамещению, можем сказать, что мы сделали всё возможное, чтобы не столкнуться с историей, когда у нас что-то отвалится и придётся всё резко переделывать. По крайней мере, старались организовать архитектуру именно таким образом. Мы выстраиваем многослойный DWH на Open Source стеке, внедряем туда Data Quality инструменты — тоже на базе опенсорсных решений.Концепцию и архитектуру нашего DQ-решения, которое можно применить в любой компании, обсудим в следующей статье. Если есть какие-то вопросы по этой теме — ждём в комментариях.",
    "А так ли важно планирование поставок в ритейле?": "Зачастую среди топ-менджмента или миддл-менджмента в ритейле бытует мнение, что система управления запасами — это задача вторичной важности. Есть более приоритетные задачи такие как обеспечение работы склада или процесс управления ценами. Либо же существует представление, что самое сложное это прогноз, а управление запасами это просто задача в стиле решения простой формулы A + B - C = X. В этой статье я попробую объяснить, почему это не всегда верное мнение и зачастую эта задача должна стоять первой.Кто ты, мальчик?В ритейл пришел в 2003 году в роли сотрудника рабочего зала, это простые процессы выкладка, смена ценников, консультации клиентов и работа с кассой. После этого начал заниматься оптом и госзаказами. Дальше карьерные амбиции меня привели к смене города проживания до регионального центра и пришлось идти на склад ритейлера простым кладовщиком. Я поучаствовал во всех типовых процессах склада в роли исполнителя и линейного менеджера. На этом мой опыт в области операционных задач закончился и начался опыт офисный.В рамках роста по карьерной лестнице меня ждал переход на роль продакт-менеджера, это была новая, на тот момент для рынка, профессия аналогичная категорийному менеджеру, который «и швец, и жнец ….», в том смысле, что в нем концентрировался весь набор задач по управлению продажами начиная от формирования матрицы, обеспечения поставок и заканчивая ценообразованием и промо мероприятиями. Объективно говоря это не самый эффективный способ управления продажами в розничном бизнесе, менеджер перегружен задачами и со всеми справляется не до конца эффективно даже на небольшом масштабе. Это я понял, когда позже перешел уже на «обычного» категорийного менеджера в другой компании, в круг задач которого входило ограниченное количество обязанностей, например ценообразование или управление логистикой было отделено от этой функции. Следующей ступенькой стал рост до начальника аналитической группы по анализу эффективности основного бизнеса, куда вошли задачи по анализу качества управления ассортиментом, эффективности логистики и ценообразования.Это привело меня к первому проектному опыту – разработке собственной системы ценообразования. Так начался мой путь движения от фронт-офиса к бэк-офису, где моя команда не принимает конечных бизнес-решений, но разрабатывает инструменты для их корректного принятия. Это был небольшой проект продолжительностью один год. По сути, концентрировался на простых задачах – создать «иллюзию низких цен» у наших покупателей, выполнить цели по марже, при этом не наращивая нагрузку на операционный блок (сотрудники зала могут поменять только ограниченное количество ценников в день).Следующий проект – это разработка собственной системы управления ассортиментом конечных магазинов уже в другой компании. Бизнес, в котором я работал в тот момент, насчитывал несколько тысяч торговых объектов разного размера, местоположения и окружения. К тому же этот бизнес быстро рос, а значит открывал 1-2 тысячи торговых объектов в год. Надо было создать умный алгоритм, позволяющий категорийному менеджеру управлять общими принципами образования матрицы товаров, а мелкие детали отдать системе. Начали мы с организации мастер данных, в масштабах компании это был крупный проект самостоятельной эффективности, но в рамках разработки решения по управлению ассортиментом это был первый шаг перед основными работами. Задачи операционного бизнеса в этом проекте тоже имели решающее значение. Система ежедневно высчитывает оптимальный ассортимент в каждом магазине, но логистика имеет инерцию, категорийные менеджеры работают над общей эффективностью матрицы, а сотрудники торгового зала вынуждены менять выкладку под каждую ротацию. Данный проект пытался подстроить процессы других служб под себя, но если процессы коммерческих служб легко принимали изменения, то логистика представляла собой очень сложный и негибкий процесс. На данном проекте продолжился мой карьерный рост на пару-тройку грейдов и в определенный момент времени в мое управление попала вся корпоративная аналитика, включая финансовую и управленческую. Под моим управлением команда аналитического блока систематизировала всю модель данных компании, для чего постепенно создавала корпоративное хранилище данных и впоследствии создала свой самостоятельный бизнес юнит. Выходцы из него сейчас работают на ключевых позициях в телекоме или финансовом секторе – там, где важны точные и полные данные в короткий период времени, но это отдельная история.Возвращаясь к истории с проектом по управлению ассортиментом – ключевым препятствием в разные отрезки времени становилась логистика, а менять ее всегда было сложнее чем любой другой процесс в компании. Со стороны казалось, что это управленческое противодействие или легкая диверсия против основного бизнеса, ведь что важнее чем определить какой ассортимент нужен покупателю. На деле же, и это стало понятно гораздо позже, задача логистики важнее всего в ритейловом бизнесе и по своей ценности превосходит даже такие операционные моменты как чистый пол в торговом зале.По успешному завершению проекта по управлению ассортиментом мою команду направили повышать эффективность работы логистики. В общем смысле мы должны были разработать такие системы, которые с минимальными затратами позволили бы обеспечить два простых принципа – необходимое и достаточное количество товара в торговом зале. Эти принципы я пытался выполнить в разное время в 5 компаниях, занимая разный уровень должностей от CEO минус три, до CEO минус один и работая с разными видами бизнеса, начиная от продуктов питания или бытовой электроники и заканчивая элитным нижним бельем, в компаниях с выручкой 200 млн долларов США в год и компаниях с выручкой 30 млрд долларов США в год. В моем управлении была как проектная деятельность по развитию и внедрению систем, так и вся операционная деятельность. В рамках разных конференций мне приходилось общаться с коллегами из других бизнесов или принимать к себе в штат людей из других областей, которые рассказывали о сложностях и задачах на их прежнем месте работы. Несмотря на разные цели, инструменты и методы реализации неизменность двух базовых принципов подтверждалась в каждой компании.Коротко про ритейл.Любой ритейловый бизнес характеризуется тем, что представляет собой разнесенную на большой площади «сборную солянку» из разных по площади и конфигурации торговых объектов, сложную сеть собственных складов, порой существенно отличающихся друг от друга, а также иерархию поставщиков, с не менее сложной сетью площадок отгрузки и, что более важно, со своим набором требований к клиентам. Я применил слово «иерархия» к поставщикам, потому что в мире бизнеса есть те, кто крупнее тебя, то есть ты зависишь от них и тебе надо считаться с их условиями и те, кто мельче тебя, иными словами, зависимы от тебя, то есть те, кому ежедневно ваш топ-менеджмент рассказывает о партнерстве, но в контексте «будьте добры, пересмотрите свои условия, иначе такие партнеры нам не партнеры».Задача логистики – обеспечить товар в магазине, то есть внутри себя понимать всю структуру бизнеса с ее особенностями и сделать так, чтобы несмотря на всю проблематику «физической реальности» гарантировать наличие товара. Это простая задача если мы просто пытаемся перевезти товар из точки А в точку Б. Всего-навсего нужно учесть, что в точке Б есть некая потребность для продажи. Предсказываем эту потребность и везем ее из точки А. Казалось бы, какие сложности могут быть, ну, вероятно, самое узкое место в такой системе – предсказать сколько нужно. Однако для многих компаний и это не составляет труда.Выше я уже говорил, что бизнесы отличаются между собой принципами и методами. Если объединить их в две большие группы, то существуют бизнесы:про-активные – там, где у покупателя есть потребность, но спрос не сформулирован. Ну, например, вам нужна зимняя куртка, обычная серая базовая, но будет это куртка от производителя «ИП Иванов» или «ООО «Хорошие куртки» для вас не имеет значения. Главное это наличие, приемлемое качество и цена. Компании ведущие такой бизнес управляют спросом опираясь на вашу потребность. То есть они привозят вам коллекцию курток от ИП Иванова по той цене, что смогли купить (подразумеваем, что она лучшая) сделали адекватную наценку оглядываясь на конкурентное окружение и вуаля, у вас есть спрос на куртку от Иванова. Дальнейшее управление спросом выражается в том, что компания «играет» ценой в течении сезона, меняет выкладку, дарит куртку в подарок к ботинкам и делает в общем-то все, чтобы привезенная под сезон партия была распродана к его концу, а цели по маржинальности этой партии привели к выполнению показателей компании.ре-активные компании живут на рынке, где бренд уже сам управляет рынком формируя именно спрос, а не потребность. То есть вам нужен не просто растворимый кофе, а кофе марки «Якобс», и вы не согласны на «Нескафе». Такие компании просто предсказывают сколько «Якобса» они смогут продать на базе прошлой статистики, ищут лучшую цену на этот продукт, оптимальную стоимость логистики и везут его. Они тоже играют в управление спросом, но значительно меньше. Потому, что и Якобс, и Нескафе всегда есть на рынке, не нужно мыслить партиями или их распродажами. Во главе угла всегда ассортимент, на который уже есть спрос.Важно сказать, что кристально выраженной компании одного типа практически не бывает, если это не моно-брендовый бутик. Я работал в бизнесе, где было 5% про-активного управления и 95% ре-активного, так и в компаниях где доля про-актива достигала – 85%. Глобально и про-активной, и ре-активной компании нужен прогноз. Оба вида компаний не хотят потерять продажи ни за сезон целиком, ни в конкретный день. Но и первая, и вторая компания могут позволить себе использовать простой метод пополнения – продал 2 куртки, привез 2 куртки. Продал две банки кофе, привез две банки. В этом случае ценность прогноза очень низка, угадать сколько курток или банок вы точно не продадите за один цикл поставки нужно всего разово, то есть, по сути, определить потолок. Допустим ваш потолок 10 курток, вы привозите 11-12-15 и дальше вообще не думаете о прогнозе их продаж.На деле методы управления запасами в этих компаниях отличались, но об этом позже. Ключевая мысль данного раздела заключается в том, что на простой модели «везем некоторый объем из точки А в точку В» нет никаких сложностей, в том числе и прогноз спроса не является проблемой.Небольшое отступление про прогнозЗачастую непосвященному человеку кажется, что прогнозирование спроса — это очень сложная задача, покрытая таинством предвиденья будущего, вплоть до хрустальных шаров и… ну вы поняли. Действительно прогноз высокой достоверности — это очень сложный алгоритм, учитывающий десятки или сотни факторов и событий, которые могут произойти и повлиять на будущее. Особенно усложняется этот алгоритм если вы пытаетесь предсказать даже самые мелкие детали – какой товар в каком количестве продастся в конкретный день в конкретном магазине, а еще и какого цвета, фасона или размера он будет. Системы, с которыми я имел дело, в пике учитывали более 200 факторов, включая вкус продукта, наличие конкурентов в 500-метровой зоне магазина или прогноз погоды в конкретном регионе.Однако, действительно ли такая достоверность прогноза важна? Начнем с простого пояснения – прогнозом является любая величина, которую вы себе «придумали» на завтра, будь то сто или один. Самым примитивным методом прогнозирования является метод – «завтра будет как вчера». То есть прогноз является простым транслированием вчерашних событий «в завтра», продали 5, значит и завтра будет 5. На практике такой прогноз имеет очень высокую достоверность, в ряде случаев он будет достигать точности в 80% и более, особенно на высоко-оборачиваемых товарах. Но если брать в среднем, это прогноз с точностью около 50%. Посвященный в прогноз меня поправит, что в оценке прогноза учитывается не точность, а ошибка, но мы упростим этот момент для понимания большинством читателей.Если в этот алгоритм добавить логику усреднения продаж за последние 5-10-30 дней (так называемая скользящая средняя, SMA), то мы уже получаем некое подобие тренда и к точности сразу прибавляется 10%, а если к этому добавить регулярную сезонность мы выйдем на среднюю сопоставимую с 65% точности. Большинство компаний останавливаются на 3-5 факторах, таких как годовая сезонность, недельная динамика, периоды отсутствия товара, цена и промо. Некоторые же идут дальше.Причина остановки на 3-5 факторах заключается в следующем: улучшение алгоритма прогнозирования и увеличение его точности — это затраты в его разработку, развитие и поддержку. И, как в любой массивной задаче, тут действует правило Парето, 20% усилий для 80% результата и наоборот, оставшиеся 20% результата стоят в 4 раза дороже. Чтобы оправдать такой мультипликатор усилий в прогноз высокой точности, надо понимать каким образом они будут окупаться. То есть нужна модель монетизации прогноза. Здесь становится понятно, что монетизировать прогноз можно только через рост представленности товара в магазине. Основные бизнес-риски неверного прогноза это вероятность опустошить магазин в середине между поставками (когда логистика еще не успевает довезти дефицит) и потерять продажи до следующей поставки. Если мы исходим из точности прогноза в 65 процентов, то, гипотетически, вы можете потерять 35% от выручки. А точно ли это так?Прогнозирование не единственная система в цепочке, влияющей на запас в торговой точке. В обычной торговой точке есть демонстрационный/презентационный остаток. Система пополнения закладывает страховые запасы. Могут включаться процессы и системы, балансирующие поток товаров в магазины и также формировать некие избыточные запасы, чтобы пройти некие проблемные периоды. Например, специалисты вручную вмешиваются в управление запасом перед волатильными периодами и формируют дополнительный сток для перекрытия рисков. В конце концов цепь поставок чаще всего возит товар не штучно, а некими минимальными квантами (упаковками) и на полке всегда образуется избыток, связанный с округлением заказа до кванта. Мой практический опыт показывает, что влияние ошибки прогноза на продажи всегда находился в пределах 2-4% доступности товара на полке и влиял менее чем на 0,5-1,0% продаж. Далеко не всегда экономический эффект от этих продаж перекрывает затраты на проект по развитию системы. Но это зависит от каждой компании индивидуально, потому что у нее уже есть своя статистическая база. Самый важный шаг перед тем, как инвестировать в точность прогноза оценить монетизацию и весь финансовый кейс в целом. То есть использовать рациональный подход к необходимости развивать это направление.Также важно отметить, что операционные проблемы, такие как отсутствие товара у поставщика или ошибки товарного учета, всегда влияли на представленность в 2-3 раза больше, чем проблемы неверного прогноза.Пример реального влияния ошибки прогноза на представленность в крупной компанииПример реального влияния ошибки прогноза на представленность в крупной компанииГлавная мысль данного раздела заключается в том, что непонимание масштаба проблемы и ее влияния на операционный бизнес в совокупности с заблуждениями относительно таинственного могущества прогноза зачастую формируют у топ-менеджеров иллюзию того, что будет «идеальный прогноз» и проблемы устранятся. Обязательной необходимостью является, перед стартом данной инициативы, собрать факторную аналитику доступности товара на полке и оценки общего товарного запаса. На первых порах это сложный отчет, собрать который потребует большого количества усилий продолжительностью от одной недели до десяти, но разработка и замена систем — это месяцы и годы, поэтому на этом фоне усилия всегда себя оправдывают. Он позволит топ-менеджеру избавиться от иллюзий и четко понимать точку приложения усилий. А если этот отчет поставить «на поток» с регулярным обновлением, то топ-менеджер может наблюдать за результатами своих усилий в реальном времени. Если вы не СЕО и ваша зона ответственности это не «выручка за год» или «LFL YoY», то только путем факторного анализа можно выявить, где именно вы повлияли на общий успех компании (ну или наоборот). Тем не менее прогноз — это отдельная и интересная тема, потому что есть кейсы, когда прогноз окупает себя и на 1% роста продаж за счет очень больших цифр, об этом я подробнее пишу в другой статье.Возвращаясь к темеВесь предыдущий раздел был посвящен значимости прогноза, но мы все еще говорим о том, какая система является ключевой в ритейле. И тут будет уместна аналогия, которую я часто привожу, давая пояснение к этой теме. Если компания — это единый организм, то вся инфраструктура вашей компании это составные части этого организма. То есть органы, которые надо снабдить жизненно важными элементами для их существования. Система, которая делает эту работу в человеческом организме это кровеносная система. Представьте себе, что ваша сложная логистическая сеть ритейловой компании — это кровеносная система вашего бизнеса. Используя эту аналогию, становится понятно, почему иногда возникают проблемы снабжения отдаленных конечностей вашей структуры, что происходит, когда возникают проблемы с сердцем и так далее.Сеть поставок как кровеносная система, а товародвижение как сердцеТак вот система планирования запасов и поставок это то, что заставляет ваше сердце биться. Именно заявка, которую создал человек или система на перемещение товара из точки А в точку В является сердечным тактом, который впоследствии приведет к снабжению необходимыми для выживания элементами любой конечный орган. Это нисколько не умаляет значимость работы каждого отдельного органа, но именно логистика и системы, инициирующие «сердечные такты», являются самыми критичными системами жизнеобеспечения. (Тут, конечно, будут уместны замечания про значимость мозга, но не хотелось бы уходить в этические дискуссии относительно того, что есть примеры жизни организмов и без его участия)Кстати, система планирования поставок и есть та самая система, которая инициирует «сердечный такт». Если в вашей компании это делает, например, автозаказ, то именно ежедневная генерация заявок на движение товаров, а также их последующее исполнение и есть процесс, вокруг которого строится весь бизнес. Ритейл живет пока внутри вашей сети движутся товары. «Качество жизни» вашего бизнеса является отражением качества движения товаров внутри вашей логистической инфраструктуры. Резюмируя, «основной бизнес» ритейла это движение товаров.Прочти я эту мысль лет 10-15 назад, когда только начинал работать в этом направлении, то смог бы придумать десятки аргументов, почему есть что-то более важное, ну давайте пофантазируем.«Хорошо, привез ты товар, но поставь на него высокую цену – и нет продаж», заявит специалист по управлению ценами. Это безусловно так, неразумное ценообразование может «убить» продажи. Если ваша себестоимость 100 при входе товара в магазин, ваши конкуренты продают с наценкой 30% за 130, а вы заявляете цену на полке в 200 это конечно губительно для любого бизнеса. Но мы исходим из ситуации «при прочих равных», когда и вы, и ваш конкурент разумны. И вот тут ваша система логистики дает вам преимущество. Сколько вы потратили на транзит товара определяет именно она и именно это дает вам на входе в магазин 100 или 90, или 110. И если ваш вход 130, а у конкурента 130 уже «на полке», ваша система ценообразования уже не будет справляться в войне с рынком.«Прежде чем везти товар, надо управлять ассортиментом – толку от перевозки никому не нужных товаров» заявит менеджер по управлению ассортиментом и взаимоотношениями с поставщиком. Это тоже верный тезис, но отчасти. Качественные системы планирования дадут вам нулевой план по товарам, не имеющим спроса. Даже если первая поставка будет совершена на неверных предпосылках, следующие поставки не состоятся если товар не востребован. Ваш магазин, конечно, пуст, но система снабжения не генерирует вам неверные движения. Но если тот же менеджер по управлению ассортиментом ввел востребованный товар, то система поставок сфокусирует все свои усилия именно на этом товаре. Таким образом система сама сгенерирует поток по тому товару, что позволит бизнесу развиваться.«Вежливый кассир и красиво выставленный на полку товар, вкупе с освещенным торговым залом и чистым полом – вот залог успеха» заявит ответственный за операционный бизнес. Здесь не буду спекулировать на тему, «а как же магазины без персонала, которые массово открываются сейчас в разных уголках мира?» или «а как же рыбные рынки восточной Азии где нет ничего из этого?». Скажу, возможно грубо и просто, но без цели кого-то задеть: уборщица необходимый элемент всех существующих «в кирпиче и бетоне» бизнесов, но вы же не будете заявлять, что уборщица — это бизнес-образующий элемент? Да, значим, как и любой другой элемент системы, но в ритейле продавец продает, если есть что продавать.Вероятно, вы сможете придумать более дельный аргумент как финансист, HR или IT специалист. Но еще раз подчеркну, у меня нет цели сказать, что в ритейле есть неважные элементы, также как и в организме неважные органы. Лишь прошу обратить внимание на понятие «основной бизнес». То есть чем вы занимаетесь, уместив это в одну фразу? Моя мысль такова:Вы доставляете товар к тому месту, где покупатель может его купить.Если бы вас не было, покупателю пришлось бы самого себя доставлять к месту производства, чтобы его купить на фабрике. То есть ваш бизнес – доставка/перемещение товаров с эффективностью выше, чем это делают ваши конкуренты, производители или мог бы сделать сам клиент.Данный раздел, вероятно, является самым спорным, потому что в нем делается однозначное утверждение, причем вывод довольно дискуссионный. Те, кто этой мысли не уделял много времени, могут сходу придумать несколько критичных замечаний и потребовать дописать в формулировку несколько нюансов. Да и мне самому приходилось работать в ритейловой компании, основной бизнес которого не движение товаров, а время. Я долго осмыслял природу этого, пока не пришел к мысли, что работаю не в ритейле, а децентрализованном производстве и тогда все стало на свои места. В целом же данный вывод это результат многолетней практики в разных областях ритейла и итог большого количества наблюдений за развитием разных компаний.Ритейловый бизнес — это логистический бизнесК этой части статьи нужно принять позицию, указанную в заголовке, чтобы дальнейшее ее прочтение не формировало новых противоречий. Теперь попробуем разобраться в самом логистическом бизнесе. Если на время забыть о существовании всех остальных частей ритейла, то сама логистика тоже имеет внутреннее дробление. Крупных блока можно выделить три:Soft-логистика – перечень задач и функций направленных на работу с данными, предшествующих физическим операциям с материальными ценностями. По сути, все это можно объединить в один большой термин – планирование, но под этим термином скрываются совершенно разные задачи в зависимости от того, какой горизонт и детализацию вы планируете. Если бы у нас была задача перевезти товар из точки А в точку В, то в этом месте появилось бы понимание, куда надо перевезти товар, когда и в каком количестве.Hard-логистика – физическое исполнение планов, то есть процесс состоящий из действий конкретных юнитов по погрузке, упаковке, перевозке, приемке и распаковке ценностей, включая все сопутствующие затраты. Очевидно, что это самый дорогой элемент в логистике, пропорции таковы, что на тысячу исполнителей может хватить одного планера из предыдущего блока (правда снабженного современными инструментами). А стоимость одного склада в разы превышает стоимость серверного оборудования необходимого для планирования.Support-логистика – бэк-офис помогающий бизнесу развиваться в правильном направлении, включающий топ-менеджмент, все аналитические элементы, такие как построение бюджетных планов и анализ затрат, повышение производительности труда и прочие непрофильные задачи. В некоторых компаниях у этой функции есть даже собственный HR, СБ или IT.Находящиеся в разных этапах своего эволюционного развития компании приходят к такой структуре постепенно. Если компания совсем молодая, то планирование обычно находится в коммерческой функции, порой это просто ассистент категорийного менеджера ответственный за заказы поставщикам. Чуть позже формируется подразделение ответственное за товародвижение, а в крупной компании это превращается в отдельный блок по планированию. Как правило в финальной части этот блок переходит в ведение лидера по hard-функции, именуемого, чаще всего на западный манер, «Директор по цепочкам поставок», он же «Supply-chain manager, SCM», или по-нашему «Директор по логистике». Этот менеджер (SCM) находится в блоке support (как и написано выше) и анализируя экономику своего направления он просматривает P&L (отчет о прибыли и затратах), стремясь сократить стоимость своих затрат на обслуживание того потока, который он обязан через себя пропустить для обеспечения продаж. Обычно ее считают в деньгах на единицу перевозимого на км товара. Это некая квинтэссенция эффективности. Если вы и ваш конкурент возят одинаковый объем на одинаковое расстояние, но вы делаете это дешевле и с гарантированным качеством, то вы эффективнее чем конкурент, а значит ваши шансы на выживание значительно выше.Возвращаясь к основному инструменту этого менеджера (P&L), он видит в своем бюджетном анализе огромные затраты на водителей, складских работников, обслуживание складов и автопарка, а также затраты на развитие и амортизацию инфраструктуры, фокусирует свое внимание на снижение стоимости всех этих статей, повышая эффективность производительности труда и снижая стоимость одной операции. Все это верные шаги, если мы исходим из формулы «перевезти товар из точки А в точку В». На этой простой модели действительно эффективнее тот бизнес, что сделает это быстрее и дешевле. Но в погоне за стоимостью порой присутствуют явные перегибы. К сожалению, часто наблюдал такую картину, что весь бюджет развития функции цепочек поставок эти менеджеры инвестировали в задачу эффективности Hard оставляя своему малому Soft спутнику небольшие крохи. И также часто видел, как достигая плато по эффективности эти же менеджеры верили в некие «святые супертехнологии» (например, роботизированные склады), которые имели окупаемость в десятки лет, но они готовы были идти в них лишь бы сократить стоимость одной операции на несколько процентов. Но всегда ли это верное направление?Перевезти товар из точки А в В.До текущего момента статьи мы отталкивались от позиции, что задачу, которую решает логистика в ритейле (а по сути, весь ритейл) это перевозка товара, сознательно упрощая модель до такого простого примера как в заголовке. Принцип упрощения сущностей для понимания — это стандартный подход во многих задачах, но теперь хочется разобраться, а так ли просто все в ритейле. Можем ли мы упрощать эту задачу чтобы оценить ее целиком? Здесь следует обратиться к ежедневным функциям soft-логистов и задать вопрос, чем они занимаются при планировании. Ответ будет примерно такой, в их задачах нет никакого «rocket science», они пытаются составить план поставок, соответствующий принципам необходимости и достаточности.Изображение MidjourneyДля этого план должен соответствовать ряду принципов:Важной вводной для любого плана является горизонт, то есть план содержит в себе несколько отрезков времени в будущее (например, план на неделю содержит дни, план на квартал может содержать или дни, или недели целиком и так далее) для каждого из которых план составляется на индивидуальных правилах с учетом прогноза продаж, изменений в структуре сети и потока, а также изменений параметров используемых в алгоритмах, отражающих пожелания к корректировке работы системы.План должен обеспечивать «необходимость», за этим простым принципом скрывается модель определения минимального порога остатков ниже которого риск недо-продажи становится критичным. Это означает, что план может включать в себя сознательно заложенный уровень недо-продаж, важный нюанс, который создает разницу между прогнозом продаж и планом. Вы ожидаете, что прогноз находится в вилке от 7 до 13 штук, на какой уровень вы будете ориентировать свою систему? Самый простой ответ – конечно 13 штук, ведь привези мы 12, есть риск потерять продажу одной штуки, но ответ не всегда так однозначен, по «другую сторону» складывается совершенно иная экономика и не всегда обеспечение 100% вероятных продаж это обеспечение самой эффективной затратной части.Напротив необходимости находится принцип «достаточности», который должен лимитировать верхнюю границу в вашей структуре остатков. Это тот принцип, который должен ограждать от роста затрат в рабочий (замороженный) капитал (стоимость всего товара внутри торговой сети, который по принципам банковского процента генерирует регулярные затраты). Плюс перегруженная сеть поставок приводит к необходимости открывать и поддерживать новые звенья цепи (склады и подсобные помещения), увеличивать площадь для хранения, где товар не продается, а просто лежит. В итоге при пересчете затрат на каждую единицу товара существенно растет стоимость транзита на километр, а мы помним, что это ключевая метрика директора по функции.Опциональным, но крайне желательным является общий баланс потока. Если мы построим план, соответствующий вышестоящим условиям, вы получите очень волатильную кривую. На простом примере: у вас торговая сеть по продаже алкоголя, очевидно, что пятничные продажи существенно выше продаж понедельника. Значит план остатков показывает «пик» в четверг вечером и «яму» утром понедельника (вспоминая сердечные такты логистики мы видим на плане кардиограмму). На языке логистики это означает, что ваша инфраструктура работает с перегрузкой в четверг и «простаивает» в начале недели. А что такое «простой»? Допустим у вас есть склад, где работает 10 человек в смену. В понедельник на него падают задачи загружающие 5 человек из 10, значит вы платите зарплату 5 сотрудникам обосновано, а 5 получают зарплату не «за работу», а «за выход», то есть впустую с точки зрения бизнеса. В четверг на склад падают задачи на 15 человек, ваши 10 человек работают с перегрузкой и возможно вам нужно вывести из резерва дополнительных людей. Это дополнительные затраты на вызов человека с выходного, да и вместит ли ваш склад 15 человек и не будут ли они «толкаться локтями»? А ваш погрузочный блок может обслужить в 1,5 раза больше машин? А у вас есть такое количество авто? А в магазине могут принять объем в 1,5 раза больше и успеть выложить? В общем и целом, затраты на единицу растут, ведь вы закладываете в него «простой» понедельника и двухкратную оплату выхода с выходного в четверг. Конечно, на небольшом складе можно особым образом спроектировать смены в течении недели, но, если у вас 50 складов в каждом из которых 200 человек, вы уже не решите эту задачу простым планированием смен. Но и на небольшом складе у вас половину недели хранится товар, а это дополнительное пространство, ведущее к росту аренды. Резюмируя данный пункт, эта часть задачи не связана напрямую с наличием товара, но очень важна для директора по функции и влияет на экономику логистики в целом.Описанные выше принципы несколько усложняют задачу от уровня «перевезти товар из точки А в В» до уровня «сформировать план перевозки всех товаров между всеми точками, обеспечивая минимальное и достаточное количество товара в каждой точке и балансируя общую нагрузку на логистическую сеть». Также из указанных принципов следует ключевые параметры эффективности (KPI) для оценки работы блока в целом. Как правило это:Доступность товара (OSA, ISA) – как сравнительная метрика «ожидаемое наличие к фактическому». То есть логистика принимает на себя обязательство обеспечить наличие определенного ассортимента. Тот ассортимент, что есть в наличии вероятнее всего меньше, чем тот, который ожидается. Плюс сам термин «наличие» имеет разный способ расчета. Если товара 1 штука – это достаточное наличие? Вероятно, для одних товаров да, а для других остаток не должен упасть ниже 3-5-10 штук. Отношение факта к ожиданию и есть оценочное состояние качества решения этой задачи.Товарный запас или оборачиваемость (inventory turnover) – это ограничительная метрика, следить за которой нужно в динамике. Она показывает отношение среднего остатка к средней скорости продаж в сравнимых единицах. Идеальный и, в то же время, недостижимый запас это 1 день продаж для всего остатка. А какой является оптимальным для конкретного ритейлера это результат сложных моделирований и вычислений. Те ритейлеры, которые не научились строить эти сложные модели обычно работают с динамикой этого параметра стремясь каждый год его улучшать. Можно было бы сказать, что так делать неразумно, но практика бизнеса такова, что 95% компаний работают с этой метрикой именно так и при этом лидируют на рынке, возможно это неплохой способ работы.Затраты логистики (costs) – способ оценки экономики логистики в сравнении с другими компаниями. Обычно считается как отношение затрат логистики к выручке всей компании в деньгах. Получается процент затрат, что позволяет использовать эту величину с бенчмарками рынка. Компания А сравнивается с компанией В путем сравнения этих величин из публичных отчетов. Это в целом верно для простых сравнений, но для стратегического целеполагания несет в себе ошибки, более того это опасный путь. Тут небольшое отступление.Отступление про затратыДело в том, что процент затрат — это не только затраты на ресурсы и персонал, но следствие той инфраструктуры, которой обладает ритейлер. Если мы имеем две абсолютно одинаковые по макропараметрам сети, то безусловно более экономная сеть выглядит выгоднее чем, та, что тратит больше. И именно так рынок оценивает две компании между собой. Затраты на логистику уже давно находятся в публичной отчетности любой компании с размещением акций. Но даже непубличные компании все равно сравниваются по этой метрике путем небольшого шпионажа.Важен тот факт, что термин эффективность — это сложный термин. Он включает в себя затраты и их соответствие стратегическим целям. И как правило о «соответствии стратегическим целям» забывают, вынося на первый план только фактические затраты. На практике более высокие затраты это не обязательно ошибки менеджмента в части управленческих решений, но и вполне разумные резервные вложения, направленные на исполнение стратегических решений:Например, устойчивость напрямую коррелирует с тем, какой у вас ресурс – собственный или аренда. Когда на рынке начинается нестабильность она мгновенно влияет на компанию, переложившую свои проблемы на 3PL и аут-стафф. Тут уже нет возможности оперировать термином «лояльность» если это не ваши сотрудники. Или нет возможности отложить рост затрат на ресурсы путем управления объемом сделки, 3PL это отдельный от вас бизнес, он живет в своей стратегической модели.Способность к гибкой реакции на точечные изменения зависит от ваших резервов, которые стоят дополнительных затрат. Компания со своим штатом всегда растит замены линейного персонала и менеджеров внутри себя, перекрывает отпуска и больничные своими собственными штатными сотрудниками, а HR постоянно имеет некое понимание о стоимости среднего специалиста на рынке и понимает, как нужно увеличить ФОТ чтобы закрыть вакансии или снизить текучку в конкретной части цепи поставок. Также понимает цену обучения собственных сотрудников.Любому росту предшествует рост затрат, сначала надо потратить деньги на строительство склада, его конфигурирование и последующее комплектование персоналом, а потом он начинает генерировать возврат вложений. Конечно, грамотный финансовый директор может немного схитрить и вынести затраты на строительство в инвест-вложения исключаемые из затрат до расчета прибыли и не включать их в стоимость логистики, но ФОТ нового персонала, который вы наняли заранее для обучения туда уже не отнесешь.Так как метрика стоимости логистики обычно фигурирует в публичной отчетности, директору по функции часто ставят в цели снизить эту величину, чтобы выглядеть привлекательным для инвестора, но в своей практике я наблюдал как цели по этой метрике ставились несвоевременно. Например, компании в быстром росте ставили задачу сократить инвестиции или компании, прошедшей предшествующий год с проблемами, на новый бюджетный год ставили задачу пройти еще дешевле, без учета того, что проблемы являлись следствием недофинансирования прошлых периодов. И это недофинансирование не покрывал даже рост компании или инфляция. Затраты считаются как относительная величина, поэтому рост выручки теоретически увеличивает доступный бюджет логистики каждый год, но рост может быть в районе 10%, а недофинансирование значительно превышать эти цифры. При этом от директора ждут что он сможет уместиться в часть этой суммы, то есть ему доступно из 10% роста только 3%, а остальное он должен сэкономить, показав рост эффективности.Циклы для таких компаний выглядели так – пришел новый директор по функции, получил задачу снизить затраты (costs), стремясь получить бонус срезал как можно больше, в том числе жизненно важные функции, в коротком периоде это не привело к остановке работы из-за инерции, получил бонус, ушел в другую компанию оставив своему наследнику невыполнимую задачу с большим количеством воспаленных участков, руководство компании ищет топ-менеджера готового еще больше срезать затраты. Дальше цикл повторяется до первого крупного кризиса. После чего компания делает дикие вливания средств в эти статьи, порой выше, чем если бы компания делала все своевременно. Я бы добавил в публичную отчетность пункт про то, сколько текущий директор по функции занимает свой пост или сколько их сменилось за последние 5 лет, причем речь не только про функцию логистики, но и про остальные публикуемые метрики.Я сознательно сделал такое большое отступление про затраты несмотря на то, что статья про Soft-логистику, а затраты генерирует в основном Hard-логистика. Забегая вперед – позже в статье мы рассмотрим, как Soft-логистика может помочь директору по логистической функции найти внутренние резервы без вливаний в покупку складов или транспорта.Решение задачи формирования планаВ самом начале этой статьи мы говорили о делении комплексной задачи на множество простых задач. Если у вас есть сложная задача, то иногда вы можете разложить ее на простые подзадачи и добившись улучшения на маленькой задаче получить общее влияние на результат. Для примера возьмем задачу из области логистики.Для Hard-логистики это, например задача пробега при комплектации заказа специалистами отборщиками на складе. Ваши сотрудники суммарно ежемесячно проходят расстояние до луны? Берем маршрут одного сотрудника при сборке одной строчки в заказе и работаем с ним. Меняем логику расстановки товара в зонах склада, логику WMS в размещении товара в местах хранения относительно мест отборки, формируем задания на спуск таким образом, чтобы не терять время на сборку одного заказа. Мелкими шагами уменьшаем сборку одной строки с трех минут до двух минут, пробег с 30 метров до 20 и этот рост производительности на 30% на подзадаче приводит к существенному улучшению общего решения.Пример сокращения пробега на базе зонирования складаК сожалению, далеко не все задачи могут быть разложены на простые элементы. Речь идет о задачах, имеющих зависимости друг от друга. В примере выше я описал сборку одной строчки заказа с точки зрения процесса отборки. Но когда сотрудник складывает заказ на паллет или в другую транспортную тару он уже решает задачу сборки груза целиком. И тут нельзя добиться оптимизации работая со складыванием одного товара. Всегда найдется товар с другими весогабаритными характеристиками и его надо принимать во внимание. Будет странно складывать тяжелые аккумуляторные батареи поверх пластиковых бутылок с горючей жидкостью. Решение этой задачи всегда происходит в комплексе, и система должна комбинировать большое количество вариантов чтобы найти наилучший. В математике эта задача имеет общепринятый пример, на базе которого ее пытаются решить наилучшим образом – это задача о рюкзаке.Картинка из Википедии к статье «Задача о рюкзаке».Сложность этой задачи заключается в трех моментах:1. Есть общая емкость рюкзака, которую нельзя никак превышать2. Каждый элемент имеет несколько измерений, такие как, например, вес, ценность, габариты и представлен ограниченным количеством (то есть нельзя взять 10 товаров одинаковой ценности и размеров, надо сложить из имеющихся).3. Загрузить рюкзак необходимо максимально возможным весом и максимально повысить итоговую стоимость груза.В логистике можно себе это представить загрузкой грузовика, в который надо сложить товар в одной партии. Ну например вы везете компьютерную технику, у вас есть коробки с клавиатурами, с мышками, мониторы, системные блоки, процессоры, блоки бесперебойного питания и прочие комплектующие. В один грузовик вся партия не влезет и вам надо сделать так, чтобы загрузка объема грузовика была максимальной, а ценность перевозимого груза наибольшей, в этом случае отношение цены перевозимого груза к цене рейса будет наивысшей. Допустим рейс стоит 500 000, а перевозимый груз, состоящий только из блоков бесперебойного питания, 5 000 000, цена вашей логистики 10%, если же мы повезем полный грузовик процессоров, то цена рейса практически не изменится (ну разве что подорожает из-за стоимости страховки), но перевозится уже 500 000 000 и логистика будет стоить 0,1%. В реальности отвезти надо сборный груз, идеального заказа, состоящего только из процессоров, скорее всего, не получится.Не буду останавливаться на методах решения этой задачи, повторю лишь, что все методы — это различные вариации перебора всех возможных вариантов. Некоторые методы решения сокращают количество перебираемых вариантов отсечением большой ветки «плохих» вариантов, некоторые останавливаются на приближенном решении. Очевидно, что идеальное решение можно найти только взвесив каждый вариант и сравнив с другим.Главная мысль данной главы заключается в том, что задача по расчету плана движения товаров — это комплексная задача и ее сложность выше сложности остальных задач, в силу того что она является не разбиваемой на простые подзадачи. В ритейле есть и другие задачи, которые могут решаться с использованием комплексного подхода. К ним относится:Управление ассортиментом – хороший ритейлер стремится сформировать ассортиментную матрицу по группе, учитывая каннибализацию продаж идентичных товаров между собой и стремясь расширить предложение на все группы покупателей.Ценообразование и промо – если ваши технологии достаточно развиты, то вы, делая скидку на один товар, учитываете цены аналога, чтобы не привести ситуацию к полной потере прибыли. Совершенно нет смысла два разных бренда в одно время продавать с одинаковой скидкой. Покупатель возьмет свой любимый бренд, а ваша скидка не привела к стимуляции спроса, то есть вы просто «слили» маржу. Конечно, есть нюансы, но учитывать в ценообразовании одного товара цену на другой это рабочий метод.Прогнозирование продаж – по мере усложнения алгоритма продаж, каннибализация должна стать значимым фактором прогноза в силу того, что действия с ассортиментом в рамках одной группы спроса влияет на группу целиком. Рост продаж одного производителя в нормальном сценарии может привести к замедлению продаж его аналога, просто по той причине, что в одинаковом трафике обычно наблюдается равномерный спрос на определенный вид продукции.Эти примеры отличаются от примера с планом движения товаров так как являются для этих процессов опциональными. Вводя новую ассортиментную позицию и не выводя ее полный аналог, вы на какое-то время переполните полку, но категорийный менеджер вправе рассчитывать на то, что эту ошибку исправит логистика. Просто через время вы увидите полное замедление заказов по позиции, на которую нет спроса. Неверное ценообразование по двум позициям это нереализованный потенциал прибыли, но не потеря её. А прогноз продаж, не учитывающий продажи аналога при вводе, учтет его с небольшой задержкой, когда более слабая позиция покажет статистически отрицательный тренд. Иными словами, это потенциальные точки роста в этих процессах, которые обычно есть в списке будущих задач, но чаще всего ближе к хвосту бэклога, потому что влияние этих задач на общий результат малозначимо. То есть те самые задачи по Парето входящие в 20% результата за 80% усилий. Для плана движения товаров (или плана пополнения) это является базовой частью задачи, так как она всегда должна решаться комплексно. Давайте разберем почему так.Из чего состоит план.В первую очередь план пополнения представляет собой шкалу времени, протянутую от сегодняшнего дня в будущее на несколько циклов. Если пополнение происходит с частотой раз в неделю или чаще, то план обычно строится на уровне дня и на горизонт в 30-90 дней. Если пополнение происходит раз в месяц, то план строится на уровне недель и на горизонт 15-50 недель. На самом деле это просто отраслевая практика, а не незыблемый принцип.Основной влияющий на это фактор это цикличность поставок, в плане должен быть расчет относительно 3-10 ближайших поставок. То есть план обязательно обладает признаком точки О – стартовая точка, в которую мы приступили к расчету, точка А – ближайшая возможная поставка, точка В, С и т.д. – следующая возможная поставка.Шкала времени для расчета планаСобственно, производя нужные вычисления в каждую из возможных точек мы принимаем решение нужно ли в ней производить пополнение отталкиваясь от локальных ограничений. Заказ нужно производить если есть риск обнулиться до следующей точки и, при этом, сумма заказа должна быть минимальной возможной. Нужно учесть ошибку прогнозирования и прочие параметры, которые заложил пользователь на будущее. Это простая формула вида А+В*С, решаемая несколько раз в зависимости от того, сколько дат у нас на плане. Результат расчета этой формулы называется «идеальный план», в отрасли он зовется «неограниченным» потому, что результат расчета не содержит в себе ограничения, задаваемые физическими лимитами объектов и лимитами в контрактах с поставщиками. Отправлять неограниченный план в исполнение нельзя, контрагент не выполнит заказы в которых не учтены ограничения, а заказы не учитывающие лимиты «физики» просто не будут выполнены в срок. Это к тому, что решение задачи А+В*С не является ценным решением ввиду того, что его не исполнят, а значит комплексное решение — это не опция в данном случае.Если мы определились по одному товару, что его заказ надо сделать в точке А, то следующим этапом мы формируем заказ по всем товарам, которые нам отправляет данный контрагент, просто группируя в заказ все товары, которые тоже нужны в точке А. В простом варианте этот заказ можно отправлять, но тут не учитываются ограничения контракта. Например, сумма заказа в точке А должна быть больше какой-то суммы в рублях, потому что в контракте написано «заказ меньше чем на Х контрагент не отгружает» (его рейсы тоже стоят денег и везти товара на 500 000 за 50 000 он не хочет). В этот момент к каждому товару в заказе должны быть применены эти ограничения. То есть каждый товар надо пересчитать так, чтобы суммарные условия были выполнены. Решение этой задачи это решение системы уравнений.Такая же система уравнений решается если контрагентом выступает внутренний склад, но в этой задаче уже нужно учесть, что на складе могут быть дефициты, выступающие верхней границей. А если принять во внимание, что склад — это тоже объект, пополняемый нашей системой, появляется сложная матричная система зависимостей между уравнениями. Одна система уравнений решает задачу поставки со склада на магазин, а вторая систему поставки от поставщика на этот самый склад. И эти поставки должны быть синхронны между собой. Если магазину товар нужен на складе 10го числа, то поставка на склад 11го числа становится малополезной. Именно внутренние склады существенно усложняют расчеты. Если предположить, что вы смогли решить задачу с одним эшелоном, то представьте себе реально существующие на практике 3-4 эшелона.Решенная задача в данном случае — это ограниченный план. То есть в нем, в отличии от предыдущего «идеального» плана уже учтены ограничения первого этапа.Таким образом решая задачу для одного товара, мы решаем простое уравнение.Если задача решается для заказа, то мы решаем систему из нескольких уравнений.Если задача решается для одного склада мы решаем матрицу систем уравнений.Может показаться, что это конечные шаги решения, но тут вступает фактор оптимизации. Это тот кейс, когда пятничные отгрузки кратно выше отгрузок в понедельник. Это накладывает еще один уровень усложнения решения, но следуя примерам из других сфер ритейла эта задача является опциональной, потому что с точки зрения своих задач (снабжение товарами магазинов и складов с учетом ограничений), мы ее выполнили, решив матрицу из систем уравнений.Подводя итог данного раздела, формируется следующий вывод: задача составления плана поставок (плана пополнения) — это комплексная задача, декомпозиция которой на более мелкие всегда снижает качество общего решения, а в некоторых случаях упрощение до простой логики «перевезти товар из точки А в точку Б» делает задачу нерешенной в принципе.И тем не менее.Если вспомнить эволюционный путь подразделения soft-логистики внутри компании (там, где оно зарождается в коммерции и в итоге приходит к SCM), то нужно понимать, что системы компании тоже проходят эволюцию в несколько этапов вместе с самой компанией и функцией управляющей запасами. Когда компания открывает свой первый магазин, то заказы на него считаются вручную человеком, не имеющим вообще никакого отношения к экспертизе по товародвижению. Зачастую это просто менеджер магазина, отвечающий «за все» в новом проекте. По мере роста и развития подразделения сначала появляются Excel файлы для расчета (именно расчета, учет делается в ERP), потом появляются вариации автоматизаций, либо это макросы, либо какие-то надстройки или сервисы к материнской учетной системе собственной разработки.Качественный переход происходит как всегда по Гегелю, после количественных изменений. То есть с открытием новых торговых и складских объектов, по мере появления новых категорий товаров и схем поставок сложность логистики растет, количество сотрудников ответственных за пополнение увеличивается и управление в Excel становится невозможным. Убытки от ошибок в простых инструментах становятся вполне ощутимыми за счет масштаба, сотрудники жалуются на невозможность решить какие-то задачи без улучшений. К этому моменту ответственный за этот блок понимает, что качественный переход надо производить. Именно в такие моменты принимаются решения о покупке профильных систем для целей товародвижения или их самостоятельной разработке «с нуля».Следующим шагом, как правило, является внедрение несложной системы позволяющей упростить рутину. То есть простой расчет заказов с учетом небольшого набора ограничений, как правило автоматизируется самый массовый вид документов – заказы на магазин. Крупнейшие ритейлеры начинали с «автозаказа магазинов с встроенным прогнозом на скользящей средней». Более редкие и сложные заказы на склады, в которых нужно учесть многофакторные ограничения продолжают делать эксперты с большой практикой и развитой интуицией. Они видят прогноз по скользящей средней идущий вниз, недоверчиво оценивают взглядом и экспертным образом закладывают по своей практике увеличенный объем заказа. В компании к этому моменту обычно введена измеряемая система ключевых показателей (KPI), а для сотрудников есть система штрафов и поощрений. Ему не хочется терять свой доход допустив ошибку со снабжением, он использует метод собственных перестраховок.Заказы «на склад» могут считаться вручную, но специалисты зачастую стремятся внедрить внутреннюю автоматизацию на самом раннем этапе, пускай и простыми формулами или макросами. В общем и целом, это действительно рабочий метод использовать Автозаказ для магазинов и Excel для расчета заказов на склады. Так может продолжаться несколько лет, пока измерение KPI и постоянных поиск эффективности не приводит логистику компании к тупику. Уменьшение «пробега по складу» не дает возможности существенно сократить стоимость логистики ежегодно. Эффективность, достигнутая за первые несколько лет приходит к своему «плато», и грамотный менеджер по функции логистики (SCM) обращает свой взор на специалистов по управлению запасами.На этом этапе, который обычно предшествует следующему качественному переходу, стандартный диалог руководителя с экспертами строится примерно следующим образом:- Что вам мешает делать качественные заказы на склады? Почему одной части товара критически мало, а другой части с существенным избытком. Операционный бизнес постоянно на это жалуется.- У нас очень плохой прогноз с большой ошибкой, товары по которым прогноз завышен мы пере-заказываем, а по которым занижен недо-заказываем. Из-за этого мы и получаем «плохие» запасы.- Что нужно сделать чтобы вы стали заказывать лучше и мы стали выполнять цели по KPI?Повысить точность прогноза, а дальше мы справимся!Этот ответ отчасти верен, но в целом неверный совершенно. Дело в том, что, задавая вопрос эксперту его спрашивают о том, как он будет делать лучше свою часть работы, но мысля своим фрагментом общей задачи, он не всегда способен рассказать, как повысить качество решения задачи в целом. Общаясь со своими коллегами, я часто слышал вопрос от топ-менеджеров в стиле «что надо сделать чтобы повысить точность прогноза для заказов?», который по сути являлся передачей их диалога с экспертами.Начнем с того, что постановка вопроса в целом некорректна. Задачу, которую надо решить – это повысить качество решения задачи управления запасами. А через какой подход это уже следующий вопрос. Надо понимать, что эксперту выгодно занимать позицию, в которой его ошибки очень небольшие, а вот внешние факторы влияют на его результат существенно, это не означает что он вредит компании своими действиям, просто он мыслит теми категориями, в которых он профессионал и выдвигает соответствующие гипотезы. Здесь самый правильный шаг – собрать необходимый срез данных и перепроверить эту гипотезу как я предлагал в начале статьи.С большой вероятностью повышение точности прогноза позволит вам решить только часть проблем и точно не самую большую (их масштаб есть на графике выше). Пусть в вашей компании могут быть другие пропорции, если в вашей компании ошибки это действительно прогноз, то тогда нечего думать, надо его улучшать как можно быстрее. Но если вы уперлись в проблему, генерируемую количественным накоплением ошибок, то в данной точке нужно совершить качественный переход.Если бы я спросил людей, чего они хотят, они бы попросили более быструю лошадь. Г. Форд               Цитата из интернета, которую часто приписывают Генри ФордуЗавершить данный раздел я бы хотел небольшим итогом: несмотря на то, что задача планирования запасов является комплексной, на разных этапах ее все еще можно дробить на подзадачи. Отдавать рутину различным математическим алгоритмам, а финальную сложность собрать в работе эксперта. Но такое дробление лишь отложит проблему на время, до тех пор, пока логистика показывает общий положительный результат (например, за счет улучшений в hard). Если у вашей компании все хорошо, и она продолжает развитие, то вы вынуждены будете вернуться к задаче soft, когда достигните предела в возможностях физических улучшений.Новые этапы эволюцииК этому моменту уже понятно как дальше должна развиваться компания, нужно сделать следующий количественный переход от конфигурации «простое алгоритмами, сложное человеку» к конфигурации «всё алгоритмами, человеку контроль». Это существенный переход так как меняется роль специалиста с ключевой экспертной, на простую ремесленную. Но и у этого периода тоже есть этапы. Если решение о замене системы или ее существенной переработке принято заранее, то в данной точке происходит внедрение мульти-эшелонной системы управления запасами. Которая позволяет решать систему из матрицы уравнений с максимально достижимой точностью. Если вспомнить то, о чем я писал выше, как правило решение этой задачи – это перебор вариантов. А значит система позволяющая на огромном массиве делать перебор всех вариантов не всегда достижима. Используются методы и системы позволяющие найти «приближенное» решение через упрощение комбинаций. Такой шаг ведет к сокращению роли эксперта, в задачи которого входит настройка системы таким образом, чтобы она выдала результат, соответствующий целям компании. Например, компания хочет снизить оборотный капитал, риски списаний и готова пойти на некие упущенные продажи – снижаются настройки представленности товара и цели по сервису, либо наоборот задача на максимальные продажи и тогда все страховочные механизмы выкручиваются на максимум.Такая гибкость дает не только плюсы в бизнес метриках, но для нашего менеджера по функции (SCM) она дает возможность существенно облегчить жизнь hard логистике, генерируя экономию по-своему. Если напомнить то, что написано выше«он просматривает P&L, стремясь сократить стоимость своих затрат на обслуживание того потока, который он обязан через себя пропустить для обеспечения продаж»дальше шла речь о том, что он работает с самым атомарным состоянием данного потока – пробегом отборщика на складе. Но управление потоком в целом это тоже весьма большая опция. «Прикручивая» или «откручивая» посильнее движущийся поток в разных точках своей кровеносной системы, он может решать проблемы на глобальном уровне.К сожалению, такую возможность дает только полноценная система, не состоящая из экспертов. Практика в бизнесе такова, что используя метод «письменных распоряжений» управлять потоком нельзя, вы можете написать своим экспертам письмо «Ребята, у нас в таком-то регионе проблема, давайте подумаем как сократить там поток процентов на 30», но если ваша компания уже доросла до большого уровня сотрудники отвечающие за поток в этом регионе могут либо слишком затянуть гайки по всем направлениям, лишив вас и важного, и неважного товара. Либо вы дадите им свободу самим применять систему приоритетности и тогда они не будут сотрудничать. Есть известная в теории игр «дилемма заключенного», которая объясняет почему рациональные люди вольные делать выбор не всегда будут сотрудничать друг с другом в пользу других, даже если это в их интересах.Иллюстрация Midjourney по теме «Дилемма заключенного»При этом ни у кого из них не будет злого умысла, они искренне хотят помочь своему руководителю, также искренне они считают «свою часть» потока наиболее важной и считают, что высокие показатели именно по их части ведут к успеху всю компанию, пусть и «небольшим ущемлением» других категорий. С этим может даже попытаться побороться мидл-менеджмент, но за тысячами ежедневных решений очень сложно проследить. Зато беспристрастно принять те же тысячи решений основываясь на объективных показателях может система. Эксперту нужно лишь настроить базовые принципы этих ограничений в системе и алгоритмы сами найдут ближайшее решение, которое позволить исполнить волю руководителя. То есть внедрение системы это в первую очередь повышение управляемости.Если с моментом, когда мульти-эшелонную систему стоило внедрить менеджер затянул, оставив приоритет задачам soft ближе к тупику, то к системе управления запасами ставятся более амбициозные задачи. Кроме автоматизации процесса принятия решений на объективных метриках обычно от системы ждут и существенного улучшения в части экономики. Система должна уже не только принимать решения в рамках заданных ограничений, но и управлять самими ограничениями предлагая их наилучшее состояние. Это на несколько порядков повышает вариативность задачи, то есть существенно повышается количество комбинаций, которые нужно перебрать и выбрать решение с наилучшей производной функцией. При этом такой перебор нужно делать очень часто, в огромных компаниях несколько раз в день, а в небольших не реже чем раз в неделю.Заранее скажу, что в данный момент систем, которые в состоянии перебрать все варианты не существует просто в силу количества вариантов. Самые дорогие системы от ведущих вендоров работают над упрощением процесса перевода, разбивая задачу на этапы и в каждом этапе находя приближенное решение. Как правило работу с «экономикой» логистики решает даже отдельный модуль системы, который позволяет производить «Что, если?» анализ или модуль, который сам просчитывает синтетические варианты ограничений в виде симуляций. Но отсутствие точного решения не означает, что нельзя найти следующее решение, которое лучше текущего.Второй важной опцией данных модулей является возможность найти оптимум, а не жить в парадигме «лучше год к году», что, как правило, означает просто меньше тратить. После внедрения данной системы топ-менеджер отвечающий за данную функцию (SCM) может аргументировано показать, что текущее состояние затрат или другого KPI является обоснованным математически, указать какие именно товары или контрагенты приводят к росту и предложить работать над ограничениями уже в другом направлении, не стремиться их исполнить, а стремиться их пересмотреть в лучшую для компании сторону.В одном из примеров моей практике на этом этапе появился «логистический контракт» вкупе с «коммерческим контрактом». До этого с поставщиком продукции подписывался договор коммерческой дирекцией. Менеджеры, отвечающие за работу с поставщиками, работали в интересах своих показателей, поэтому соглашались на выгодную цену закупки, даже если за ней стояли невыгодные ограничения по логистике. Потому, что скидка в процент на выручке в сто миллионов — это ощутимая и оцифрованная экономия на один миллион, а тот факт, что этот миллион приводил к удорожанию логистики на три миллиона никто просчитать не мог. В итоге внедрения системы позволяющей моделировать, что будет при пересмотре условий, многие контракты стали подписываться по другой системе. В частности, без «визы», что данный сценарий не приводит к удорожанию затрат или что удорожание принято, контракт не двигался дальше по цепочке согласований. Работать это могло и в обратном направлении, когда поставщику предлагалось смягчить условия, а рост цены, который поставщик требовал взамен был заранее пре-согласован.А что там с прогнозом?В процессе прочтения уже должно быть понятно, что в многофакторной модели расчета приближенного варианта решения задачи по запасам, прогноз, безусловно, является одним из факторов влияющим на производный результат решения. Он имеет свой вес в общем результате довольно высокий если его сравнивать с факторами второго и третьего порядка, но в самой формуле, решение, которой надо найти заложена логика позволяющая балансировать ошибку прогноза за счет прочих переменных. Вернемся, к примеру с продажами:Вы ожидаете, что прогноз находится в вилке от 7 до 13 штук, на какой уровень вы будете ориентировать свою систему? Самый простой ответ – конечно 13 штук, ведь привези мы 12, есть риск потерять продажу одной штуки, но ответ не всегда так однозначен, по «другую сторону» складывается совершенно иная экономика и не всегда обеспечение 100% вероятных продаж это обеспечение самой эффективной затратной части.Что если фактические продажи по итогам данного прогноза будут 15 штук? Очевидно, что имея в своей основе неверные предпосылки решение сложной системы уравнений, которое мы выбрали не позволило нам обеспечить необходимый нам товар. Если мы берем только этот частный случай, то в действительности вы получили очень существенный объем недо-продаж (2 из 15 которые вы не привезли – это 13%, а если не был сделан страховой запас, то целых 30%). Однако в реальности эта разница скорее всего будет нулевой или в несколько раз меньше. Во-первых, прогноз всегда ошибается в обе стороны, поэтому недо-проданные куртки вполне себе компенсируют случайно пере-проданные, из-за зеркальной ошибки прогноза, пальто. Во-вторых, на товарный запас кроме прогноза влияют десятки других факторов, самый частый из них – округление потребности до уровня упаковки. Самым частым явлением решения задачи является округление вверх до упаковки, упаковок до паллета, паллеты до авто, авто до минимальной суммы заказа поставщику и так далее. 60-80% товарного ассортимента продается с такой маленькой скоростью, что генерируют огромный товарный запас. Когда ваша упаковка 10 штук, а скорость продаж 0,5 штуки в день ваша ошибка прогноза на 50% совершенно неважна на общих цифрах.Выше я уже приводил пример влияния ошибки прогноза на провал в доступности товара на полке в 2% от общего результата. Важно понимать, что это не упущенные продажи, а именно провал в доступности, который в ряде случаев просто приводит к замене продажи одного вида продукции на его полный аналог с точки зрения покупателя. В некоторых отраслях ритейла 2% доступности — это эквивалент 0,5% упущенных продаж, выведенных на статистике. А сколько ваша компания потеряла на том, что выбрала неверный ассортимент? А установила некорректную цену в промо? А на том, что вам не хватило сотрудников на отдельном складе? А на том, что ваш поставщик привез товар с опозданием на два дня по своей вине или по причине очереди на вашем складе? А завал паллеты, допущенный в отгрузке со склада на магазин.Это не означает, что прогноз не имеет значения, а означает что 0,5% упущенных в год продаж это конкретная сумма. Ну, например, ваша выручка 100 миллионов в год, 500 тысяч вы теряете в выручке. Если ваша прибыль 8%, то 40 тысяч чистого влияния на вашу прибыль. Рассматривайте эти 40 тысяч как эффект от проекта по улучшению прогноза. Ожидаемо ваши затраты на сам проект не должны превысить 60 тысяч, чтобы окупить за 1,5 года вложения и начать генерировать положительный эффект. Много можно улучшить на 60 тысяч? Каждый ответит для себя сам.И здесь вероятно стоит сказать о положительных факторах влияния прогноза. На самом деле прогноз позволяет не только избежать недо-продаж. Есть его влияние на избыточные запасы и на просрочку продукции, которая имеет небольшие сроки годности (фарма, продукты питания) тоже довольно велико. Они тоже должны стать частью модели расчета экономического эффекта от внедрения этой системы. Математика расчета этого эффекта похожа на ту, что выше, нужно лишь подставить нужные цифры, но с запасами и рисками просрочки все сложнее. Дело в том, что ваш целевой уровень запаса должен быть результатом моделирования всей системы уравнений. То есть имея оборачиваемость запаса в 30 дней вы не знаете много это или мало. Отраслевой бенчмарк тоже не даст много информации, например, у вашего конкурента 25 дней, а насколько сравнимы все ваши ограничения и насколько похожа ваша инфраструктура? Возможно, у него существенно отличается ассортимент, входная цена от поставщика хуже вашей, но зато нет ограничительных мер в договоре по типу «каждый заказ должен быть кратен автомобилю». Без внедрения системы позволяющей делать расчет плана на базе всех предпосылок вы не получите оценку целевого запаса и не сможете сравнить свой потенциал с текущим фактом.Попытка внедрить улучшенный прогноз на эмпирической оценке его значимости от эксперта приведет к тому, что все улучшения от внедрения более сложной математики будут просто теряться на выполнении других расчетов с учетом лимитов.Системы другого порядкаВажно сказать, что планирование запасов в структуре самой развитой компании ритейлера это лишь одна система из комплекса. Ее глобальная суть быть частью «правильного» для любого бизнеса процесса интегрированного бизнес-планирования (IBP). В этих процессах через системы планирования каждая функция декларирует свои намерения в виде оцифрованных показателей внутри этого комплекса, а система планирования запасов является частью отвечающий за операционную реализацию этого планирования просто как один из шагов.На примере это выглядит как-то так: сначала СЕО компании ставит цели на следующие годы, финансы их декомпозируют до всех бизнес метрик на ближайший год, маркетинг подгоняет стратегию на ближайшие кварталы, коммерция планирует ассортимент на пару сезонов вперед и так далее. В конце этой цепочки стоит управление запасами. Выстраивается такой состав, где каждый новый вагон — это отдельная функция, добавляющая в план свою ценность.Вольная фантазия на тему паровозика IBPРазрыв в процессе создания и исполнения плана приводит к тому, что последующие вагоны начинает разбрасывать в разные стороны и компания страдает от лишних шагов или убытков. Но если план изначально составлен гармонично и с участием всех служб в его обслуживании, то управление запасами существенно упрощается. В такой модели практически исключены ситуации с волатильностью загрузки складов и транспорта, минимизированы ситуации с неверными ценами или неправильно подобранным ассортиментом. Локальная точность прогноза имеет гораздо меньшее значение и управление запасами в первую очередь ориентируется на утвержденный план, нежели на предсказание ближайших продаж, разве что, работая с оглядкой на них. Этот процесс там называют по-разному, где-то это товарно-финансовое планирование, где-то S&OP/S&OE/MIOE, где-то может быть просто совокупность связных процессов планирования, а где-то настоящий IBP.В других компаниях применяют метод «как исторически сложилось», все кто находятся в начале состава не особо переживают, за тех, кто находится в «хвосте» поезда считая их проблемы не своими. Обычной проблемой для таких компаний является ввод неэффективных товарных позиций, подписание невыгодных контрактов, перегрузка магазинов акционными товарами и прочие проблемы разнонаправленных векторов, которые шатают состав из стороны в сторону. Последние вагоны, в числе которых находится управление запасами страдают от того, что к моменту выполнения своих задач получили все ошибки на предыдущих этапах и пытаются создать сверхсложные инструменты исправления ошибок «за других» или встраивают разного рода защиты «от входящих ошибок». Особенно такой проблемой страдают в компаниях, где доля «ре-активных» товаров очень высока, больше, чем 60 процентов, но это не обязательно так, есть разные примеры. Само собой работа такой компании будет постоянно сбиваться из-за отсутствия этого подхода внутри нее, а в некоторых отраслях без этого подхода компания просто не сможет выжить на конкурентном рынке. Пример отрасли, где про-активный подход жизненно необходим ввиду особенности продаваемого товара fashion, строительные материалы или мебель, но не только в них.Мы раньше выяснили что у директора по функции есть как минимум два инструмента, которые ему может дать подразделение Soft:управление потоком в разных точках позволяющих управлять экономикой за счет объемафакторное выделение вклада каждого товара и контракта в модель запасов, чтобы работать не внутри ограничений, а над их изменениямиТретьим инструментом директора по функции (SCM) является балансировка данного состава. Любой новый для компании процесс должен обладать внутренним спонсором чтобы запуститься и начать работать. Как правило внедрение нового процесса, тем более такого как совместное планирование функций, это большое количество ресурсов и времени, а также сложных внутренних согласований с учетом всей политики присущей крупной компании. Но лидировать внедрение этого процесса кто-то должен, а самыми заинтересованным лицами для этого являются те, кто находятся в «последних вагонах», потому что их трясет больше всего. Нужно убедить владельца каждой функции, включая СЕО, что именно от внедрения этого процесса компания приобретает наилучший эффект на логистику. Нужно создать или внедрить готовые инструменты по работе с ним, поддерживать процедурную часть процесса (такую как регулярные встречи).В моей практике такая работа заканчивалась успехом только в половине случаев. Довольно долго руководителю просто не хватает настойчивости и упорства во внедрении такой методики, и он опускает руки. Комитеты по планированию быстро становятся площадками куда не приходят лица принимающие решения, а значит на них не фиксируются нужные действия и не выполняются шаги по улучшению. Но если процесс внедрился, то эффект от этого невозможно недооценить, согласованные действия разных служб давали огромный эффект на коротком периоде. Важно понимать, что эффект планирования достигается не за счет того, что вы смогли решить задачу с огромным количеством вариантов к перебору – быстрее, а за счет того, что вы существенно сократили количество вариантов до небольшой группы приемлемых. То, что раньше казалось проблемой (завышенный запас в каком-то участке бизнеса) уже не проблема работы логистики, а незначительное отклонение от совместного плана компании, у которого уже есть факт фиксации в рамках аналитики, принятое решение об исправлении разными средствами и вы находитесь на пути реализации этого решения в ближайшем будущем.Резюмируя данную главу, хочу отобразить тройку основных инструментов, которыми пользуется директор по функции SCM.Инструменты директора по цепочкам поставокИнструмент для планирования решения задачи по управлению запасами – по сути говоря это сложная математическая модель позволяющая решить задачу с учетом ограничений не на базе «писем экспертам», а на базе оцифрованных логичных правил, которые система превратит в решение. Зачастую такую модель называют системой «Автозаказ», не совсем верно, но отражает суть.Результатом данной модели является возможность проанализировать решение, увидеть вклад каждого ограничения в общий результат, а также влияние на затраты и сформулировать правильные приоритеты – факторная аналитика запасов и доступности и инструменты для анализа «Что, если?». Обычно в своей основе они нуждаются в данных из предшествующего блокаИнструмент коммуникации для трансляции этих приоритетов внутри компании (или вовне) – портал или другой инструмент для совместного обсуждения плана и внесения в него правок направленных на достижение приоритетных целей. Прежде чем предложить принять решение коллегам из соседних функций, следует узнать какие ограничения являются лучшими и почему. Результатом работы данного инструмента или метода является новая постановка задач для системы из первого пункта, чем образуется некая цикличность в использовании этих инструментов.Как правило принятие совместных решений существенно упрощает саму задачу, которую надо решить. Гораздо проще сбалансировать входящий поток, если о проблемах в конкретном регионе задумываются все службы, а не только логистика в «хвосте» поезда.ПослесловиеВ рамках данной статьи я ставил себе конкретную цель, ответить на самый частый вопрос, который я слышу от CEO, IT-директоров или Директоров по функции SCM в процессе диалога об их проблемах с завышенными стоками или недо-продажами, который они формулируют так как я написал выше:Что надо сделать, чтобы повысить точность прогноза для заказов?Бывают и другие вариации, которые могут иметь отличия в формулировке, но их суть сводится к тому, что задачу все видят, как простое повышение точности прогноза. К сожалению, сбор всей информации об ответе на этот вопрос занял очень большой объем статьи и потребовал сведения всей доказательной базы в одну точку. Но тут уместен вопрос – что же ты за эксперт, если не можешь дать простой ответ на сложный вопрос? Это не так, простой ответ на этот вопрос возможен – необходимо внедрить три ключевых инструмента Soft логистики в ежедневную работу.Однако специфика ответа такова, что он подразумевает под собой большие инвестиции времени и ресурсов в решение. Такой дорогой в реализации ответ как правило сбивает с толку тех, кто его слышит и им кажется, что нет очевидной взаимосвязи между вопросом и ответом. Тому, кто его задает, вероятно, хочется услышать свой ответ, что-то в стиле «надо внедрить умную модель на машинном обучении» и эта волшебная таблетка решит все проблемы. При этом задающие вопросы это опытные топ менеджеры, которые понимают, что волшебных таблеток не существует. Таблетка, в виде умной модели на машинном обучении, частично снимет симптомы, но очаги воспалений в организме вашей ритейловой компании не исчезнут.Попробуйте задать вопрос врачу в стиле «у меня систематически болит желудок, какую таблетку выпить чтобы он никогда не болел?». Если вы понимаете суть ответа на вопрос, то плохой врач скажет выпейте обезболивающее, а хороший врач скажет:пройдите диагностику, завершите назначенный курс лечения, исправьте привычки питания.Сложность диалога с топ-менеджерами еще в том, что они говорят не с врачом, которым люди склонны доверять в силу отсутствия медицинских знаний и практики, а с другим менеджером. Это хороший повод поставить его компетенцию под сомнение, так как весь практический опыт, полученный участниками диалога, развивался в аналогичных ролях и похожих компаниях. Когда общаются два эксперта с незначительными отличиями в опыте позицию каждого надо выражать не короткими рекомендациями, а развернуто и с большим количеством промежуточных выводов. Промежуточные выводы так же нужны, чтобы применить все методы, рассмотренные в статье не полностью и сразу, а применимо к той стадии, на которой уже находится компаний, то есть рассматривать статью не как конкретный ответ, а как руководство для самооценки текущей ситуации и выработки плана ближайших действий. В конкретный момент времени может потребоваться срочно внедрять новую систему, а где-то обойтись простым использованием Excel и эксперта.В любой точке принятия решений стоит в первую очередь сформулировать вопрос корректно, а согласно известной истине, правильно сформулированный вопрос содержит в себе большую часть ответа.",
    "Обучение ИИ-моделей на облачных серверах: совместный проект РБК и Рег.ру": "Привет, Хабр! С вами Сергей Рыжков, руководитель департамента хостинга и профессиональных сервисов Рег.ру, и Александр Михеев, ML-engineer РБК. В этой статье расскажем, как мы автоматизировали процесс тегирования редакционных материалов РБК с помощью нейросети в облаке Рег.ру. О первых результатах нашего эксперимента читайте под катом.Навигация по тексту:→ Зачем начали обучать нейросеть→ Как проверяли гипотезу и проводили эксперименты\t↪ 1. Выбор ИИ-модели\t↪ 2. Эксперименты с обучением\t↪ 3. Тестирование оборудования\t↪ 4. Проверка гипотезы→ Результаты проектаЗачем начали обучать нейросетьТегирование материалов — неотъемлемая часть работы любой медиакомпании. В РБК ее выполняли вручную: редакторы прописывали 2–3 тега для каждого материала. В связи с этим возникало несколько трудностей: Количество тегов неконтролируемо увеличивалось — в основном разделе РБК до внедрения системы их набралось десятки тысяч.Появились дубли и синонимичные теги. Например, тег «сыр» можно написать по-разному: использовать заглавные буквы или кавычки. С точки зрения системы «Сыр», «сыр» и «сыры» — разные теги. Из-за большого числа тегов стало сложнее выбирать релевантные, и оставался риск пропустить другие подходящие.Тогда решили проверить гипотезу, насколько нейросеть потенциально может нивелировать человеческий фактор и позволит организовать процесс тегирования в полуавтоматическом режиме. Редактору можно будет не отвлекаться на поиск тегов, а только утверждать предложенные ИИ. В этом случае рутины станет меньше, и у сотрудников редакции появится время на по-настоящему важные задачи. Как проверяли гипотезу и проводили эксперименты1. Выбор ИИ-моделиПри выборе ИИ-модели одним из главных критериев было понимание русского языка. В РБК редакторы работают со сложно структурированными материалами на разные тематики, и чем лучше модель будет «понимать» русский язык, тем выше качество ее работы. За основу выбрали SOTA Open Source решение — архитектура T5. Это разработка Google, которую использовали для обучения модели FRED. Она обучалась на русском языке 35 дней на 160 графических процессорах V100 и 5 дней на 80 процессорах A100. Во время реализации проекта тестировали обе модели, и впоследствии перешли на оригинальную архитектуру T5 — большую мультиязычную модель MT5 от Google с более современным токенайзером.2. Эксперименты с обучением Начали с того, что разработали отдельный сервис для подготовки «чистого», более компактного списка на основе тех самых десятков тысяч тегов. В дальнейшем этот white list пригодится для создания датасета («корректные» теги + размеченные ими материалы), на основе которого будет обучаться модель.Первичный цикл обучения проводился на локальной видеокарте на мощностях РБК и составил 8 дней непрерывной работы. Нейросеть мгновенно подбирала теги, а процент ошибок был незначительный. Было ясно, что дообучение ИИ потребует дополнительных вычислительных ресурсов. Поэтому процесс решили перенести в облако с более мощным железом. Следующим шагом необходимо было подобрать оптимальную конфигурацию инфраструктуры, которая с одной стороны позволит сократить время на дообучение модели, а с другой — не будет избыточной по соотношению затраты/производительность. 3. Тестирование оборудования Специальной для этой задачи инженеры Рег.ру подготовили тестовый стенд с видеокартой А5000 на базе облачных серверов с GPU. Производительность стенда сравнили с двумя другими конфигурациями: Т4 и RTX 3090. В таблице ниже представлены результаты тестирования. Значения it/s —- это количество обрабатываемых материалов за один шаг в рамках эпохи, этот показатель отражает скорость обучения. По вертикали указано количество батчей в процессе параллельного выполнения задач обучения.Out — означает ошибку out of memory, то есть объема вычислительной памяти не хватило для размещения задачи. Подпись (gen) в модели — что обучение было на задачу text2text generation, а (pred) —- sequence classification.По итогу проведенных тестов видеокарта А5000 в облаке Рег.ру показала лучшие результаты. Она оснащена графической памятью объемом 24 ГБ и позволяет обрабатывать бо́льшие объемы данных без замедления работы. К тому же видеокарта поддерживает APICUDA и DirectML и совместима с большинством нейросетевых библиотек и приложений. 4. Проверка гипотезыТестирование автоматической разметки материалов тегами проводили на разных проектах РБК, включая «РБК Тренды», «РБК Отрасли» и «РБК Life». Суммарно это более 25 тысяч материалов. Для перепроверки использовали уже существующие материалы, размеченные редакторами, — публикации загружали в нейросеть и сравнивали результаты машины и человека. На основе полученных результатов делали выводы о том, насколько релевантные теги подобрала модель. Проведенный тест подтвердил работоспособность подхода. После успешного первичного тестирования и до внедрения в админку для публикации статей, ИИ-модель интегрировали в редакционные процессы «РБК Трендов» с помощью промежуточного решения в виде телеграм-бота. Результаты проектаПроцесс обучения ИИ-модели в облаке удалось уместить всего в 14-15 часов за один цикл обучения. Точность подбора тегов составила  99%, а скорость тегирования одного материала экстремального сократилась до 0,03 секунды. При этом различалось число тегов. Например, редактор ставил 3 тега, а ИИ-модель выдавала 7 тегов, среди которых в 99% случаев были исходные 3.  В таблице ниже представлены временные значения запуска ИИ-модели в сравнении в разных конфигурациях.Init — время загрузки модели в RAM / VRAM.Pred — время выполнения задачи до получения результатов. Значение времени является усредненным для 1 000 запущенных задач тегирования. Для оценки использовались два материала «РБК Трендов»: первый длиной ~200 токенов (по GPT4 токенайзеру), второй ~2000 токенов.В качестве наглядного примера рассмотрим демо в «РБК Трендах». Редактор указал 4 тега для материала, мы попросили ИИ-модель предсказать 6 тегов по тексту. Ниже представлены результаты двух моделей, обученных на 18 и 30 эпох, — для сравнения. В результате все 4 редакционных тега вторая модель предсказала верно.Что касается возможных ошибок в работе нейросети, то безусловно такую вероятность нельзя не учитывать, поэтому мы говорим не про автоматическое, а про автоматизированное решение. То есть нейросеть подбирает теги, а редактор визирует и либо принимает, либо правит их. Это позволяет исключить возможные ошибки нейросети, но при этом сохранить все преимущества, которые дал проект.В ходе эксперимента мы поняли и перспективы дальнейшего развития. Нейросеть может позволить давать более персонифицированные рекомендации, улучшить пользовательский опыт и повысить вовлеченность аудитории. Но это нас ждет еще впереди.",
    "Учимся (не) проходить финалы на стажировку в Яндекс": "Лирическое отступлениеМне 32 года из которых около трех лет активно изучаю python. Я являюсь тем самым \"в IT`шником\", который решил что у него достаточно сил чтобы побороться со студентами за место на стажировку в Яндексе. Подготовка к Яндексу заняла более полу года. К тому времени у меня завершенная стажировка в стартапе, пара проектов на заказ, несколько прочитанных книг и несколько учебных проектов.Получив фидбек об успешном прохождении второй алгоритмической секции я точно не ожидал, что впереди 8 месяцев отказов и практически отсутствие интереса ко мне среди команд.Дисклеймер: вся информация является моим личным мнением, отнеситесь к ней соответственно.Общая информация о финалахСобеседования с командами проходят по следующей схеме:Ты рассказываешь о себе, своем опытеИнтервьюер задает тебе интересующие его вопросы: по твоему опыту, техническим знаниям, могут дать задачи на подумать либо покодить, твоей готовности к работе, мотивации и тдПредставитель команды рассказывает о своем проекте и иногда условиям прохождения стажировки у нихТы задаешь интересующие тебя вопросы интервьюеру Чем больше у тебя отказов и хуже отзывы в начале, тем меньше команд хотят приглашать тебя на собеседование, даже если твои фидбеки в итоге становятся хорошими. Получив первые пять отказов я узнал что можно было отказываться от собеседований с командами, которые мне были не интересны. Резюмирую: не интересна команда - отказываемся от собеседования с ней. Экономим своё время, время команд, не собираем лишние отказы и лучше готовимся к собеседованиямСобеседованияВсем новоприбывшим обычно предлагают сразу три команды. Я еще не знал что можно отказываться от собеседований, поэтому соглашался на всё. Здесь я допустил ошибку - поставил три собеседования один за другим, а когда получил сразу три фидбека то был неприятно удивлен результатами. Резюмирую: ставьте собеседования с интервалом минимум 2 дня, чтобы вы могли получить фидбек и проработать ошибки из него до следующего собеседования.Первая командаЯ полный уверенности начинаю рассказ \"о себе\", но оказалось что информации не достаточно - я не помнил нюансов проекта прошедшей стажировки. Это вылилось в то, что начали задавать вопросы по проекту о котором я мало что помнил, а некоторые нюансы стажировки и вовсе было стыдно озвучивать. В итоге я пытался выкручиваться давая размытые ответы, а мой потенциальный ментор пытался выяснить что же было на самом деле. Получился своеобразный допрос, в котором я явно выводил из себя интервьюера. Далее спрашивали иерархию исключений, но так как в точности её не помнил, то рассказал в общих чертах. Интересовались как я вижу своё развитие, на что ответил: \"мне интересен путь в сторону архитектуры, нежели управления людьми\". От себя добавил, что не хотел бы работать с \"высшей математикой\" (подразумевал ML, DS и подобные), потому что у меня нет \"глубокой математической базы\". Я не против ковыряться в алгоритмах, но если мне придется выполнять половину работы (либо всю) как ML - из этого ничего хорошего не выйдет.Фидбек\"Кандидат достаточно спорный. С одной стороны, очень уверен в себе и знает, чего хочет добиться. С другой - при своём небольшом опыте самоуверенность стреляет ему в ногу. Софты: были какие-то странные ответы на вопросы, уходящие совсем в сторону. Послушал рассказ про задачи для стажёров, вопросы по ним задавал корректные, но ощущения достигнутого понимания не было - кандидат просто решил забить, кажется. Техника: не успели долго поболтать, но что-то рассказывал про предыдущую стажировку (django и fastAPI) и телеграмного бота, а на вопросы по ходу дела отвечал сносно. При этом я бы посоветовал следующему интервьюеру тут углубиться - есть подозрение, что я просто не копал глубоко. Мотивация: хочет \"архитектурить\", но вкладывает в это понятие явно не то, что я. Почему-то очень настороженно относится к задачам, где нужно чуть поломать голову (алгоритмы, математика) - сразу уходит в защиту \"я не специалист, я не могу\". Хочет попасть в большую компанию в России, т.к. в Беларуси, судя по рассказу, сложно найти айтишную работу и \"кругом одни джависты, а я - питонист\", а за рубежом язык знать надо.\"ВыводыБыть прощеЛучше подготовить рассказ \"о себе\" и готовность ответить на все вопросы по прошлому опытуНе говорить то, чего у тебя не спрашивают, в том числе что тебе не нравится / с чем не хотел бы работатьПовторить иерархию исключенийВторая командаНачало стандартное - представление \"о себе\". После этого я сказал что мне не интересно направление команд (я еще не знал что можно отказывать до собеседования), при этом я не представлял чем вообще занимается команда даже из описания. Далее своеобразный блиц опрос по многопоточности / многопроцессорности, как это работает; в чем отличие asyncio и многопоточности на глубоком уровне; как работает / устроен GIL в python и для чего он нужен. Спросили теорию графов, где используются - я ответил что-то про социальные сети и какие-то примеры из того что мог вспомнить, но хотели услышать что используются в импортах модулей и тп.Фидбек\"В общении проблем не было, кандидат рассказал про свой опыт (писал tg бота (FastAPI) и бекенд на Django), поспрашивали про некотрые тонкости Python(тут в общем ок), параллельное и асинхронное программирование, БД, в ответах плавал, теоритеческой базы тут не хватает, есть практика, но почему именно так работает кандидат не знает. Год назад пробовал читать книги, но понял, что без практики толку мало, потому ушел в практику, а чтение книг забросил. Из наших комманд предпочтений не было и вообще сначала сказал, что ему не интересна инфраструктура и хочет продуктовой разработки, писать код, а вот деплой/алерты/сети ему не интересны. От стажировки ожидает, что попадет в штат и готов вложиться в нее по полной.\"ВыводыЛучше изучить асинхронность и параллельность \"под капотом\"Если о чем-то не спрашивают, не стоит это говоритьТретья командаКак обычно начинаю с рассказа \"о себе\". После этого дали задачу на реализацию переноса большого количества данных из одной базы в другую. Я рассказал что можно использовать генераторы (пришло в голову т.к. это экономит память), пытался вспомнить про OFFSET в SQL, но забыл как называется функция и объяснил это своими словами. Данный вариант не особо устроил интервьюера и он задал уточняющий вопрос - \"как я буду делать выборку данных из БД для прошлой задачи?\". Тут я предложу вам подумать, как будете готовы читайте ответ.ОтветПо UUID невозможно делать сортировку, поэтому необходимо отсортировать данные по времени создания и уже из получившегося результата пачками через LIMIT и OFFSET их забирать.Как я понял потом, мне необходимо было знать что первичные ключи хранятся в виде UUID, я же предлагал решение в виде численных первичных ключей. Так же я должен был знать что данные в базе перезаписываются.Вопросов по чистому SQL и работал ли я с ним не было.Фидбек\"Спорный кандидат. Самоучка. В прошлом опыт был в виде телеграмм бота и стажировки в стартапе. С базами работал только через orm. По ощущениям, есть знания языка и алгоритмов, остальное выглядит поверхностно. От стажировки ждет, что попадет в штат. Хочет в Москву\"ВыводыПочитать про UUIDПовторить SQLПолучив сразу три фидбека я провел работу над ошибками в рассказе \"о себе\", а так же подтянул остальную теорию.Четвертую команду мне искали около двух недель после получения фидбеков.Четвертая командаПосле краткого рассказа о своём опыте я спросил - \"рассказывать, чем я занимался на проекте стажировки более подробно?\", на что мне ответили - \"не надо\". Дальше был вопрос \"что было самым сложным на стажировке\", на что ответил - \"в начале стажировки пришлось изменять структуру проекта, попутно разбираясь в нем\". Были вопросы по SQL, точнее попросили в онлайн‑редакторе написать пару запросов на создание, объединение таблиц и выборку из них. Тут я неправильно выбрал столбец для подсчета и путал названия JOIN`ов. Интервьюер спрашивал об удаленке, так как у них есть данный вариант, но я сказал что рассматриваю только офис. В конце я задал вопросы про дежурства в данной команде и то, как в проекте взаимодействует бэкенд с фронтендом.Фидбек\"Из интересного:в чате на fastapi хотел отрефакторить код. недостатки: sql-запросы прямо в ручкахбыло 2 репы с чатом и календарем Простой опросник по SQL inner join называет cross join В целом норм, не знает некоторые конструкции типа FILTER в COUNT Пообщались по проект. К задавал вопросы про удаленку, дежурства. Кажется, К пытался срезать углы (например, спрашивал, что бэк только предоставляет API, или может еще генерирует html-страницы) К себе брать не готов. Интересного из К ничего вытащить не смог. На текущих проектах часто занимался непонятным рефакторингом. Нет понимания, как будет работать в команде и как общаться с заказчиками\"ВыводыПосмотреть конструкции FILTER в COUNT и перестать путать названия JOIN`овДоработать рассказ \"о себе\", чтобы в кратком изложении можно было донести максимум небходимой информациюНе задавать вопросов по условиям работы в командеПятую команду мне искали неделю после получения фидбека от четвертой команды. Пятая команда\"О себе\" с последующим переходом к вопросам о том, что такое хэшсет, как работает / устроен, писал ли я тесты и работал ли с asyncio. Далее вопрос о том, чего я хочу от стажировки, на что ответил - просто хочу работать (сказывалось состояние усталости от постоянных отказов). На уточняющие вопросы по данной теме отвечал в таком же стиле. Вопросов по БД и SQL не было.Фидбек\"На заказ разработал бота на python-telegram-bot для публикации сообщений в каналы, после стажировка в стартапе, проект - фриланс биржа занимался доработкой rest ручек монолита и чата в команде из 3 человек, синхронное апи чата - fast api, монолит django-rest, сообщения - через веб-сокеты - не изменял. есть базовое знание python асинхронное программирование в python - только теория не сталкивался с автоматическими тестами базы - знает select/join/group by, но в ответах не уверен. стажировку хочет проходит очно, с переездом в мск. на стажировке - работать работу, под присмотром ментора, с обратной связью для быстрого обучения. для меня - пограничный кандидат, харды для стажера ок, в целом в общении особых проблем нет, но стиль общения - размытые и краткие ответы на вопросы по предыдущим проектам, интересам, скилам, надо постоянно вести и вытаскивать вопросами информацию отталкивает. Пока к себе брать не готов\"ВыводыИзучить asyncio и pytest минимум на базовом уровнеДавать развернутые ответы на вопросыОтвечать подготовленным ответами на вопросы \"что хочешь от стажировки, почему мы и тд\"Академический отпускПосле получения пятого отказа мне сказали что желающих команд для меня сейчас нет и мне стоит лучше подготовиться, отправив на полу годовое самостоятельное \"повышение квалификации\". Я еще раз просмотрел все проблемы прошлых собеседований, сделал работу над ошибками и доработал рассказ \"о себе\". Так же на базовом уровне изучил и поработал с asyncio и pytest.Спустя 2.5 месяца ко мне возвращается рекрутер и предлагает продолжить поиск команд, на что я соглашаюсь. В течении следущих двух месяцев мне предлагают четыре команды, с одной из которых я соглашаюсь на собеседоване.Немного про отказы командам. Я не ищу идеальную команду, но если мне не хватит недели подготовки чтобы соответствовать основным требованиям команды - я отказываю. Мне например сложно за неделю изучить с нуля C++ и ML на базовом уровне.Шестая командаВ начале собеседования интервьюер говорит - \"это будет легкое для меня собеседование\". Дальше уже отточенный рассказ \"о себе\". Спросили про asyncio: как устроен, зачем нужен; когда стоит использовать asyncio, а когда многопоточность; про брокеры сообщений; типы БД и где какие использовать; про шардирование и репликацию (тут в голове всё перемешалось и временами путал термины). Спрашивали про многопроцессорность - \"как можно работать с CPU задачами\", на что ответил - \"можно распараллеливать по процессам, использовать технологии вроде map reduce и брокеры сообщений\". Возможно я не правильно понял вопрос. Из нюансов хотел отметить - я больше одного раза говорил что на прошлой стажировке была сложная задача, где приходилось самому разбираться и помочь с ней мне никто не мог (мол мне может понадобиться помощь). Так же после того как ответил что с брокерами не работал, интервьюер сказал - \"обычно разработчики изучают смежные технологии\" и продолжил свой рассказ, а я не успел отработать \"возражение\". В конце я спросил какой код предпочтителен в команде, \"чистый\", либо \"быстрый\".Фидбек не пришел в первые два дня, поэтому я понял что ситуация нестандартная. Я попросил рекрутера поставить поиск команд на паузу пока не будет ответа от данной команды. Спустя 9 дней я получил фидбек и отказ.ФидбекОбщее: • есть опыт коммерческой разработки (5 месяцев, в основном fastpai и django) • на одном из проектов писал телеграмм бота (бот-админ для публикации постов в каналы) • представляет как работает asyncio и есть опыт, про многопоточность и GIL в питоне тоже понимает, а вот с многопроцессорностью что-то не очень • слышал про брокеры сообщений, но без опыта (и прям совсем только слышал) • имеет хорошее представление, о том какие бд бывают и в каких задачах могут быть полезны (kv/document oriented/графовые/колоночные) • немного абстрактно пообщались про шардирование и репликацию, конечно не очень глубокие знания во всем этом, но где-то что-то слышал и общее представление местами имеетсяВпечатление: Кандидат достаточно хороший, есть опыт в бэке. Но у меня сложилось впечатление, что слишком много уделяет времени \"красоте кода\" (я был бы и рад такому Кандидату, но у нас тяжело будет с таким подходом). Не сошлись по софтам скорее, есть ощущение, что тяжело погружается в новые области. К себе взять не готов, но другим командам советую посмотретьВыводыПочитать про шардирование и репликациюОзнакомиться с брокерами сообщенийНе задавать вопросов, которые касаются условий работы в команде (в данном случае про чистоту кода)Не давить на жалось, повторяя что тебе \"надоело беспросветно тащить всё на себе без какой-либо помощи\". Достаточно спросить кто будет твоим ментором и как часто вы будете с ним созваниватьсяДаже если ты попал в \"шорт лист\" команды, не стоит прекращать поиск / собеседования с другими командами. Принимать решение стоит тогда, когда у тебя есть фактический офер от команд(ы)Через две недели мне находят еще одну команду, от которой я отказываюсь. Скоро будет месяц как я нахожусь в поиске очередной командыИтогЯ пока не собираюсь сдаваться, хотя силы уже не те что в начале.Общие выводыСоглашайтесь на собеседование только с интересующей вас командой. Перед тем как дать свой ответ - поищите в интернете информацию о ней, если это необходимо. Есть сомнения - один раз можете согласиться на такую команду ради опыта, но больше не советую. Не тратьте своё и время команды зря, ну и не забывайте про отказыСтавьте собеседования с командами с интервалом минимум два дня, чтобы вы могли получить фидбек от прошлой команды и проработать ошибки до следующего собеседованияНе стоит останавливать поиск других команд если вы попали в \"шорт лист\" какой-либо команды (отсутствие фидбека в течении 3 дней после собеседования). Принимайте решение только после получения офера от команд(ы)На собеседовании будьте \"проще\", общайтесь дружелюбно на \"ты\" (обычно интервьюеры делают это первыми в начале собеседования)Не стоит шутить на собеседовании - у всех разное чувство юмораПодготовьте краткий рассказ о себе, в котором будет максимум информации о вас и ваших проектах, которая может быть интересна интервьюеру. Будьте готовы ответить на все вопросы по вашим проектам, как будто вы это техническая документацияВам необходимо знать на хорошем уровне всё, что находится в road map вашей специальности до уровня middle+, а всё что выше - по одной статье. Никогда не знаешь что могут спросить (я хочу чтобы это была просто шутка)Никогда не говорите что чего-то не знаете. Отвечаем на это развернуто по схеме: где и в каком объеме встречался с данной темой, почему не может ответить на этот вопрос сейчас. Пример: \"читал когда-то об этом на заборе, но не знал что это может мне пригодиться\"Отвечаем на вопросы развернутоНе говорим того, чего не спрашивают - это потенциально может вас дискредитировать. Примеры: \"я люблю кофе\" - \"будет целыми днями пить кофе и ничего не делать\"; \"я общительный и коммуникабельный\" - \"мало того что днями будет пить кофе и ничего не делать, так еще и других будет постоянно отвлекать своими разговорами\"Интересуемся о проекте в общих чертах (мы же соглашаемся только на интересные нам команды). Вы можете поискать информацию о данном проекте (либо схожих) в интернете и задать вопросы из технических требований. Примеры: какую нагрузку выдерживает, какой аптайм, какая скорость и тдНе задавайте вопросы про условия работы в команде на собеседовании. Стандартные условия стажировки - фултайм офис с задачами, во время которых теряешь счет времени и регулярные дежурства. Если у вас специфичные требования - просим рекрутера связаться с командой и узнать ответ на эти вопросы у команды. Команда может предоставить такие условия - соглашаемся на собеседование. Не тратим своё время и время команды зряЗаранее готовим ответы на вопросы: почему именно эта команда, что хотите от стажировки, чего хотите добиться, какие были сложности / неудачи в прошлых проектах и тд. Про сложности и проблемы отвечаем в духе \"было сложно, но разобрался, сделал такие-то выводы и стало проще / таких ошибок больше не допускаю\"Расскажите о том что изучаете либо изучали в последнее время. Если это будет \"созвучно\" с требованиями команды - супер. Если ничего не изучаете - пора начинать",
    "Как реализовывать IT услуги из России в ЕС/США, оставаясь незамечанным для санкций и активистов?": "Пример №1. Вы – владелец IT компании в России и оказываете услуги заказчикам/лицензиатам в ЕС или США.  Есть действующие заказчики и две проблемы:  (а) не проходят платежи в Россию и (б) есть желание скрыть владение российской компанией «на всякий случай».Пример №2. Вы – владелец компании, занимающейся автоматизацией производств. Поставщики оборудования из ЕС, а покупатели в России.  Вы не в сакционных списках, как и ваши покупатели, но неизвестные «активисты» пишут на мэйл и интересуется тем, как же вы закупаете из Европы оборудование и ввозите его в Россию. Такие «письма счастья» приходят по итогу анализа открытых данных из ЕГРЮЛ и купленных в даркнете баз таможенной службы. Цели учредителей в обоих кейса:  (а) продолжить оказывать услуги по поддержке ПО и перепродаже лицензий на рынки ЕС и США из России, продолжить закупку оборудования и (б) скрыть связь владения российской компанией. Первая цель решается либо через открытие транзитного счета юр. лица в Казахстане (описано здесь), либо через открытие филиала российского юр. лица в Казахстане. Вторая решается двумя путями Самурайский – вы создаете ТОО в Казахстане/ОООшку в Узбекистане и ставите ее главой номинала. Не самый надежный вариант, поскольку гражданское законодательство Казахстана даже не предусматривает понятия «номинальный директор» и не регулирует его ответственность перед бенефициаром. Номинал владеет «правом первой подписи», т.е. имеет доступ к банковским счетам и вправе распоряжаться денежными средствами. Проще говоря, ему ничто не мешает взять деньги и исчезнуть. А посредники, предоставляющие услуги номинальных директоров, никаких гарантий погашения убытков вам не дадут.  Разумный – вы выходите из состава своей ООО через корпоративный договор.  Корпдоговор – это договор между участниками ООО и/или третьими лицами о порядке управления компанией (см. ссылку). Он прекрасен тем, что является конфиденциальным и даже в налоговую его не сдают.  Вы выходите из состава соучредителей, оставляя на этой позиции номинала. Далее, заключаете с номиналом корпоративный договор и/или договор конвертируемого займа в пользу компании. В случае нарушения порядка управления компанией номиналу грозят штрафы по корпоративному договору, а конвертируемый займ позволит мгновенно вернуть права на долю в ООО, если «что-то пойдет не так». В ухом остатке, у вас фактический контроль над ООО при полном отсутствии данных о вас в ЕГРЮЛ.Рад помочь по вопросам сделок, контрактов, корпоративных отношений и судебных споров в РФ, Казахстане и международных арбитражах. Искренне Ваш, юридический консультантВасюков Иван@IvanLawyer1990\"Бизнес в Казахстане\", \"Московский юрист в Казахстане\", \"Правовое сопровождение\", \"Релокация бизнеса в Казахстан и Центральную Азию\".",
    "Что такое podman kube и как он может быть полезен для работы в rootless режиме": "При развертывании пары десятков контейнеров в Podman в rootless-режиме мы внезапно обнаружили, что они не могут одновременно использовать одни и те же порты, как это обычно работает при использовании Docker.Решений несколько, но в рамках наложенных ограничений стандартные варианты не подходили. В итоге мы обратились к функционалу Podman Kube, который помог нам решить эту проблему. Подробнее о том, как это работает, и чем может быть полезно, ниже..Как простая задачка с контейнерами внезапно стала непростой  У нас много заказчиков, которым мы оказываем услуги DevOps. В какой-то момент для одной поддерживаемой нами облачной платформы потребовалось внедрить стороннее приложение – продвинутый чат-бот. Приложение разрабатывалось внешней организацией и поставлялось «как есть» без доступа к исходному коду. Архитектурно оно представляло собой порядка двух десятков Docker-контейнеров, разворачивающихся в Docker с помощью compose-файла. Именно в таком виде код для развертывания и сам дистрибутив передаются для установки. Из базовых наработок по автоматизации, предоставляемых вендором –  только bash-скрипты для загрузки образов и docker-compose файл. В качестве ограничений – утвержденный заказчиком стек инструментов, где для контейнерной оркестрации следовало использовать Podman или Kubernetes.Kubernetes мы откинули сразу, поскольку потребовалось бы очень много времени на адаптацию приложения, а его не было ни у нас, ни у заказчика, ни у вендора. Поэтому выбор сократился до безальтернативного Podman.Казалось бы, в Podman мы точно так же, как и в Docker, можем поставить podman-compose, а при желании даже docker-compose, который будет работать с Podman и запускать все в исходном виде – в том, как это предоставляется вендором. Но нам мешало дополнительное строгое требование заказчика – использовать Podman только в rootless-режиме. То есть, для работы инженеру предоставляется заранее подготовленная виртуальная машина с Podman, и работать с ним можно только под непривилегированным пользователем.Далее мы столкнулись с рядом  проблем.Первая – в Podman иная реализация разрешения имен контейнеров. Суть в том, что при создании виртуальной сети для контейнеров DNS-резолвером выступает шлюз этой сети. Если создать другую сеть, то будет другой шлюз и, соответственно, другой адрес резолвера.На что это влияет? Например, если у вас в конфигурации nginx присутствуют бэкенды, резолв имен которых опирается на имена контейнеров, то в директиве resolver следует менять адрес на шлюз вашей Podman-сети.Например, ниже конфигурация nginx:  server {\n  server_name _;\n  listen 80 default_server;\n  # optional SSL\n  include ssl*.conf;\n …\n  # global platform timeouts\n…\n  resolver <шлюз podman сети>;\n  # variables for the the proxy_pass forcing NGINX to re‑resolve the domain name when its TTL expires\n  set $front http://front.dns.podman:80;\n ...\n ...\n}\nВ директиве resolver требуется указать адрес gateway, который мы получаем из команды podman network inspect <network>.Для docker это обычно 127.0.0.11).Также при указании фронтов рекомендуется добавлять домен dns.podman, чтобы избежать проблем с разрешением имен при обращении друг к другу через nginx.  Важно помнить, что в случае, когда используется CNI для настройки сетевого окружения контейнеров, необходимо убедиться, что установлены все требуемые плагины. Например, плагин dnsname отвечает за работу DNS в виртуальной podman-сети. При этом зачастую из коробки этот плагин не подключен к default сети, и требуется создать новую podman сеть, чтобы в ней заработал dnsname.Далее  начались проблемы, связанные непосредственно с rootless-режимом. Доступ к привилегированным портам в rootless-режимеПубликация портов для контейнеров без root-прав возможна только для «высоких портов». Все порты ниже 1024 являются привилегированными и не могут быть использованы для публикации.Обычно проблема решается разрешением на изменение непривилегированных портов с помощью команды sysctl net.ipv4.ip_unprivileged_port_start=80как это описано в решении от RedHat.После этого, казалось бы, уже все должно было заработать, однако появилась другая проблема, которая заставила нас погрузиться глубже в теорию. При запуске контейнеров в непривилегированном режиме с помощью обычного compose они конфликтуют за одинаковые порты, которые используются сервисами, например порт 80.  Конфликт портов  Суть в том, что в привычном нам Docker контейнеры работают в режиме bridge networking. В нем каждый микросервис может сделать bind 0.0.0.0:80 внутри контейнера, и контейнер становится доступен в Docker-сети как <имя контейнера>:80. При этом “0.0.0.0” внутри контейнера – это ip-адрес <имя контейнера> (или имя сервиса) внутри виртуальной контейнерной подсети, то есть это не IP самого хоста. Следовательно, в Docker в привычном режиме bridge networking конфликта за порт 80 между контейнерами нет.Но Podman использует другой подход. При использовании rootless-доступа настройка сети происходит автоматически с помощью режима сети slirp4netns, который создает изолированный сетевой стек, позволяющий подключаться к сети изнутри контейнера и привязывать определенные порты контейнера к тем портам, которые доступны для пользователя на самом хосте. Иными словами slirp4netns создает туннель от хоста в контейнер для пересылки трафика. С помощью slirp4netns контейнеры полностью изолированы друг от друга. Виртуальной сети нет, поэтому для связи друг с другом контейнеры могут использовать проброс портов на хостовую систему - port mapping, и в этом месте как раз возникает проблема, что тот или иной порт уже занят первым стартовавшим контейнером. Или же их можно поместить в один Pod, где они будут использовать одно и то же сетевое пространство имен, где также будет конфликт за порты.В описании от RedHat это объясняется следующим образом:   When using Podman as a rootless user, the network setup is automatic. Technically, the container itself does not have an IP address, because without root privileges, network device association cannot be achieved. If you're running Podman without root, it can only use the network mode slirp4netns, which will create an isolated network stack so that you can connect to the internet from the inside of your container and bind certain ports of your container to the user-bindable ports on you host, but nothing more. To be able to select the network mode bridged, which does exactly what I need, you'll have to run Podman as root.Или тоже самое объяснение из документации Podman на GitHub:One of the drawbacks of slirp4netns is that the containers are completely isolated from each other. Unlike the bridge approach, there is no virtual network. For containers to communicate with each other, they can use the port mappings with the host system, or they can be put into a Pod where they share the same network namespace.Примерно так это можно проиллюстрировать схематически:Небольшое отступление про slirp4nets.Slirp4netns — это сетевой инструмент, используемый контейнерными средами исполнения для обеспечения сетевого подключения контейнеров без необходимости повышения привилегий.Slirp — это, изначально, программа, эмулирующая подключение PPP, SLIP или CSLIP к Интернет с использованием учетной записи текстовой оболочки. Это уже давно legacy инструмент. Еще в 90х годах прошлого столетия студенты из США активно использовали slirp, чтобы серфить в сети через выдаваемые университетами dial-up shell-терминалы. И в сети до сих пор можно найти эти инструкции. Однако возможности slirp до сих пор активно используются как в QEMU, так и для сетевой работы контейнеров, особенно для непривилегированных сетевых пространств имен.Но получается, что этот режим крайне неудобен в случае, когда разные контейнеры используют изнутри одни и те же порты.  Поскольку контейнеры работают в одном и том же пространстве имен сети, они делят один и тот же эмулированный сетевой стек, что приводит к конфликту портов внутри их изолированной сети.А режим сети bridged доступен только при запуске Podman с root доступом.Варианты решения ситуации с портамиМы сформулировали четыре варианта решения проблемы:Заменить rootless Podman на rootless Docker, который не имеет таких ограничений. Использовать Podman в привилегированном режиме.Изменить порты микросервисов, чтобы они отличались от порта 80.Обойти ограничение rootless Podman путем распределения контейнеров на:разные виртуальные машиныразные виртуальные сетиразные подыПервые два варианта не проходили по административным ограничениям, установленным заказчиком. Третий вариант слишком ресурсозатратный и во многом бессмысленный. В итоге нужно было думать, как изолировать контейнеры, конкурирующие за 80-й порт. Разделение на разные виртуальные машины — слишком ресурсозатратно.Разделение на сети вызывает сразу много вопросов, учитывая, что в slirp4netns режиме мы не оперируем сетями в принципе. Даже если их создать отдельно, то как будет работать связь между контейнерами в разных сетях, как будет работать разрешение имен, ведь получится, что на каждую сеть будет свой DNS resolver адрес?И тут на помощь приходит такой функционал Podman, как Podman Kube.Podman Kube теорияПро функцию Podman Kube статей мало, и описанных случаев применения на практике в реальных кейсах мне тоже не встретилось. И даже если спросить любую GPT-модель про основные команды Podman, в ответе не найдем ничего про Podman kube. Возможно, для большинства ситуаций эта возможность Podman выглядит избыточной, но нам она очень помогла.Попробуем разобраться, как это работает.В теории, когда мы создаем несколько подов, каждый под имеет свой собственный сетевой namespace. Это обеспечивает базовую изоляцию сетевого стека для каждого пода.Важной особенностью оказалось то, что для коммуникации между подами при запуске через kube play даже в непривилегированном (rootless) режиме Podman подключает поды к bridged-сети. Эта сеть может быть создана заранее, либо Podman создает ее автоматически. Таким образом, если специально не использовать хостовую сеть (параметр network_mode:host), создается новый сетевой стек bridged, что делает возможным взаимодействие между подами.При этом, хотя сеть и называется bridge, в rootless-режиме она реализуется как виртуальная сеть в пользовательском пространстве с помощью slirp4netns и CNI плагинов. Это позволяет создавать изолированные сетевые окружения для контейнеров без привилегий root, обеспечивая при этом функциональность, похожую на сетевой мост.​​​​​​​​ ​Таким образом, каждый под изолирован в своем сетевом namespace, но при этом все они подключены к одной виртуальной сети, обслуживаемой одним процессом slirp4netns, что позволяет использовать в разных подах одни и те же порты.​​​​​​​​На узле мы можем это увидеть, например, с помощью определенных команд. Начнем с вывода списка сетевых namespaces:# sudo lsns -t net \n        NS TYPE NPROCS   PID USER      NETNSID NSFS COMMAND\n4026531840 net     290     1 root   unassigned      /sbin/init\n4026532564 net       8 15259 podman unassigned      /catatonit -P\n…\n4026532635 net       1 15242 podman unassigned      /usr/sbin/dnsmasq -u root --conf-file=/run/user/915/containers/cni/dnsname/...\nЗдесь мы можем определить, что NS 15242 принадлежит процессу slirp4netns, в котором настраивается сетевое окружение с помощью CNI плагинов.Смотрим, что делает сам slirp4netns:# ps aux |grep slirp4netns \npodman   15173  0.1  0.1  37428 35512 ?        S    Jun11  76:02 /usr/bin/slirp4netns --disable-host-loopback --mtu=65520 --enable-sandbox --enable-seccomp --enable-ipv6 -c -r 3 --netns-type=path /run/user/915/netns/rootless-netns-5df09f647b449af857cc tap0С помощью этой команды можно ходить по разным нейспейсам и смотреть сетевые настройки: # sudo nsenter -t <ns_pid> -n ip a В namespaces, принадлежащих подам, мы увидим только lo и eth0 порты. В namespace, принадлежащему процессу slirp4netns, мы увидим tap0, cni-podman0 и veth пары с соответствующими link-netnsid. Также в namespace slirp4netns можно проверить правила iptables, созданные для реализации NAT.1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n   …\n2: tap0: <BROADCAST,UP,LOWER_UP> mtu 65520 qdisc pfifo_fast state UNKNOWN group default qlen 1000\n    ..\n    inet 10.0.2.100/24 brd 10.0.2.255 scope global tap0\n    3: cni-podman0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000\n    …\n    inet 10.89.0.1/24 brd 10.89.0.255 scope global cni-podman0\n       …\n4: veth3c23371b@if2: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master cni-podman0 state UP group default\n    link/ether <mac_address> link-netnsid 0\n   …\n5: veth71b41f66@if2: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master cni-podman0 state UP group default\n    link/ether <mac_address> link-netnsid 1\n    …\nПроцесс следующий: при запуске пода slirp4netns создает виртуальный сетевой стек в пользовательском пространстве. CNI управляет распределением IP-адресов для контейнеров в виртуальной сети и отвечает за маршрутизацию. Внутри каждого сетевого namespace создается виртуальный eth0 интерфейс. Этот eth0 виртуально подключается к общей сети через veth-пару. А сама сеть представляет собой интерфейс cni-podman0 — виртуальный мост, созданный CNI. С точки зрения пода, он имеет прямое подключение к сети. Для связи с хостом slirp4netns использует tap0 интерфейс. Он также существует в контексте slirp4netns, а не в namespace подов.Подам назначаются IP-адреса из диапазона, определенного для созданной bridge сети. Эти адреса видны только внутри виртуальной сети и недоступны напрямую с хоста. При этом поды могут общаться друг с другом через виртуальную сеть. Slirp4netns обеспечивает NAT для исходящего трафика от подов, но входящие соединения обычно требуют явного проброса портов. А чтобы под оставался «живым» при перезапуске или остановке содержащегося в нем контейнера, Podman использует так называемый infra-контейнер, основанный на образе pause, который не делает ровным счетом ничего. Его задача — резервировать и поддерживать в рабочем состоянии сам под и, соответственно, связанный с ним namespace на протяжении всего жизненного цикла всех входящих в него контейнеров.Примерно так это можно проиллюстрировать схематически:Таким образом эта конфигурация обеспечивает баланс между изоляцией (отдельные namespaces) и связностью (общая виртуальная сеть). Каждый под изолирован, но при этом все они подключены к одной виртуальной сети, обслуживаемой одним процессом slirp4netns.​​​​​​​​​​​​​​​​В этой парадигме kube play предоставляет особые возможности, потому что он, вероятно, по задумке разработчиков RedHat, должен быть как можно ближе по поведению к Kubernetes.Интересно, что упоминание об этом алгоритме работы Podman попадается в основном только в обсуждениях багов на github тут и тут.  Podman Kube практикаТеперь рассмотрим, как можно управлять этой конструкцией.Во многом функционал Podman Kube можно описать как некий Kubernetes на минималках. Для запуска контейнеров используются манифесты в формате YAML, которые максимально приближены к YAML-манифестам K8s. В них есть возможность указать ConfigMap, Volumes, VolumeMounts и описать запускаемый контейнер.По аналогии с compose-файлом можно описывать несколько контейнеров и запускать их либо в одном поде, либо в разных.Примеры манифестов:1. Описание ПодаВ нем мы по аналогии с K8s описываем apiVersion, kind, metadata и spec. В spec указываем описание контейнеров, вольюмов и параметров окружения.apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    app: nats\n  name: nats\nspec:\n  containers:\n  - name: nats\n    image: nats:2.9-alpine\n    args:\n    - --jetstream\n    - --port\n    - \"4222\"\n    - --http_port\n    - \"8222\"\n    - --store_dir\n    - /data\n    volumeMounts:\n    - mountPath: /data\n      name: nats-data\n  volumes:\n  - hostPath:\n      path: /home/podman/nats/data\n      type: Directory\n    name: nats-data2. Описание Пода вместе с ConfigMapТакже по аналогии с K8s в манифесте для ConfigMap описываем apiVersion, kind, metadata и указываем наши переменные среды. Далее в описании пода ссылаемся на ConfigMap.apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nginx-config\ndata:\n  QUERY_PREFIX: /api/v1\n  CRUD_PREFIX: /api/v1\n  SSL_KEY_PATH: /ssl/tls.key\n  SSL_CERT_PATH: /ssl/tls.crt\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    app: nginx-router\n  name: nginx-router\nspec:\n  containers:\n  - name: nginx-router\n    image: nginx-router:5.6\n    args:\n    - nginx\n    - -g\n    - daemon off;\n    envFrom:\n    - configMapRef:\n        name: nginx-config\n        optional: false\n    ports:\n    - containerPort: 80\n      hostPort: 80\n    - containerPort: 443\n      hostPort: 443\n    volumeMounts:\n    - mountPath: /ssl/tls.crt\n      name: https-crt\n      subPath: /home/podman/cert/tls.crt\n    - mountPath: /ssl/tls.key\n      name: https-key\n      subPath: /home/podman/cert/tls.key\n    - mountPath: /var/cache/nginx\n      name: nginx-cache\n  volumes:\n  - hostPath:\n      path: /home/podman/cert/tls.crt\n      type: File\n    name: https-crt\n  - hostPath:\n      path: /home/podman/cert/tls.key\n      type: File\n    name: https-key\n  - hostPath:\n      path: /home/podman/nginx/nginx-cache\n      type: Directory\n    name: nginx-cacheАвтоматическое создание YAML-манифестовЧтобы использовать функционал Podman Kube, требуется писать YAML-манифесты с нуля, либо делать ручной рефакторинг compose-файлов в YAML-манифесты.Хорошо, что Podman упрощает жизнь возможностью генерации YAML-манифестов с помощью команды podman kube generate. Условие одно: контейнеры должны быть запущены. Тут можно воспользоваться либо командами podman run, либо тем же compose-файлом. При этом не обязательно, чтобы контейнер работал корректно и без ошибок. Требуется только, чтобы Podman видел их запущенными.Получив таким образом основное описание, мы можем его модифицировать. Например, удалить лишние или добавить требуемые ENV-переменные, скорректировать имена и параметры для volumes и volume-mounts. В общем, привести к виду, удовлетворяющему все ваши требования для корректного запуска.Пример последовательности команд:Запуск контейнера: podman run -d -it imageIDСмотрим id контейнера: podman psСоздаем манифест: podman kube generate ctrIDПрочие детали можно найти в документации RedHat.Итак, мы получили желаемое — скомпоновали контейнеры в поды, точнее, распределили их по манифестам для запуска в изолированных подах. После подготовки манифестов используются команды podman kube play и podman kube down для запуска и остановки подов.Например:podman kube play pod.yaml --network mynetpodman kube down pod.yamlСразу стоит отметить, что в Podman нет аналогов ReplicationController или ReplicaSet. То есть мы, к сожалению, не можем управлять количеством запущенных инстансов нашего пода.Работа с Podman secretsКаждый раз при создании манифестов мы сталкиваемся с необходимостью передавать чувствительные данные, например пароли подключения к базе данных или элементы учетных записей. Работа с чувствительными данным в Podman Kube основывается на стандартной функции podman secret. В манифесте YAML для Podman Kube мы можем определить, какие переменные мы будем брать из созданных секретов.К сожалению, на момент написания статьи не было возможности интегрировать создание «секрета» в общий манифест описания пода. С другой стороны, это позволяет использовать в разных подах одни и те же «секреты», что удобно, если сервисы обращаются к одним и тем же базам или IAM-провайдерам.Например, мы можем создать «секрет», описав его в отдельном YAML-манифесте:apiVersion: v1\ndata:\n  password: base64encodedvalue\nkind: Secret\nmetadata:\n  creationTimestamp: null\n  name: my-passwordИ выполнить команду podman kube play secret.yml.Затем можем обратиться к нему в манифесте с помощью инструкции: env:\n    - name: MY_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: my-password\n          key: passwordПодробнее это описано в документации RedHat.Трудности доступа к логам подовОтдельное внимание придется уделить правильным настройкам логирования. «Из коробки» мы получали ошибки при попытках выводить логи с помощью podman logs и флагом --follow.В режиме rootless с драйвером journald у Podman возникают проблемы доступа к логам, и для решения этой проблемы требуется внести правки в локальный файл настройки .config/containers/containers.conf:[containers]log_driver = \"k8s-file\"Больше деталей по этой теме есть в базе знаний RedHat.Хранение данных и прочие настройкиИ пару слов про хранение данных. В Podman на момент написания статьи поддерживается два вида volumes: persistentVolumeClaim и hostPath.Задать тип persistentVolumeClaim можно непосредственно в основном YAML описания пода, например: apiVersion: v1\n kind: PersistentVolumeClaim\n metadata:\n   name: example-pv-claim\n   labels:\n     app: example\n spec:\n   accessModes:\n   - ReadWriteOnce\n   resources:\n     requests:\n       storage: 20GiИ далее использовать его в самом поде по аналогии с манифестами в K8s: volumes:\n   - name: example-persistent-storage\n     persistentVolumeClaim:\n       claimName: example-pv-claimНадо заметить, что проект Podman развивается достаточно динамично, и первые версии полны всевозможных багов.Например, чтобы Podman Kube мог использовать нативные podman secretes для интеграции их с ENV-переменными, требуется версия не ниже 4.4, в которой исправлен баг, не позволяющий правильно преобразовывать содержимое «секретов» в режиме play kube.В версии Podman 4.4 таже есть возможность интегрировать управление подами в systemd с помощью Quadled.Коротко о том, как это работает. Мы можем создать манифест описания пода, как показано в примерах выше. И создать конфигурационный файл с расширением .kube, например example.kube, в котором укажем наш манифест:[Install]\nWantedBy=default.target\n[Kube]\nYaml=example.ymlДополнительно мы можем вносить директивы по аналогии с конфигурацией systemd сервисов, например, если требуется, чтобы под стартовал после другого пода:[Unit]\nRequires=first-pod.service\nAfter=first-pod.serviceДалее оба файла необходимо поместить в директорию ~/.config/containers/systemd/ и перезапустить systemd daemon: systemctl --user daemon-reloadЕсли мы описываем ConfigMap в отдельном файле, его можно указывать в блоке [Kube]: ConfigMap=example-configmap.ymlВ таком случае этот файл также требуется поместить в ~/.config/containers/systemd/.В блоке [Kube] также есть возможность указывать отдельно сеть и пробрасывать порты:Network=example.networkPublishPort=8000:8080В итоге мы можем запустить под с помощью systemctl следующим образом: systemctl --user start example.serviceПодробнее это описано в документации RedHat.Краткие итогиОказалось, что для работы в непривилегированном режиме, что всегда считалось одним из главных преимуществ, Podman предлагает пользователям уйти от парадигмы compose-файлов к использованию более современных и повсеместно используемых YAML-манифестов и их запуску через функционал “play kube”.Это позволяет обходить ограничения непривилегированного сетевого стека slipr4netns. А с точки зрения разработки и дальнейшего развертывания приложений в Kubernetes такой подход выглядит даже более рациональным, так как разработчики могут с самого начала запускать и тестировать сервисы локально уже с помощью “K8s-ready” YAML-манифестов, делая процессы непрерывной интеграции и доставки более бесшовными.Надеюсь, наш опыт послужит своеобразной подсказкой тем, кто окажется в подобной ситуации, и поможет увидеть большинство подводных камней, которые попадаются в процессе реализации данного подхода.",
    "GIMP Script-Fu Первый Дан. Первое приветствие": "Наш первый Hello World в GIMP!Наша цель нарисовать приветствие на изображении в GIMP. Но для того что бы вывести что то на изображение, это изображение у нас должно быть. Мы можем создать его в ручную. Просто средствами GIMP, или же создать его прямо из плагина Script-fu.Научим плагин создавать изображения, определив функцию создания изображений. Что надо знать, так это то что изображение состоит из слоев - layer, в нашем новом изображении будет изначально только один слой. Изображение будет создано и заполнено ТЕКУЩИМ цветом фона, установленного в Гимп, но мы могли бы вполне себе и задать цвет фона создаваемого изображения.(define (create-1-layer-img w h)\n   (let* ((i1  (car (gimp-image-new w h RGB)))\n         (l1  (car (gimp-layer-new i1 w h\n                                RGB \"layer 1\" 100 LAYER-MODE-NORMAL-LEGACY))))\n      (gimp-image-undo-disable i1)\n      (gimp-image-add-layer i1 l1 0)\n      ;;(gimp-palette-set-background '(0 127 50))\n      (gimp-edit-fill l1 FILL-BACKGROUND)\n      (gimp-display-new i1)\n      (gimp-image-undo-enable  i1)\n      i1))\nДа забыл сказать, этот код подходит для версии 2.10. А GIMP хотя и медленно, но постоянно меняется, и я работал в двух версиях, так что можете сравнить  код для версии 2.6:(define (create-1-layer-img w h)\n   (let* ((i1  (car (gimp-image-new w h RGB)))\n         (l1  (car (gimp-layer-new i1 w h\n                                RGB \"layer 1\" 100 NORMAL))))\n      (gimp-image-undo-disable i1)\n      (gimp-image-add-layer i1 l1 0)\n      ;;(gimp-palette-set-background '(0 127 50))\n      (gimp-edit-fill l1 BG-IMAGE-FILL)\n      (gimp-display-new i1)\n      (gimp-image-undo-enable  i1)\n      i1))Изменения - косметические, в именах констант, но именно такие вот мелкие изменения могут делать код не работоспособным при работе его в различных версиях гимпа.Используем эту функцию и создадим изображение:(define img (create-1-layer-img 640 480))\n;;можно получить img или ошибку:\n;;Error: eval: unbound variable: LAYER-MODE-NORMAL-LEGACY\n;;если применить код для версии 2.10 в gimp версии 2.6\nВ переменной img будет храниться handle(хендл), что можно перевести как ручка, нечто за что можно держаться и управлять этим объектом, представляющий собой некий числовой идентификатор, передавая который обратно в гимп с помощью функций гимп, мы можем работать с внутренним объектом гимпа. Типы этих объектов могут быть совершенно разными: изображение, слой или какой либо другой тип.Так же мы можем создать изображение с помощью средств гимпа или даже загрузить его из файла. Но для того чтобы работать с ним нам надо знать хендл этого изображения. Получить список всех изображений можно с помощью функции:(gimp-image-list)\n;;(1 #(1))\n\n(define img 1)\n;;img\nи просто присвоить известный числовой идентификатор переменной img и так же работать с ним как с хендлом.Далее нам надо определится с тем каким шрифтом выводить текст, список всех известных гимпу шрифтов, можно получить с помощью функции:;;посмотреть список фонтов присутствующих в системе\n(gimp-fonts-get-list \".*\")\n;;очень длинный вывод\n(gimp-fonts-get-list \"Sans\")\n;;у меня список из 218 элементов в Линукс и 23 в Видовс.\nфункция ищет по шаблону имени фонта и выдает все фонты имена которых соответствуют  шаблону, регулярному выражению. Из этого списка мы можем выбрать фонт, которым будем рисовать наш текст.(gimp-text-layer-new img \"Привет Мир!\" \"DejaVu Sans\" 1 1)\n;;(3)\nВведя эту команду в консоль скрипт-фу, мы к сожалению не увидим добавленного текста, но она вернет опять таки некий хендл(как список), созданного текстового слоя. Используя его можно получить некоторую информацию о созданном текстовом слое. К сожалению, до тех пор пока слой не будет добавлен в изображение, все функции работы с текстовым слоем выдают ошибку. Поэтому слой с текстом будем добавлять с помощью функции:(define (insert-text1 i str font size unit)\n  (let ((l (car (gimp-text-layer-new i str font size unit))))\n    (gimp-image-add-layer i l 0)\n\tl))\n\t\n(insert-text1 img \"Привет Мир!\" \"DejaVu Sans\" 1 1)\n;;4\nНе смотря на единички, а вернее благодаря последней единице(обозначающей вывод текста в неких юнитах), в линукс текст получился гигантским, в виндовс - вполне нормальным. Но мы попробуем второй заход. И да, если изображение \"подпорчено\", неудачной функцией в ГИМПе можно легко откатиться на предыдущую версию изображения воспользовавшись \"Историей действий\", это такой список изображений, выбрав то изображение которое вы считаете нормальным, у нас это пока единственное пустое изображение, выберем его.(insert-text1 img \"Привет Мир!\" \"DejaVu Sans\" 100 0)\n;;6\nПоследний 0 в вызове функции обозначает, размер будет указан в пикселах, а 100 обозначает условную высоту текста. Полученный слой приблизительно соответствует этой величине. \"Привет Мир!\" Из текстового слоя можно получить не мало интересной информации, помните хендл полученный нами для данного слоя 6, и именно его мы используем в указанных ниже функциях, если у вас хендл другой используйте его: (gimp-text-layer-get-text 6)\n;;(\"Привет Мир!\")\n(gimp-text-layer-get-language 6)\n;;(\"ru_RU\")\n(gimp-text-layer-get-font-size 6)\n;;(100.0 0)\n(gimp-text-layer-get-font 6)\n;;(\"DejaVu Sans\")\n(gimp-text-layer-get-base-direction 6)\n;;(0)\n(gimp-drawable-height 6)\n(gimp-drawable-width  6)\n;;(117)(668)\nРезультаты могут отличаться, например потому что в Виндовсе у меня нет такого фонта, но система не ругается, а молча пытается подобрать какой то фонт, близкий к заданному.Но что не менее важно, можно эту информацию и установить, т.е изменить сам текстовый слой.(gimp-text-layer-set-color 6 '(255 255 0))\n(#t)\n(gimp-text-layer-set-font 6  \"URW Gothic Oblique\")\n(gimp-text-layer-set-font 6   \"Terminus\")\n(#t)\n(gimp-text-layer-set-text 6   \"Хай, Бро!\\nКак живёшь?\")\n(#t)\n(gimp-text-layer-set-base-direction 6  4);;в 2.6 направления 4 нет, есть 0 или 1.\n(#t)\nИ вот результат:\"Докатились!\"Таким образом видно, Гимп предлагает очень богатый набор функций по выводу текста на изображение. И что не менее важно, слой создаваемый функцией gimp-text-layer-new является не просто картой пикселей, но объектом, динамически изменяющим свой вид, в зависимости от устанавливаемых для него параметров.Как запомнить результаты нашей работы? Надо объединить слои в один и дать ГИМПу команду сохранения:(gimp-image-flatten img)\n;;(7)\n(gimp-file-save 1 img (car (gimp-image-active-drawable img))\n                \"D:\\\\WORK\\\\gimp\\\\test-hello1.png\" \"test-hello1.png\" ) \n;;(#t)Путь указан для Виндовса, для Линкуса всё тоже самое, но с обычным слешем, конечно же без диска. И да, почему я всё время CARкаю? Потому что многие процедуры, типа gimp-image-active-drawable возвращают список, хотя казалось бы, почему список? активный слой может быть только один, но она возвращает список, а мы берём из него 1 элемент. Поэтому CAR.И на этом пока всё.",
    "Outcome-driven innovation (ODI)  — фреймворк для стратегии, основанный на CX": "Фреймворки встречаются нам часто, например, их достаточно много в маркетинге (SWOT-анализ), в продакт-менеджменте (RICE для приоритезации) и так далее. Любой фреймворк, который мы применяем в той или иной деятельности, должен облегчить принятие решения в бизнесе.Сегодня мы будем говорить про фреймворк, который может быть полезен для исследователя и продакт-менеджера. Это фреймворк Outcome-driven innovation (ODI).Для исследователя ODI - это возможность легко анализировать данные и делать выводы, а для продакт-менеджера - удобный инструмент для принятия решения. Впервые я услышала о нем в книге Джима Калбаха “Jobs To Be Done PlayBook”.Что такое ODI? ODI - это подход, разработанный в 1990-х годах Энтони Ульвиком, который позволяет с помощью исследований целевой аудитории анализировать рынок и создавать востребованный продукт. Outcome Driven Innovation базируется на JTBD (тут прослеживается тесная связь Энтони Ульвика с Клейтоном Кристенсеном).Применимость ODI Многие любят идти по проторенной дорожке и использовать один и тот же фреймворк для всех задач. Как будто один фреймворк может стать “волшебным ключиком” от всех неизведанных дверей. Например, так происходит со всеми любимым Jobs to be done. Но у него есть довольно понятные ограничения в использовании (об этом есть статья у Константина Ефимова и Анастасии Жичкиной, обязательна к прочтению, если вас интересует JTBD). Нельзя использовать один фреймворк под все задачи подряд, потому что это не приблизит вас к решению бизнес-задачи. Порой, скажу на своём опыте, не нужны никакие фреймворки. Вы можете ограничиться простой группировкой данных или кластеризацией, которую сами придумали.ODI может быть* полезен в следующем бизнес-контексте:Выход продукта на новый рынок Существует гипотеза продукта и её нужно проверитьУ продукта есть цель - захватить долю рынкаВы в продукте не понимаете ландшафт конкуренции и какие потребности ваших клиентов остаются неудовлетвореннымиСистематически падают продажи Высокий отток клиентовКомпании предстоит стратегическое планирование*Для каждой задачи в отдельности могут быть использованы альтернативные фреймворки, здесь не нужно ограничиваться только ODIПонятие ожидаемого результатаГлавной категорией ODI является ожидаемый результат (desired outcome). В книге “Jobs to be Done: Theory to Practice” Энтони Ульвик (основатель ODI) уделяет много внимания объяснению сущности “desired outcome”.Ожидаемый результат - это метрика успеха, по которой пользователь определяет — достиг он успеха при использовании продукта или нет.Примеры ожидаемых результатов:Сократить время регистрации и заселения в отель после прибытия.Уменьшить время согласования документов при покупке недвижимости.Повысить степень понимания учебного материала студентами при дистанционном обучении.Вы можете заметить схожесть между примерами. Ожидаемые результаты конструируются по определенным правилам, сформулированным Энтони Ульвиком.Правила формулирования желаемых результатов:Направление действия (direction of improvement) - оно указывает на то, каким образом клиент хочет изменить определенный аспект при выполнении своей задачи. Направление действия выражается с помощью глагола действия, который отражает желаемое улучшение или изменение.Метрика изменения (performance metric) - это может быть время, количество, вероятность, степень, интенсивность и т.дОбъект контроля (object of control) - конкретизирует параметр или аспект, на который направлено действие.Контекст (contextual clarifier) - уточняет, в каких условиях или при каких обстоятельствах клиент желает достичь результата.Пример ожидаемого результата:Ожидаемые результаты берутся из интервью с целевой аудиторией. Выдумывать их опасно, так как именно ожидаемые результаты будут использоваться при количественной валидации.Этапы ODIСоздатель ODI говорит: “Если \"JTBD\" - это теория, то ODI, - это процесс, воплощающий ее в жизнь.” И в целом, в своих статья Энтони Ульвик интерпретирует ODI как “инновационный процесс”, который дает возможность инновации превращать из искусства в науку. Мы предлагаем рассматривать ODI как надстройку над JTBD, помогающую приземлить результаты качественного исследования на продукт и сделать их более применимыми. Для этого мы рассмотрим этапы ODI.Энтони Ульвик выделяет 10 этапов в Outcome Driven Innovation:Ремарка: не путайте Job Map и Customer Journey Map, потому что у них разное назначение. CJM - это более узкая субстанция опосредованная каким-то решением. То есть CJM мы конструируем для какого-то уже существующего на рынке продукта. А Job Map может выходит далеко за рамки вашего продукта, и показывает “жизнь клиента” в процессе достижения главной цели.С первыми 6 этапами может справиться исследователь,но остальные 4 требуют погружения продакт-менеджера (или других лиц, принимающих решения в продукте).Результатом первых 6 этапов должно стать несколько артефактов: job map и opportunity landscape. Давайте разберем каждый артефакт.Job map - это визуальное изображение достижения основной функциональной задачи (core job), разложенное на отдельные процессы или этапы работы (job steps), которое подробно объясняет, что именно пытается сделать потребитель. В каждом job steps есть набор желаемых результатов.Пример Job map потребителя ипотечного кредита:C помощью Job map вы сможете посмотреть, на какие этапы делится путь потребителя при достижения цели, какие ожидаемые результаты есть на каждом этапе. Уже на этом этапе исследования вы можете понять, какие job steps закрывает ваш продукт, где у потребителей есть самые острые проблемы и неудовлетворенность. Да, это может быть этап за который не отвечает ипотечный брокер, например,  выбор недвижимости (обычно эту работу делает риелтор). Но “захват” этого этапа может стать новым витком в стратегии вашего продукта. Вы можете придумать удобный агрегатор с фильтрами для поиска жилья и таким образом создавать экосистему, закрывающую наибольшее количество job steps. Ремарка: не путайте Job Map и Customer Journey Map, потому что у них разное назначение. CJM - это более узкая субстанция опосредованная каким-то решением. То есть CJM мы конструируем для какого-то уже существующего на рынке продукта. А Job Map может выходит далеко за рамки вашего продукта, и показывает “жизнь клиента” в процессе достижения главной цели.Opportunity landscape - представляет собой карту, которая отображает важность и степень неудовлетворенности различных желаемых результатов, позволяя компаниям сфокусироваться на тех областях, где существует наибольший потенциал для создания ценности для клиентов.После интервью с пользователями нам нужно провести количественный опрос по методике Opportunity Score. Мы берём сформированные ожидаемые результаты и валидируем их количественно через оценку важности и удовлетворенности. Опрос нужно провести на нашей целевой аудитории у конкурентов, как прямых, так и косвенных. Внизу статьи будет ссылка на ресурс о том, как рассчитывать Opportunity Score. После расчета индекса для удобства все результаты визуализируются через Opportunity Landscape.Пример из статьи Энтони Ульвика с Microsoft (статья):Каждая точка - это ожидаемый результат. В правом нижнем углу отмечены ожидаемые результаты, которые имеют самую высокую важность и низкую удовлетворенность рынком. Это значит, что часть ожидаемых результатов неудовлетворена на рынке. Согласитесь, что после комбинации качественного сбора данных и количественной валидации ваша уверенность в принятии какого-либо решения возрастет. А что после исследований?После такого массивного ресерча наступают этапы использования и внедрения данных (7-10 этапы ODI). Здесь роль исследователя переходит в “режим саппорта” для продакт-менеджера (или другого лица принимающего решение). Эти этапы больше фокусируются на стратегическом вижене. Ульвик разработал Jobs-to-be-Done Growth Strategy MatrixМатрица разделена на четыре квадранта (перевод по книге Ульвика):1) Differentiated strategyКлиенты считают эти задачи критически важными, но существующие решения не удовлетворяют их ожидания (примеры продуктов по Ульвику: кофеварки и эспрессо Nespresso, iPhone 2G от Apple,международные рейсы авиакомпании Emirates, спортивные автомобили BMW, PlayStation (оригинальная модель) от Sony, пылесос и сушилка для рук Airblade от Dyson)2) Dominant strategyКомпания реализует доминирующую стратегию, когда она предлагает всем потребителям на рынке новый продукт или услугу, которые выполняют работу значительно лучше и за значительно меньшие деньги. Примерами предложений, успешно использующих доминирующую стратегию, являются Google Search, Google AdWords, UberX, потоковое видео Netflix.3) Disruptive strategyКомпания реализует деструктивную стратегию, когда она обнаруживает и нацеливается на группу излишне обслуживаемых клиентов или непотребителей, предлагая им новый продукт или услугу, которые позволяют выполнить работу дешевле, но не так хорошо, как конкурирующие решения. Примеры Среди предложений, успешно использовавших стратегию разрушения, можно назвать Google Docs (по сравнению с Microsoft Office).4) Discrete strategyЭта стратегия может сработать в ситуациях, когда покупатели ограничены юридически, физически, эмоционально или иным образом в возможностях выполнения работы. Примерами предложений, успешно использующих дискретную стратегию, могут служить напитки, продаваемые в аэропортах, минуя пункты досмотра, концессии на стадионах во время спортивных мероприятий, услуги по обналичиванию чеков и кредитованию до зарплаты, а также банкоматы в удаленных местах.5)Sustaining strategy Компания реализует стратегию поддержания, когда она представляет новый продукт или услугу, которые выполняют свою работу лишь немного лучше и/или немного дешевле. Источники по теме:ЭнтониУльвик «Jobs To Be Done: Theory to Practice» Джим Калбах «Jobs To Be Done PlayBook»Статья Ульвика про ODI (открывать с VPN)  Статья про Opportunity Score (открывать с VPN)",
    "Читерство на собеседовании": "Небольшая история про мое первое столкновение с читерством на собеседовании. Это было примерно 2 года назад. Проводил очередное техническое собеседование на английском языке. Кандидат бодро и убедительно рассказывал о своем опыте.“А теперь давайте перейдем к техническим вопросам?” - спросил я.Ответы на первые вопросы были слабоватые. Иногда он отвечал приемлемо, но по большей части - расплывчато, как ученик, прочитавший краткий пересказ “Героя нашего времени”, которого застали врасплох вопросами на литературе. Я немного загрустил. Ну что же, движемся дальше.И тут я вижу, как кандидат стал посматривать вбок и будто бы вчитываться в другой экран. По характеру речи слышу, что человек зачитывает текст. К сожалению, получается у него коряво - видимо еще не достаточно ловок для того, чтобы скрыть такое.“Подожди-ка, может быть ты сам себе придумываешь и зря про человека так думаешь.” - подумал я.Я спрашиваю: “Уважаемый кандидат, а не подглядываете ли вы случаем ответы на вопросы где-то еще? Вижу у вас экран сбоку, в который вы смотрите.”“Что вы, конечно же нет. Я забыл сказать, у меня сегодня деплоймент в прод. Поэтому, я мониторю, чтобы все было хорошо.” - ловко парирует кандидат.После этого он явно проделал какие-то манипуляции с боковым экраном. Но невербально, я еще больше убедился, что он меня обманывает.Окей, надо как-то вывести его на чистую воду. В голову пришла идея. А что если задать ему достаточно распространенный вопрос для технического собеседования, который легко гуглится и сравнить его ответ и первый ответ в поисковой выдаче?Ответ кандидата слово в слово повторил ответ в поисковике. Контрольная проверка. Результат тот же.После этого, я сказал, кандидату, что продолжать собеседование больше не имеет смысла и отметил его как читера. Ощущения были не самые приятные. Хотя добытый в ходе собеседования метод выявления читеров мне еще пригодился.ПослесловиеЯ наслышался историй про то, как кандидаты проходят собес с помощью Chat-GPT и даже получают оффер. Думаю при должной сноровке они и смогут какое-то время продержаться в компании. Возможно это будет и стандартные “года-полтора” перед очередной сменой работодателя. А потом они пойдут искать более выгодные предложения и цикл повториться вновь.Вступайте в нашу группу в Telegram. Там обсуждаем опыт прохождения собесов, помогаем друг другу с подготовкой. Уже набралось много полезного.",
    "Опыт команды t2: как мы начали переход на российские ноутбуки и какими результатами готовы поделиться уже сейчас": "Привет, Хабр! Меня зовут Никита, я – инженер технической поддержки. С 2022 года большая часть российских компаний переходит на отечественное оборудование. Это непростой, но интересный процесс, в самом эпицентре которого оказались мы с командой. В этой статье я расскажу о своём опыте, об алгоритме, который мы используем в t2, и, надеюсь, получу какую-то обратную связь от коллег по цеху из других компаний. Также упомяну ноуты, которые мы тестируем, и сделаю пару ремарок о них, НО, это будет личное мнение и наблюдение моей команды. На истину в первой инстанции не претендую. Итак, t2 не обошла стороной необходимость масштабно импортозамещать рабочую технику сотрудников компании – 8000+ человек в 69 регионах страны. Все решения, которые тиражируются на нашу большую команду, проходят через нас – техническую поддержку, а точнее её часть – четверых специалистов. Сначала я бы хотел сделать ёмкое погружение в контекст для тех читателей, которые, по счастливым обстоятельствам, пока не успели столкнуться с проблемами, которые сподвигли нас и другие корпорации импортозамещаться. Что же это за сложности?Изменились условия игры, и, несмотря на то, что многие устройства привычных брендов до сих пор доступны на нашем рынке по параллельному импорту, сформированный критерий «цена — качество» больше не удовлетворяется.Бренды, с которыми мы работали, закрыли онлайн-сервисы для обновления драйверов.Сервисные центры перестали ремонтировать ноутбуки из-за отсутствия запчастей. На российском рынке достаточно быстро появилось большое количество новых игроков, и нашей рабочей группе было поручено тестировать предлагаемые решения и выбирать наилучшие. Не все производители смогли удовлетворить и наше первое, ключевое требование к партнёрам: надёжность, которая заключается в прозрачной схеме поставок, отлаженном сервисном обслуживании, возможности напрямую контактировать с поставщиком. А теперь давайте пройдёмся по этапам нашего тестирования новой техники.Этап #1: техническое задание для потенциальных поставщиковКрупные закупки в компании проходят через тендер: мы анализируем потребности, составляем техническое задание (ТЗ) и предлагаем его потенциальным поставщикам. Если потенциальные компании-партнёры готовы предложить нам продукты с необходимыми характеристиками и (ВАЖНО!) в рамках нашего бюджета, мы заключаем договор на первую поставку. В техническое задание мы вынесли основные требования к технике, которая подходит для выполнения рабочих задач сотрудников разных подразделений t2. Мы получили следующие критерии:процессор Intel i5 11 поколения и выше;8/16 Гб ОЗУ;жёсткие диски SSD формата М2 256/512 Гб.Наша первая заказанная партия ноутбуков состояла примерно из 500 единиц техники. Здесь хочется отметить чисто по-человечески приятный момент: все поставщики охотно шли на контакт, пытались помочь и со своей стороны делали всё для комфортной и продуктивной коммуникации.Этап #2: тестированиеВот ноутбук попадает ко мне в руки (или к кому-то из нашей команды). Я формирую своё впечатление, проверяю устройство на наличие основных ошибок. Были кейсы, когда уже на этапе первичной диагностики мы сталкивались с проблемами, приводящими к замене или изъятию всей партии. Добавлю пару слов о первичной диагностике и чек-листе, который я составил для проведения проверки.1. Проверка на отсутствие повреждений, сколов на упаковке и изделии – визуальный осмотр.2. Проверка качества сборки: ровно ли стоит ноутбук на столе, нормально ли открываются крышка и другие механизмы, присутствующие у изделия – визуально, тактильно.3. Подключение зарядки: наличие индикации, заряда батареи.4. Время работы 4+ ч: запускаем видео FullHD на 100% яркости, зацикливаем, смотрим, сколько проработает. Смотрим свой любимый сериал. Конечно, это шутка. Фильмы.5. Матрица экрана: специальным ПО тестируем на наличие засветов/пикселей с проблемами; открываем текстовый файл, смотрим на читабельность и угол обзора (тут можно добавить, что существует большое количество онлайн-сервисов по запросу в поисковых системах, можно проверить свой ноутбук или просто монитор на наличие битых пикселей и засветов за несколько минут, пару раз кликнув мышкой, и иногда узнать для себя много нового ;)6. Тестирование Ethernet-разъёма: подключаем к роутеру, ноутбук должен получить сеть, определить ip адрес.7. Проверка камеры: должна уметь делать снимки FullHd качества.8. Производительность и стрессоустойчивость системы – специальным ПО загружаем на 100% систему ноутбука, проводим тест в течение 15 минут, смотрим на показатели температуры (обычно показатели 50-60 градусов), громкость работы охлаждающей системы.После моей проверки ноутбуки уходят в поля: они выдаются сотрудникам разных подразделений – разработчику, финансисту, маркетологу и т.д. Мы не проводим искусственного тестирования на решение придуманных задач – устройство сразу начинает применяться по своему назначению тем сотрудником, для которого оно предназначено. Мы на живом опыте использования смотрим, как новая техника справляется, принимаем и анализируем обращения, фиксируем ошибки для дальнейшей работы с поставщиками.На этом тестирование, в принципе, заканчивается. Мы не придумывали сложных моделей, сам процесс перехода на новое оборудование, тем более в таком масштабе, не может быть простым. Немного расскажу о трудностях, с которыми мы столкнулись.Проблемные места новой техники, которые мы для себя отметилиМы уже не в начале пути перехода на российские устройства, но и не в его конце. Процесс живой, и какие-то трудности диагностируются по сей день. Однако у нас уже есть пул проблемных закономерностей, которые мы для себя отметили при работе с техникой:прошивки и драйвера нуждаются в обновлении для исправления ошибок базового функционала устройства; модули Wi-Fi и Bluetooth зачастую работают с перебоями;качество отечественных экранов в подавляющем большинстве случаев ниже, чем у зарубежных аналогов;уровень комплектующих также уступает технике, на которой мы работали раньше. По сравнению с домашней средой корпоративные сценарии использования накладывают свои требования. В масштабе крупной компании обновить BIOS централизованно для решения той или иной проблемы в текущих реалиях не представляется возможным. При этом элементарная проблема отсутствующего сетевого соединения может выбить сотрудника из рабочего процесса на несколько часов, если перемножить на несколько таких сотрудников по всей России, простой в работе может вылиться в уже значительное упущенное время. Есть же гарантия, скажете вы, и будете, конечно же, правы. В единичных случаях гарантийные обязательства производителя могут выручить. Однако, стоит посмотреть на гарантию с другой стороны: чтобы отправить ноутбук на обслуживание в сервисный центр, сотруднику предварительно необходимо выдать замену, а ее нужно подготовить. Что в свою очередь становится дополнительной статьей затрат трудовых часов сотрудника технической поддержки. Важно понимать, что за пару лет создать сервис, который есть у известных всем компаний-лидеров мирового масштаба, практически невозможно. Отечественные производители двигаются в нужном направлении, и это нас как потребителей, конечно, радует. Ну, а самым убедительным доводом является, конечно, эффективность работы, которая не пострадала при переходе на российские ноутбуки.Инсайты нашей команды (предупреждаю: здесь будет оптимистично)Команда t2 решает свои рабочие задачи точно так же, как и раньше, изменился только лого на крышке ноутбука. Мы посчитали, что активно тестируем и вводим в эксплуатацию новые устройства уже больше года, и вот к каким выводам пришли:Российские ноутбуки, по стоимости соотносятся с тем, сколько раньше стоили привычные модели иностранных производителей, не уступают зарубежным аналогам по функциональности.Наши поставщики обеспечивают длительный срок гарантии — это очень важно для корпоративных клиентов. На российском рынке много разных вариантов техники, и, если задаться целью, вы точно найдете подходящую партию оборудования. Доступны не только классические компьютеры, но и очень необычные модели. Например, с тачскрином — ноутбук-планшет, который лично мы не ожидали увидеть в ассортименте отечественных брендов. Хочется отметить, что, опять же, компании-производители, наши новые партнёры, готовы получать фидбэк, слушать мнения, исправлять, дорабатывать и меняться. Это очень важно.А теперь конкретно: какие модели нам уже удалось протестироватьНиже в статье вы увидите фотографии, которые я сделал сам, с моими комментариями. Опять же скажу, что значительная часть замечаний – это моё мнение, которое может отличаться от мнения других пользователей.Сразу обозначу, начинка у всех моделей одинаковая, прежде всего, техника соответствует ТЗ. Но каждый ноутбук уникален по-своему:KvadraAquariusHiperСилаХотелось бы, чтобы каждый читатель обязательно услышал (прочитал) главную мысль: ноутбук - это инструмент, который должен максимально закрывать ваши потребности. Для меня таким инструментом стала модель производителя СИЛА; для некоторых разъездных сотрудников офиса, несмотря на вес, лидером стал Aquarius, благодаря сенсорному экрану. По количественному соотношению работающих моделей в t2 сейчас больше всего ноутбуков Hiper и Kvadra. «Силой» мы тоже пользуемся, но эта техника выполняет, скорее, роль «переходного этапа» между зарубежным брендовым оборудованием и официально сертифицированным на нашем рынке моделями. И вместе с \"Спасибо за внимание!\"Мы решили, что нам есть, чем поделиться. Почему? Здесь всё просто: мы – большая компания, которая закупает ноутбуки массово и сразу запускает технику в бой. У нас восьмитысячная аудитория для тестирования и оперативное выявление проблем.Если вы тоже идёте по пути замены оборудования на другое, более дружественное или у вас есть вопросы по статье, буду рад пообщаться в комментариях. Спасибо за прочтение материала.",
    "Система сквозного логирования с передачей единого идентификатора между независимыми задачами Airflow": "Привет! Меня зовут Никита Хилов, я работаю в билайне уже более десяти лет. Начинал я работать с поддержкой систем фиксированного фиксированного биллинга, впоследствии я отвечал за разработку и поддержку различных расчетов по системам управленческой или корпоративной отчетности. А сейчас я работаю в роли тимлида дата-инженеров в блоке по архитектуре и инфраструктуре данных и отвечаю за управление разработкой и сопровождением программных продуктов компании по различным точкам бизнес-приложения. Итак, какие же вопросы мы обсудим в этой серии постов. Сегодня я хочу осветить вопросы касаемо того, как же нам организовывать, компоновать и в принципе заставить работу систему журналирования наших расчетов для таких случаев, когда наш общепринятый ключ периодики, на котором мы обычно строим свои расчеты, перестает быть однозначным идентификатором той итерации процесса подготовки данных, на которую мы сейчас смотрим, и от которых мы ждем результаты. Мы обсудим, например, когда такое происходит и что для этого является катализатором. Рассмотрим механики и механизмы, которые дают возможность связывать независимые процессы и цепочки подготовки данных в единое целое.И в дополнение расскажу, как мы эту проблему решали в своем продукте. Но прежде всего давайте определим для чего нам это, в принципе, нужно. При проектировании проработки сценариев отчетности, это может быть управленческая, бухгалтерская, финансовая, корпоративная, критично учитывать основные требования, которые к ней будут предъявлены.Требования для отчётностиДля бухотчетности и финансовой отчетности есть даже специальные законы и нормы, которые эти требования отражают. Но если расширить круг, то какие же требования будут предъявляться, например, к внутренней отчётности компании?Прежде всего, отчетность, которая предоставляется разработчиками и владельцами отчетов вовне, то есть в инфраструктуру самой компании, должна быть достоверна и надежна. Другими словами, это отчетность должна отражать реальное положение дел в компании. Также отчетность должна быть оперативной, и в данном случае под оперативностью отчетности занимается то, что она должна предоставляться к такому сроку, пока она является необходима для принятия решений. Также отчетность должна быть доступной и полезной. Информацию в этой отчетности будут считать полезной при выполнении условий, что она является уместной, надежной, сравнимой и своевременной. А ещё отчетность должна быть понятной. Сведения, которые предоставляются в отчете, должны быть в понятном пользователю виде, тогда эти документы можно правильно трактовать и правильно понимать.И отчетность должна быть полной. В данном случае суть этого требования состоит в предоставлении всей необходимой отчетной информации. Так, большинство этих требований находятся явно в зоне ответственности владельца того или иного продукта или того или иного отчета. Сложно требовать от разработчика на том же Spark знаний по основам бухучета. Но эти требования должны быть проработаны на этапе архитектуры, на этапах системного бизнес -анализа и при этом не потеряны при переходе к разработке и сопровождению. Что же это фактически значит для дата-инженера, который проектирует свое программное решение поставленной задачи? В ходе своей работы мы должны исходить из необходимости удовлетворения как минимум двух двух основополагающих требований, которые будут впоследствии владельцами уже наложены на наши отчеты. Это требование гарантирования актуальности данных и требование гарантирования качества этих данных. Формализовать второе требование о качестве данных, в принципе, достаточно сложно, но давайте будем исходить из того, что мы должны строить свои отчеты, исходя хотя бы из трех критериев:Наши отчеты должны строиться на достоверных, поддерживаемых и обновляемых источниках. Мы должны в рамках разработки и запусков налагать на алгоритмы и структуры данных, которые мы при этом используем, все определяемые нашим производственным процессом тесты. Мы должны записывать в систему журналирования или логирования достаточную информацию, которая может быть необходимой при решений различных конфликтов. Однако, как можно гарантировать актуальность данных? Как ее можно проверить и измерить? Вот сейчас и узнаем.Для начала важно поднять и ответить самим себе на вопрос. Какие у нас данные?Если мы заглянем под капот информационных систем, то мы увидим, что в большинстве из них данные организованы в таблице фактов и таблице измерений. Что такое таблица фактов? Таблица фактов является основной таблицей хранилища данных. Как правило, она содержит сведения об объектах или событиях, совокупность которых мы потом планируем в принципе дальнейшем анализировать. Какие же это могут быть факты? Выделяют, как правило, четыре группы основополагающих фактов. Первый факт — это  факты, которые связаны с транзакциями. Они основываются на отдельных событиях. Например, телефонный звонок или снятие денег со счета с помощью банкомата. Вторая группа фактов связана с моментальными снимками. Они основываются на состоянии объекта, например, банковского счета, в определенные моменты времени. Это может быть время на конец дня, либо в конце месяца. Типичными такими примерами будут объемы продаж за сутки или дневная выручка. Третий же тип фактов — это факты, связанные с элементами документов. Они основаны, как правило, на том или ином документе. Это может быть счет за услуги, счет за товар, какие-то счета-фактуры и подобное. Они содержат в себе подробную информацию об элементах этого документа, там может быть количество товара, его цена, проценты скидки Четвертая группа — это факты, которые связаны с событием или состоянием объекта, но при этом они предоставляют только сам факт возникновения или, наоборот, отсутствия того или иного события, не предоставляя при этом никаких особых подробностей. При этом эти факты зачастую группируют по значениям какого-либо заранее выбранного ключа, и правило это даты совершения фактов. Сохраняют их в раздельные места для ускорения доступа к тому или иному набору фактов. Каждый такой отдельный набор формирует партиции или секции.Итак, с таблицей фактов понятно, но что тогда у нас относится к таблице измерений?Информация в таблице измерений в структуре базы данных содержит атрибуты событий, которые мы сохранили в таблице фактов. Атрибуты могут представлять собой текстовые или иные описания, логически объединенные в одно целое. Например, имя покупателя будет атрибутом в таблице измерения покупателей, наименование товара, соответственно, в таблице измерения товара. В то же время, как сумма транзакций является величиной аддитивной, её значение таким образом должно храниться в таблице фактов. Давайте предположим, что мы имеем некоторый набор данных, отражающий информацию о продаже книг. У нас есть идентификаторы книги, автора категории и любой сопутствующий факт продажи набор атрибутов. Однако есть один очень важный атрибут, который превращает наш набор данных из обычного перечисления в набор фактов. Это атрибут времени совершения факта продажи. И важен атрибут в этом контексте еще и тем, что именно время является ключевым элементом системы гарантирования актуальности данных. Вернемся к таблице фактов.Предположим, что перед нами поставили задачу составить иерархию жанров, например, по суммам выплаченных комиссий за отчетный период. У нас есть информация о продажах, есть ссылки на авторов, их проценты комиссий и информация, подтверждающая, что тот или иной платеж автору был выполнен.В нашем отчете мы получаем список продаж за отчетный период с суммами соответствующих транзакций. По ключу автора мы находим для каждой продажи размер процента выплат. Перед нахождением итоговой суммы вознаграждения убираем те, что еще не были совершены. Итоговый результат мы сложили в слой витрин в таблицу нашего отчета и отправляем в уведомление о готовности потребителям или рассылаем этот отчет по заказчикам. Что будет, если мы попробуем наложить ранее обсужденные два требования на эту модель расчета? На какой же вопрос мы прежде всего должны ответить?Вопрос этот будет звучать так — как происходит обновление данных в наших отчетных периодах? Ведь формально у нас существуют три варианта обновления наших данных, к ним относятся полная, инкрементная и дифференциальная загрузка. Первый вариант предполагает свое использование в системах, которые как правило поддерживают вендор, когда среды аналитики и разработки выносят в отдельные информационные единицы для исключения нагрузки с аналитиков или разработчиков на продуктивные контура. Второй и третий вариант, то есть инкрементальная и дифференциальная загрузка, представляет собой уже приближенные к в реальному жизненному циклу в операции, в компании и ее процессам. Для лучшего понимания давайте проведем аналогию с бэкапированием. Как и в наших моделях обновления данных, у систем резервного копирования выделяют три схожих вида. Это полный бэкап, дифференциальный бэкап и инкрементальный бэкап. Полный бэкап осуществляет сохранение полной копии нашей системы или тех данных, которые мы отметили к резервному копированию. И каждый такой снимок в нашем хранилище при полном резервном копировании с заданной периодичностью начинает создавать архивы, где данные в основной своей массе дублируются. Это его серьезный и ключевой недостаток, ведь расходуется огромный объем ресурсов и места в хранилище, время создания и время процессорное, вычислительные мощности. Поэтому есть ещё и такие варианты, как инкрементальный вид резервного копирования, которое является более экономичным и более быстрым, чем полный бэкап, поскольку в процессе инкрементального копирования будут создаваться только такие файлы, которые изменились со времени предыдущего резервного копирования, которое могло быть либо полным бэкапом, либо другой итерацией нашего инкрементального копирования. Исходные же данные, которые не изменились и которые мы изначально сохранили, они не перезаписываются.Дифференциальный же бэкап обрабатывает файлы, измененные или созданные с момента выполнения предыдущего полного бэкапа. Однако, вне зависимости от той модели обновления данных в нашем наборе фактов, изменения в секцию могут в реальности прийти как полностью за секцию, например, продажи книг за день, когда мы секцию формируем по дню, но и могут инкрементно, по мере появления их в системах источников, например, при потоковом формате загрузки данных.И в большинстве случаев поведение данных будет определяться жизненным циклом компании. И в этот момент у нас появляется разный подход для разной модели обновления, что мы и обсудим в продолжении этого поста.",
    "«Удалённо» управляем компьютером с доступом в BIOS": "Итак, о чём это? Сейчас для удалённого управления компьютером есть великое множество программ на любой цвет, вкус и запах. Но, что если мы хотим пойти немного дальше, и наши требования к удалённому управлению становятся немного жёстче:\n\n\nМы хотим иметь возможность не только работать в операционной системе, но и заходить в биос, или вообще эту систему переустановить.\nПо тем или иным причинам, компьютер не может быть подключён к сети, но управлять им мы от этого меньше не хотим, а рядом у нас есть компьютер, который в сети находиться может\n\nНо как это сделать? Вот этим мы тут и будем заниматься...\n\n▍ Как я к этому пришёл\nИногда мне приносят разное железо с просьбами переустановить винду/почистить вирусы и т. д. А я что? Я ж программист простой: мне приносят и просят сделать — я делаю. Но порой не очень удобно подключать к этому всему отдельную мышь/клавиатуру и монитор, а бывает, что там идёт долгий процесс, не требующий особого вмешательства, но периодически надо сделать пару кликов, что я мог бы сделать удалённо с работы, будь у меня такая возможность, и сэкономить кучу времени вечером. Я знаю, что такое удалённое управление бывает на серверных материнских платах, но в последний раз мне приносили сервер, чтобы я переустановил на нём Windows никогда, или даже ещё раньше. \n\nВ какой-то момент у меня возникла в голове идея: есть же недорогие устройства видеозахвата USB-HDMI, а ещё есть ESP32 S2/S3, которые умеют эмулировать USB. А что нам ещё надо? Изображение с компьютера мы можем получить, клавиатуру/мышь можем проэмулировать. Может быть, такие проекты даже уже есть, но когда мне в голову приходит идея, которая кажется мне интересной, я:\n\n\nНу что ж, проекту быть, и для него нам потребуется следующий минимум:\n\n\n\nHDMI-плата захвата видео\nПлата ESP32 S3 — у неё сразу есть 2 TypeC разъёма, что упростит нам жизнь\nHDMI-кабель\n2 кабеля USB TypeA — TypeC\nКомпьютер с Windows, стоящий рядом\n\nС железом условно всё, и если нам не нужно управлять аппаратной перезагрузкой/включением компьютера, то нам даже не придётся ничего паять. А если нужно, то всему своё время…\n\nИтак, возможно, когда я написал пункт «Компьютер с Windows, стоящий рядом», я кого-то очень сильно огорчил. И я согласен, что решение не самое оптимальное, если бы всё работало под Linux, да ещё выводить всё в Web, то можно было бы взять Малинку/Апельсинку и… Но нет. Хотя, может и да, ведь проект открытый, и если у кого-нибудь будет время, желание и умение, то он может переделать под Линукс мой проект, сделанный на .Net, но пока я всё основное время работаю под осью одной из корпораций зла, проект только под Винду.\n\n▍ Приступаем к работе\nЛадно, начинаем. Схема подключения простая:\n\n\n\nТеперь, когда у нас всё подключено, что дальше? Дальше пишем ПО.\n\n\n\nПО написано, что делаем дальше? Для начала надо залить прошивку на нашу ESP32 S3. Убеждаемся, что драйверы ком-порта у нас установлены (откуда их брать, обычно указывает продавец этой самой платы). Для заливки прошивки я использовал Arduino IDE, тем более что скетч написан именно в нём. В этой статье я не буду подробно описывать процесс настройки Arduino IDE на работу с платами EST32 и прошивки — его можно найти, например, везде, и он довольно прост. Дальше перейдём непосредственно к ПО для удалённого управления, а тут всё ещё проще:\n\n\n\nПодключаем всё, включаем компьютер, которым мы хотим управлять, и в программе нажимаем кнопку подключения. И если все звёзды на небе сошлись, то мы видим изображение с монитора компьютера, у нас есть мышь и клавиатура и они работают.\n\n▍ Немного о коде\nПрежде чем продолжить проект, добавив к нему ещё пару крутых фич, я предпочту немного замедлиться и погрузиться в код, который был написан. И если со стороны всё выглядит как вжух и готово, то на деле было не совсем так. Начиная этот проект, я стал искать библиотеки для .Net для работы с устройствами видеозахвата. И первое, что мне попалось, было OpenCvSharp. Я проверил, что эта библиотека работает с веб-камерами и другими подобными устройствами и выдаёт изображение на WinForms. Отказался я от неё потому, что не нашёл у неё возможности нормально перечислить список всех камер с их именами для выбора в меню, а городить это отдельно не очень хотелось, и пока я ещё не сильно привык к этой библиотеке, я стал смотреть другие. \n\nСледующей была AForge. В ней список камер перечислялся нормально, с именами и фамилиями, и, казалось бы, всё было хорошо, но нет. Когда я тестировал программу на реальном устройстве видеозахвата, всё было хорошо, но когда отлаживался на виртуальной веб-камере от OBS Studio, картинку я не получал. При этом ошибку тоже. Я не получал ничего, я был просто проигнорирован и видел, как происходит ничего. Мне не понравилось. Я бы подумал, что что-то не так с самой камерой у OBS, но в OpenCvSharp всё прекрасно работало. И я стал копать… И вот щетина на моём лице уже выросла, вся водка была выпита, медведь доиграл свою арию на балалайке, но ничего по-прежнему не работало. Но вскоре проблема вскрылась. AForge принудительно запрашивает у камеры формат RGB24, и если устройство его поддерживает, то всё ОК. А если нет, тады ой. Камера от OBS поддерживала формат NV12, но AForge не умела его декодировать, как и многие другие форматы. Можно было оставить эту библиотеку и пойти к следующей, но это уже было делом принципа, я потратил на поиск этой особенности слишком много времени, и раз уж исходный код AForge открыт, я решил его поправить. В очередной раз я убедился, насколько ChatGPT (и ему подобные) делают нашу программистскую жизнь легче.\n\n\nМагия XXI века\nЗапрос:\nwrite me c# function that converts YUY2 format pixels (IntPtr buffer, int bufferLen) to Bitmap\nОтвет:\nusing System;\nusing System.Drawing;\nusing System.Drawing.Imaging;\nusing System.Runtime.InteropServices;\n\npublic class YUY2Converter\n{\n    // Function to convert YUY2 buffer to a Bitmap\n    public static Bitmap ConvertYUY2ToBitmap(IntPtr buffer, int bufferLen, int width, int height)\n    {\n        // Validate buffer length\n        if (bufferLen != width * height * 2)\n            throw new ArgumentException(\"Invalid buffer length for given width and height\");\n\n        // Create a new Bitmap\n        Bitmap bitmap = new Bitmap(width, height, PixelFormat.Format24bppRgb);\n\n        // Define YUV constants for conversion\n        float yFactor = 1.164F;\n        float uFactor = 2.018F;\n        float vFactorR = 1.596F;\n        float uFactorG = -0.391F;\n        float vFactorG = -0.813F;\n\n        // Lock bitmap data for direct access\n        BitmapData bmpData = bitmap.LockBits(new Rectangle(0, 0, width, height),\n                                             ImageLockMode.WriteOnly,\n                                             bitmap.PixelFormat);\n\n        unsafe\n        {\n            byte* pYUY2 = (byte*)buffer;\n            byte* pBmp = (byte*)bmpData.Scan0;\n\n            for (int y = 0; y < height; y++)\n            {\n                for (int x = 0; x < width; x += 2)\n                {\n                    int y0 = pYUY2[0];\n                    int u = pYUY2[1] - 128;\n                    int y1 = pYUY2[2];\n                    int v = pYUY2[3] - 128;\n\n                    // Convert YUV to RGB for first pixel (x)\n                    byte r = ClampToByte(yFactor * y0 + vFactorR * v);\n                    byte g = ClampToByte(yFactor * y0 + uFactorG * u + vFactorG * v);\n                    byte b = ClampToByte(yFactor * y0 + uFactor * u);\n\n                    // Set first pixel (x) in bitmap\n                    int idx1 = ((y * width) + x) * 3;\n                    pBmp[idx1 + 2] = r;\n                    pBmp[idx1 + 1] = g;\n                    pBmp[idx1] = b;\n\n                    // Convert YUV to RGB for second pixel (x + 1)\n                    r = ClampToByte(yFactor * y1 + vFactorR * v);\n                    g = ClampToByte(yFactor * y1 + uFactorG * u + vFactorG * v);\n                    b = ClampToByte(yFactor * y1 + uFactor * u);\n\n                    // Set second pixel (x + 1) in bitmap\n                    int idx2 = ((y * width) + x + 1) * 3;\n                    pBmp[idx2 + 2] = r;\n                    pBmp[idx2 + 1] = g;\n                    pBmp[idx2] = b;\n\n                    // Move to the next set of YUYV values (4 bytes)\n                    pYUY2 += 4;\n                }\n            }\n        }\n\n        // Unlock the bitmap data\n        bitmap.UnlockBits(bmpData);\n\n        return bitmap;\n    }\n\n    // Helper function to clamp values to byte range\n    private static byte ClampToByte(float value)\n    {\n        return (byte)Math.Max(0, Math.Min(255, (int)value));\n    }\n}\n\n\nВот так легко и просто ChatGPT сгенерировал мне функцию перекодировки YUY2 в RGB, также я сделал для NV12, YUYV и I420. Если бы я писал это сам, я бы потратил на это, может быть, весь день, пока разбирался в этих форматах пикселей и отлаживал баги. А тут код написан за минуту и после визуальной проверки на отсутствие явной лажи уже работал в проекте, сразу же после компиляции. Ладно, если нужна бочка дёгтя на вашу ложку мёда, я вам её таки дам: так хорошо бывает не всегда, иногда он генерит нерабочий код, иногда рабочий, но неэффективный. Но можно попросить его ещё раз? и часто у него получается лучше.\n\n▍ Немного про экран\nПри удалённом управлении часто бывает, что размеры удалённого экрана превышают размеры окна, в котором мы работаем. И самый простой вариант — это обычное пропорциональное растягивание/сжатие картинки под размер рабочей области окна. \n\n\n\nНо, бывают ситуации, когда хочется видеть всё в масштабе 1 к 1, а удалённый экран больше нашего. И я отметил для себя 4 разных варианта, один из которых и реализовал:\n\n1. Просто скроллбары по краям, которые нужно скроллить мышкой вручную. Это не очень удобно.\n\n\n\n2. Стиль RAdmin — когда мы подводим мышку к краю окна и ведём её дальше, экран начинает скроллиться, а движение мышки блокируется. Уже лучше, но мне не нравится, что в этом случае при проскролливании нужно блокировать движении мыши.\n\n3. Стиль Aspia — когда мы подводим мышку к краю окна, окно начинает само скроллиться, перемещение мышки при этом не блокируется.\n\n\n\n4. По мере того, как мы ведём мышью от одного края нашего окна к другому, экран сам проскролливается к этому краю. Поначалу не привычно, но потом вполне удобно. Этот вариант мне понравился больше, и именно его я и реализовал.\n\n\n▍ Эмуляция устройства ввода\nС ESP32 S3 программа взаимодействует через ком порт. Она просто отправляет ей команды (KeyDown, KeyUp, MouseDown, MouseUp, MouseMove). Для мышки была выбрана эмуляция устройства с абсолютным позиционированием курсора, там передаются координаты x и y в пределах от 0 до 32768. Таким образом мне не нужно думать, какое разрешение на удалённом компьютере, всё будет работать само. С клавиатурой оказалось немного сложнее — получаемые коды клавиш нельзя было просто передать один в один в класс USBHIDKeyboard, точнее можно, но со своими приколами, которые местами все портили. Но можно было передавать сырые USBHID-коды, в которые нажатые клавиши надо было сконвертировать. Этот путь я и выбрал. Дальше эти нажатия/отжатия уже отправляются на устройство и эмулируются на конечной системе. Я не стал заморачиваться с перехватом особых спец-клавиш типа CapsLock, но на сегодняшний день у меня нет сценариев, где это могло бы потребоваться.\n\nПереходим к проверке:\n\nЗаходим в биос, загружаемся в ОС, проверяем, как работает мышь и клавиатура\n\n▍ А теперь сделаем это ещё лучше!\nВ процессе создания всего этого безобразия я решил, что его можно сделать ещё безобразней! А именно: мне внезапно может потребоваться перезагрузить компьютер, если он завис наглухо. Или выключить, а то чего он тут работает? А потом включить потому, а то чего это он не работает? Для этого надо замкнуть соответствующие пины на материнской плате. Это разъём Fpanel и нам нужны вот эти ребята:\n\n\nУ меня дома валялось пара реле с управлением от 3 вольт, и я подключил его управление к пинам ESP32 S3, а замыкание к пинам материнской платы и… естественно, ничего не заработало, потому что нельзя подключать реле к пинам ESP32 напрямую, они не дают такой ток, чтобы сработала катушка реле, но:\n\nДяденька, я, на самом деле, не настоящий электронщик, я этот паяльник нашёл!\nЛадно, у меня валялись ещё IFR3205. Не надо на меня так смотреть, я понимаю, что использовать их для включения реле — это дикая дичь, они были рождены летать, а не ползать. Но ничего не выйдет, потому что, я сказал «ползать» и они поползли! Я не буду выкладывать схему подключения этого безобразия, потому что мне стыдно. Проще взять готовые к подключению напрямую реле типа этих и не париться:\n\n\nЯ использовал пины 17 и 18, но если нужны другие, можно поменять это в скетче.\n\nИтак, теперь у меня заработали кнопки перезагрузки и включения удалённого компьютера. Также я добавил возможность ввода текста из буфера обмена эмуляцией нажатия этих клавиш (как в HyperV). Программа даже умеет переключать раскладку, если видит русские буквы в тексте. Главное, чтобы изначально раскладка на удалённой системе всегда была выбрана английской, а то будет всё наоборот. И вроде бы всё было закончено. Но тут мне пришла в голову ещё одна безумная идея…\n\n▍ А как насчёт реальной камеры?\nДа, ведь мне могут принести ноутбук или моноблок, у которого может и не быть второго видеовыхода, а если и быть, то не факт, что он будет выводить туда стартовую загрузку. Поэтому я могу просто поставить камеру перед экраном и брать изображение с него. Но! Я же никогда не смогу поставить камеру настолько идеально ровно, чтобы экран был чётко в кадре, не вылезая из него и не оставляя лишнего по краям. А если экран не будет точно заполнять кадр, то собьются и координаты мыши. Поэтому мы будем натягивать сову на гло изображение с камеры на наш виртуальный экран. Здесь мне было откровенно лень. Я попросил ChatGPT сгенерить мне функции для Perspective Image Distortion. После N попыток он привёл меня к библиотеке Emgu.CV, которая делала это достаточно быстро, и я накидал редактор для этого растягивания. \n\n\n\nТеперь мы можем натянуть картинку с камеры на наш экран, и мышка ездит от угла к углу достаточно точно. Качество изображения, конечно, прекрасно настолько, что от работы с такой картинкой возникает непременное желание куда-нибудь выйти, например, в какое-нибудь ближайшее окно. Но тут уже всё зависит от качества камеры. Главное, возможность есть.\n\nГотовы поработать так на удалёнке весь день?)\n\n▍ Бонус\nНе люблю я, когда устройство не похоже на устройство. У меня давно сложилась простая схема для создания корпусов:\n\n\nА ещё у меня есть 3D-принтер! Поэтому проектируем такую коробочку:\n\n\n\nЯ делал под свои реле, но это OpenSCAD и там легко можно задать размеры и количество для своих.\n\nЯ всегда делаю корпуса под болтики для компьютерных вентиляторов, они хорошо вкручиваются и крепко держатся в пластике и не нужно вплавлять гайки\n\nВоплощаем это в пластике\n\nТеперь собираем всё вместе\n\nТермоклеем делаем блямбы на проводах, чтобы не оторвать пайку, если дёрнуть за них\n\nА вот и устройство. Во всяком случае похоже на устройство. Если бы я не знал, как выглядят устройства, я бы подумал, что это, возможно, оно.\n\nКажется, это устройство\n\n▍ Дайте мне это немедленно!\nКак обычно, всё, что я сюда выкладываю — MIT, поэтому делайте с этим, что хотите, кроме модифицированной AForge, там GPL/LGPL, но я все исходники выложил и чист перед ними)\n\nСтраница проекта: тут. \nНо на всякий случай предупреждаю, что я особо не сижу на GitHub, редко туда захожу, не часто там отвечаю, просто выложил и забыл. А сюда пишите, отвечу)\n\n© 2024 ООО «МТ ФИНАНС»\n\nTelegram-канал со скидками, розыгрышами призов и новостями IT 💻",
    "Безопасная разработка: как обеспечить безопасность разрабатываемых продуктов": "1. Предпосылки и потребностьПотребность в разработке безопасных продуктов с каждым годом только возрастает. Востребованность продуктов, для которых «из коробки» обеспечивается необходимый уровень безопасности, в первую очередь, возникает на объектах критической информационной инфраструктуры (КИИ). Но только ли для них? За последние годы мы очень наглядно и на практике видим, что безопасность продуктов стала одним из важнейших критериев, который потребители ожидают от качественного продукта. Новостные ленты регулярно пестрят сообщениями: «такая-то организация взломана», «в таком-то продукте найдены критичные уязвимости, выявлена возможность несанкционированного управления этим продуктом». И затронуто уже большинство областей: медицина и образование, предприятия производства и услуг, про банки и информационные организации можно даже не упоминать.Потребность огромна, обоснована, но что с возможностями и готовностью рынка?2. Какие методы использовались раньше?Для начала давайте вспомним, какие методы обнаружения уязвимостей уже существуют, легко встраиваются в жизненный цикл разработки программного обеспечения (ПО) и апробированы временем.В первую очередь, рассмотрим различные методы тестирования разработанного ПО:«Ручные» методы тестирования:Ревью кода – это ручная валидация кода сотрудником-разработчиком, не являющимся автором этого кода.Функциональное и нагрузочное тестирование механизмов безопасности ПО – вид тестирования, который проверяет соответствие функциональности и отказоустойчивости (способности функционировать под нагрузкой с заявленными характеристиками) механизма безопасности продукта тому, как он был задуман.Тестирование на проникновение – проверка защищённости продукта, при которой моделируются реальные атаки злоумышленника (хакера). Автоматизированные методы тестирования:Unit-тестирование механизмов безопасности ПО – автоматизированные модульные тесты, позволяющие проверить на корректность отдельные модули (небольшие части кода). Позволяет оперативно тестировать внесенные изменения в раннее разработанный код.Статический анализ кода (SAST) – анализ исходного кода и бинарных файлов на предмет условий кодирования и проектирования, которые указывают на уязвимости. Это один из самых распространенных методов тестирования ПО на уязвимости. Тестирование осуществляется без запуска ПО (статически), проверки проводятся по принципу «белого ящика» (метод тестирования, основанный на анализе внутренней структуры и механизмов ПО, возможен при наличии исходных кодов).Динамический анализ (DAST) – тестирование ПО во время выполнения, осуществляется по принципу «черного ящика» (метод тестирования ПО и его поведения без знания внутренней структуры), т.е. без доступа к исходному коду, и предназначено для намеренного вызова сбоев в работе ПО. Композиционный анализ (SCA или анализ сторонних компонентов) – анализ состава ПО и выявление в нем и в сторонних компонентах уязвимостей на основе информации открытых баз уязвимостей (например, банк данных угроз безопасности информации ФСТЭК России).Т.е. на жизненном цикле (ЖЦ) продуктов методы обеспечения безопасности распределялись[1] следующим образом (см. рисунок 1):Рис. 1. Практики безопасной разработки на ЖЦ. Этапы выпуска релиза и предрелизного тестирования[1] Этапы ЖЦ ПО, на которых применяются практики безопасной разработки, выделены бирюзовым цветом.3. С чего начать развитие?Если оценивать визуально на схеме (рисунок 1) и применительно к основным этапам жизненного цикла продуктов, наглядно видно, что основные проверки приходятся на финальные этапы (на схеме выделены бирюзовым цветом): либо перед выпуском релиза – этап предрелизного тестирования, либо в момент его выпуска. Но рентабельность такого подхода сразу вызывает вопросы с точки зрения бизнеса. Итог прост:Благодаря применяемым методам тестирования на рынок мы выпускаем более безопасный продукт.Стоимость устранения уязвимостей, выявленных в результате тестирования, максимальна. Т.к. для исправления таких уязвимостей требуется переписывать, как минимум – часть кода, как максимум – перерабатывать архитектуру, если ошибка допущена на этапе проектирования.Рассмотрим какими методами и механизмами можно снизить стоимость обеспечения безопасности продукта при его разработке. Сначала оцениваем основные этапы ЖЦ продукта по следующим критериям: Что можно «покрыть» наименьшими усилиями, включая временные?Что обеспечит наибольший эффект?И здесь напрашивается применение концепции Shift-left или «максимальный сдвиг влево». При таком подходе необходимо охватить методами обеспечения безопасности продукта этапы его ЖЦ по возможности максимально сдвигаясь влево.Как это будет выглядеть:Этап 1. Сдвигаем все применяемые в организации методы тестирования на этап разработки (см. рисунок 2):Рис. 2. Практики безопасной разработки на ЖЦ. Включаем этап разработкиРезультаты получаем быстро и ощутимые: 1.      Не требуется выделять значительное время на одномоментное выполнение всех видов тестирования. Достаточно оперативно проводить тестирование меньших блоков разработанного кода (модулей).2.      Исправление выявленных уязвимостей так же занимает меньшее время и меньше усилий, т.к. у разработчика еще «свежа информация» и не требуется повторное погружение в контекст исправляемого функционала.3.      Разработчик, столкнувшись с выявленными уязвимостями (например, с небезопасными конструкциями в коде), далее, при разработке следующих блоков кода, перестает совершать ошибки того же типа. Т.е. прямо в процессе разработки получаем повышение безопасности кода. 4.      На финальных этапах при выпуске готового релиза количество выявляемых уязвимостей снижается в разы. Соответственно, уменьшается время выпуска релиза на рынок.Этап 2. Более трудоемкий для внедрения, но позволяющий получить качественный скачок безопасности продукта изначально – охват практиками безопасной разработки этапов ЖЦ, как можно «левее». Такой сдвиг применения практик безопасной разработки позволяет избежать «детских» (и наиболее критичных) уязвимостей в продукте. Речь идет об ошибках, допущенных на этапе проектирования, которые невозможно закрыть минимальными доработками кода, и несущих в себе высокие риски безопасности.Приведем наглядный и критичный вариант такой ошибки проектирования: Рассмотрим продукт с распределенной архитектурой для обеспечения его отказоустойчивости. Продукт по умолчанию разворачивается таким образом, что его отдельные функциональные блоки установлены и функционируют на различных серверах. Обмен данными при таком варианте осуществляется путем прямого доступа к единственной базе данных (БД) всех функциональных компонентов этого продукта. Т.е. БД со всей информацией этого продукта «вынесена» на поверхность атаки. Быстро исправить такую недоработку архитектуры не представляется возможным, т.к. все функциональные компоненты продукта просто «не умеют» работать иначе.Чтобы избежать изначально подобных проблем, «сдвигаем» применение практик безопасной разработки по максимуму влево (см. рисунок 3):Рис. 3. Практики безопасной разработки на ЖЦ. Охватываем начальные этапы (от идеи до проектирования)Какие есть практики, позволяющие повысить безопасность разработки, для более ранних этапов ЖЦ:Идея – с учетом видов продуктов, разрабатываемых в конкретной организации, формируется некоторый набор верхнеуровневых требований безопасности, который заведомо должен учитываться при разработке каждого продукта.Аналитика – подход, аналогичный этапу «идеи»: так же формируется перечень общих требований безопасности, но уже более детализированных, которые должны учитываться при разработке каждого продукта, выпускаемого организацией-разработчиком.Проектирование:·         Моделирование угроз – практика безопасной разработки, позволяющая определить потенциальные и реальные угрозы для уже разработанной архитектуры продукта. Цель выполнения практики: определить существующие угрозы безопасности, их применимость, критичность и последствия; выработать меры, позволяющие закрыть, либо снизить критичность выявленных угроз. ·         Принципы и паттерны безопасной разработки – «превентивная» практика безопасного проектирования. Позволяет заранее, перед или во время проектирования ориентироваться на некоторые примеры, как «правильно» проектировать (паттерны) тот или иной механизм или взаимодействие, или как категорически нельзя реализовывать конкретный механизм/взаимодействие (анти-паттерны). Т.е., паттерны – это именно «ориентир» в проектировании, «как именно» стоит проектировать (шаблон);а принципы – это их верхнеуровневая агрегация, т.е. «что» необходимо выполнять при проектировании.Дополним предыдущий пример проектирования актуальным принципом и паттерном:принцип безопасного проектирования: «Минимизация поверхности атаки»;паттерн: «Доступ внутренних функциональных компонентов ПО к данным этого ПО осуществляется посредством доступа к выделенному API ядрового компонента ПО».Что получаем:Отсутствие «детских» и наиболее критичных уязвимостей, «заложенных» в архитектуру продукта.Минимизацию уязвимостей на уровне архитектуры, соответственно и на последующих этапах разработки продукта.Сокращение (исключение) трудозатрат на пере- или значимую доработку архитектуры при выявлении уязвимостей проектирования на более поздних этапах разработки.Этап 3. Shift RightПоговорили про важность обеспечения безопасности разработки до выпуска релиза продукта. Рассмотрим, что делать с этапами после. Насколько необходимо предусматривать механизмы, позволяющие обеспечивать безопасность разработанного и готового продукта после его выпуска?Для обеспечения комплексной безопасности разрабатываемого продукта с точки зрения эксплуатации конечным пользователем, несомненно, необходимо предусмотреть дополнительные механизмы и рекомендации. Основные из которых – это:Автоматизированный механизм инсталляции, обеспечивающий установку продукта с рекомендуемой по умолчанию базовой безопасной конфигурацией.Руководство пользователя и администратора. Руководства должны содержать описание механизмов безопасности, возможных параметров их конфигурирования и рекомендации по обеспечению безопасной настройки.В процессе эксплуатации рекомендуется регулярно, с некоторой периодичностью, проводить анализ эксплуатируемого продукта и его сторонних компонентов на уязвимости, ориентируясь на информацию в открытых базах уязвимостей (например, БДУ ФСТЭК России).Для этапа «вывода из эксплуатации», с точки зрения безопасности, необходимо зафиксировать срок технической поддержки. В течение такого установленного срока организация-разработчик обеспечивает поддержку разрабатываемого продукта, включая рекомендации по безопасному (пере)конфигурированию и закрытие уязвимостей, если такие будут выявлены.Таким образом, выполняя практики безопасной разработки на каждом этапе ЖЦ продукта, мы добиваемся его максимально возможного уровня безопасности на каждом из этапов (см. рисунок 4):Рис. 4. Практики безопасной разработки на ЖЦ. Этап эксплуатации и ее завершение 4. Иные направления. Что важнее? И как развивать?Цикличность ЖЦ продуктов.Обсудили практики и методы безопасной разработки. Но необходимо рассмотреть процесс разработки в целом и оценить, какие еще существуют направления, обеспечивающие повышение безопасности разработки. Оценим процессы и методологию управления.Процесс разработки продукта не линеен, это итерационно повторяющийся цикл основных этапов (см. рисунок 5):Рис. 5. Практики безопасной разработки на ЖЦ. Цикличность разработкиКомплексная безопасность продуктов. Подход.Но для обеспечения комплексной безопасности продуктов выполнения одних практик безопасной разработки недостаточно. Подход должен быть именно комплексным и обязательным условием такого подхода должно быть обеспечение безопасности процессов разработки и используемой инфраструктуры.Рассмотрим безопасность самих процессов. Ключевые направления, необходимые для обеспечения безопасности процессов следующие:Регламентация безопасной разработки (политика, регламенты, положение о безопасной разработке) – верхнеуровневые регламентирующие документы, определяющие направления обеспечения безопасности в организации, обязательные к использованию правила и механизмы.Процессы и люди – регламентация каждого процесса, правила его функционирования, задействованные роли сотрудников и их зоны ответственности на каждом этапе.Методология – детальные инструкции с рекомендациями по выполнению практики, процесса, использования конкретного механизма или сервиса.Автоматизация – реализованная совокупность сервисов, механизмов и средств, используя которые возможно конфигурирование того или иного действия или процесса частично или полностью без участия человека.Приоритет. Очередность.С направлениями, востребованными к доработке в части обеспечения (повышения) безопасности разрабатываемых продуктов, определились. Но как определить, что приоритетнее? В какой последовательности дорабатывать то или иное направление? До какого уровня необходимо продолжать доработку и что считать критерием достижения цели?Подходов может быть несколько. И приоритет того или иного направления может быть повышен, исходя из целей и задач, актуальных для конкретной организации-разработчика. Индивидуальные потребности и путь их достижения возможен всегда. Но классический системный подход заключается в равномерном, взаимосвязанном и взаимодополняющем развитии всех направлений. В таком случае, развивая одновременно все направления и закладывая при их модернизации необходимость взаимосвязанности, на выходе получаем усовершенствованные связные процессы, позволяющие при минимуме трудозатрат максимально повысить комплексную безопасность разрабатываемых продуктов.Пример подобной связности процессов и их взаимного дополнения приведен на рисунке 6 и включает:Рис. 6. Связность процессов безопасной разработки на примере статического анализаРегламентация: разработано положение о безопасной разработке, являющееся верхнеуровневым регламентирующим документом организации-разработчика. Одной из практик безопасной разработки зафиксировано требование обязательного проведения статического анализа всех разрабатываемых продуктов.Процессы и люди:-        разработан регламент проведения статического анализа, в котором определены этапы процесса ЖЦ, на которых должна применяться практика, прописаны условия и критерии ее применения;-        в регламенте проведения статического анализа зафиксированы роли и зоны ответственности сотрудников, задействованных при выполнении данной практики.Методология: разработана инструкция по правилам и рекомендациям разбора выявленных уязвимостей.Автоматизация: -        в инфраструктуре сборочного конвейера установлен и сконфигурирован статический анализатор, позволяющий проводить статический анализ кода разрабатываемого продукта (например, Svace);-        подготовлены шаблоны для конфигурирования интеграции со статическим анализатором в процессе сборки конкретного продукта;-        разработана пошаговая инструкция для конфигурирования интеграции.Итеративность и актуализация.Один из важнейших критериев внедрения любых изменений в процессы организации: никогда не стоит забывать про итеративный подход. Хотелось бы, конечно, с первой итерации получить идеальный программный продукт с максимально возможным уровнем безопасности. Однако подобное возможно только в теории, чаще всего при попытке достичь «идеала» получим «перекос» в одном или нескольких направлениях (регламентация, методология, автоматизация). Развивать одновременно все и с максимальным уровнем детализации долго и дорого, оперативно внедрить необходимые изменения не удастся. Чтобы подобного избежать, стоит использовать итерационный подход. Разбить модернизацию каждого направления на сопоставимое количество итераций, приоритизировать необходимые изменения, разработать план внедрения и, в соответствии с планом, последовательно вносить требуемые улучшения.И так же не стоит забывать о необходимости периодической актуализации каждой ранее внедренной практики, процесса, механизма и метода. Со временем могут модифицироваться цели и задачи самой организации, потребности потребителей разрабатываемых продуктов, требования регуляторов, могут появляться новые практики и механизмы. Все такие изменения нужно обязательно регулярно оценивать и учитывать во внутренних процессах организации.5. Информирование и обучениеПрактики безопасной разработки внедрены, регламентация и процессы доработаны, механизмы автоматизации настроены и готовы к использованию – все готово к разработке безопасных продуктов. Для оперативного применения всех обеспечивающих функций и механизмов не хватает одного – понимания сотрудников как всем этим пользоваться, в какой момент времени и какая роль у каждого из участников.И здесь нам поможет:Введение практики обязательного информирования сотрудников о вносимых изменениях.Пилотирование каждого изменения на фиксированном количестве участников; обязательный сбор обратной связи по результатам пилотирования и внесение изменений по результатам этой обратной связи.Подготовка информационных и обучающих материалов по тематике вносимых нововведений. Причем информационные материалы должны обязательно учитывать роли сотрудников, на кого эти изменения будут влиять. Информирование менеджерского состава должно осуществляться с необходимым для данной роли уровнем погружения, т.е. для данной роли достаточным будет являться информирование об изменениях на уровне процессов, задействованных механизмов и результата, который достигаем благодаря нововведениям. А для роли разработчика инструкции должны формироваться с совершенно иным уровнем грануляции, и помимо процессных изменений необходимо обязательно подготовить низкоуровневые технические правила и рекомендации.Так же очень востребованным будет формирование полноценного обучающего курса по каждой тематике вносимых изменений, желателен аналогичный учет специфики отдельных ролей сотрудников. Подготовку и проведение уже полноценных циклов обучения нужно планировать отдельно и проводить со специалистами в дополнение и после первоначального погружения. Такое обучение – так же один из механизмов, позволяющих повышать осведомленность сотрудников о важности и возможностях повышения безопасности разрабатываемых продуктов.6. РезультатТеперь сведем все воедино, в единый чек-лист, что необходимо выполнить в организации для обеспечения разработки безопасных продуктов:Безопасность процесса разработки:Верхнеуровневая регламентация учитывает необходимость безопасной разработкиПроцессы доработаны с учетом фокуса на обеспечение безопасности разрабатываемых продуктовПодготовлены низкоуровневые инструкции, рекомендации и чек-листы для каждой практики безопасной разработкиВнедрены сервисы и механизмы, позволяющие максимально автоматизировать выполнение практикПрактики безопасной разработки:Внедрены практики безопасной разработки на всех этапах ЖЦ ПООбеспечивается безопасность инфраструктуры, используемой в процессе разработкиВыполняются обязательные критерии:Все модификации процессов проводятся итерационноВсе процессы и методологии регулярно актуализируютсяОбеспечивается оперативное и своевременное информирование участников о планируемых измененияхОбеспечивается обучение участников процессов практикам безопасной разработкиРезультат. Что получаем.На выходе, при использовании описанного подхода и выполнения обязательных критериев, мы получаем продукты с максимально возможным уровнем безопасности для каждого уровня зрелости организации. И одновременно обеспечиваем минимизацию трудозатрат на выполнение практик безопасной разработки.Практики безопасной разработки успешно применяются ведущими вендорами страны, например, компанией «ИнфоТеКС», которая входит в число лидеров российских разработчиков и производителей высокотехнологичных программных и программно-аппаратных средств защиты информации. Использование описанных подходов на практике позволяет ИнфоТеКС обеспечивать безопасность разрабатываемых продуктов экосистемы ViPNet и качественно и оперативно оказывать поддержку их потребителям.",
    "Cоревнования по программированию для тех, кто пишет на Rust": "В этом году мы решили провести RustCon Contest — соревнования по программированию для тех, кто пишет на Rust или только начинает его изучать. Старички конференции помнят, что мы уже проводили его в далеком 2021. Интересно посмотреть, как изменились ваши скиллы за эти годы. В этом году мы проводим его вместе с компанией «Криптонит», которая предоставила задачи для участников.Занявший 1 место получит билет на RuctCon и памятную футболку, обладатель 2 места — билет на RustCon, а бронзовый призер — футболку. Все остальные участники  — скидку 10% на RustCon 2024.Как устроен RustCon ContestСоревнования состоят из двух частей. Первая часть — решение задач на языке Rust. Вторая — Open-source contribution contest. Участвовать можно как в одной части, так и в обеих.Первая часть контеста рассчитана для тех, кто пишет на Rust или других языках (Python, C++, Ruby, Java и пр.), но хочет попробовать себя в ржавчине. Задачи будут размещены на CodeForces. Каждую неделю будет публиковаться по две задачи, решить которые нужно за 3 часа. Соревнование будет длиться 4 недели (итого, 8 задач). Все решения должны быть написаны на языке Rust.Задача второй части — внести наибольший вклад в открытые Rust-проекты. Под вкладом подразумевается добавление/изменение кода на языке Rust путем публикации Pull Request с указанием участия в конкурсе и ссылки на RustCon Russia.Даты проведения: С 1 ноября по 2 декабря 2024 годаКак принять участие:Зарегистрируйтесь на платформе CodeForces или зайдите в свой аккаунт.Заполните данные о себе в форме, чтобы судьи могли вас идентифицировать.Пройдите по ссылке RustCon Contest 2024 и нажмите \"Вступить в группу\" в правом нижнем углуПерейдите по ссылке, и выберите удобное для вас время стартаРезультаты контеста выложим на этой странице 25 ноября Площадка для прохождения второго тура: githubПодходящие проекты: не меньше 100 звезд и нет аффилиации участника с владельцем репозитория.Допустимые лицензии проектов: MIT/Apache/BSD/GPL/MPL/CC и аналоги. Как подводятся итогиВыше находятся те участники, которые решили больше задач.При равном числе задач выше находятся те участники, которые имеют меньшее штрафное времяШтрафное время вычисляется как сумма штрафных времён для всех задачШтрафное время для одной задачи — это время прошедшее с начала соревнования до момента отправки верного решения + 20 минут за каждую неудачную попытку, сделанную до отправки верного решения*Задача считается решённой, если ваш код прошёл все тесты на платформе CodeForces (тестирование происходит в реальном времени) Если вы уже купили билет на RustCon, а затем стали победителем контеста — ничего страшного, вернём деньги!RustCon Contest — наш вклад в развитие сообщества. Мы будем признательны, если вы расскажете о соревнованиях друзьям и коллегам, пишущим на Rust, или тем, кто задумался об изучении этого классного языка. Чем больше участников, тем острее борьба и приятнее вкус победы. Всем удачи!",
    "Провели в ИТ-компании ребрендинг и завели кота: что это изменило": "Привет! Я — Анна Астахова. Вместе с мужем руковожу ИТ-компанией. Долгое время мы не придавали много значения тому, как название влияет на нашу работу, какой логотип мы используем, как оформлены презентации и т. д. Но в определенный момент решили подключить маркетинг, и одной из первых больших задач стал ребрендинг. В этой статье подробно рассказываю, что делали и что получилось.В 2015 году мой муж Сергей зарегистрировал ООО «Хороший учет». Это было началом большого дела, которым сейчас мы занимаемся вместе. Позже появилось название BPCA — Business Processes Consulting Analysis. В таком формате мы существовали еще несколько лет. Однако я стала замечать, что это название коверкают не только клиенты, но и сотрудники. Пару раз я слышала, как говорили «БэПэЦэА». Тогда появилась мысль провести ребрендинг и придумать новое название. В итоге мы решили сменить название, логотип и фирменный стиль. В начале 2023 года у нас сформировался полноценный отдел маркетинга, и летом мы приступили к задаче.Считаю, что ИТ-компаниям важно иметь понятное название. Вот несколько аргументов:1. Узнаваемость. Название помогает выделиться. Это важно в сфере информационных технологий. Сегодня на рынке много компаний, конкуренция высокая. К июню 2024 года в России насчитывалось 217 993 ИТ-компании, по данным главы экосистемы «Контур». Это на 14% больше, чем в январе 2022 года. 2. Легкость запоминания. Простое название легче запомнить потенциальным клиентам и партнерам. Согласно данным, опубликованным Simply Business в феврале 2023 года, потребители с большей вероятностью будут взаимодействовать с компанией, если у нее забавное, запоминающееся название.3. Позиционирование. Название может отражать основные ценности, миссию и принципы работы. К тому же это помогает продвигать компанию в социальных сетях и других каналах коммуникации, создавать рекламные кампании.Этап 1. Новое название. Что вместо BPCA?Мы понимали, что нужно что-то простое и запоминающееся, при этом название должно отражать нашу деятельность — интеграции систем и построение корпоративной отчетности, также мы автоматизируем работу с помощью 1С. Наша сильная сторона — глубокая экспертиза. В названии нам хотелось отразить именно это, а также показать, что мы — современная компания, так как иногда за франчайзи 1С тянется шлейф чего-то сложного и устаревшего. Мы придумали около 60 названий, большую часть вариантов выдал наш маркетолог Станислав. Среди них были:ШТРИХСХЕМАЭЛЕМЕНТОБОРОТАПЕКСОСНОВАФАЗАСИРИУСЯ читала список, примеряла каждое и вдруг в самом конце увидела вариант «Белый код». Его же отметил мой муж. Мир ИТ для бизнеса с каждым годом становится сложнее: нейронные сети, распознавание лиц и т. д., появляются новые сервисы, ужесточаются требования к безопасности и отказоустойчивости. Все больше компаний осознают, что ИТ-инфраструктура — ядро, от работы которого зависит развитие бизнеса. В названии «Белый код», на мой взгляд, заложены такие смыслы как: «надежный партнер», «чистая работа», «прозрачная система».Название с одной стороны отражает специфику — связано с программированием, кодом, интеграцией, технологиями, с другой — указывает на прозрачность, чистоту, аккуратность работы. Также в названии заложена игра слов, в слове «код» при произношении оглушается звук Д, возникает персонаж — белый кот. Его можно интегрировать в логотип, в жизнь компании, он может стать тем самым узнаваемым символом, появляться в комиксах, стикерах, мемах, этот образ удобно использовать и привлекать. В конце концов, пользователи интернета любят котиков.                                 Станислав Селезнев, маркетолог, ИТ-интегратор «Белый код»Этап 2. Логотип и битва дизайнеровСледующий важный этап, который нас ждал, — создание логотипа. Мы сразу определились, что кот — это добавочный образ, хорошо, если он будет, но первичен и важен для нас код, так как мы ИТ-компания.Тот дизайн, который у нас был, соответствовал среднестатистической компании-интегратору 1С, которая существует на рынке уже не первый год и находится в стадии стагнации. При этом ментально наша компания молодая, прогрессивная, с развивающейся внутренней корпоративной культурой. У нас довольно много молодых ребят в команде, самому молодому сотруднику всего 20, а начинал он работать с нами в 16. Мы открыты новому, пробуем, но при этом у нас уже большой опыт, и это мы хотим транслировать.Задачу я также отдала маркетологу Станиславу. Он нашел дизайнера, договорился и начал работать.Прежнее название коверкали и сотрудники, и клиенты. Провели ребрендинг ИТ-компании и устроили битву дизайнеровЯ намеренно не пошел в дизайн-студию, а выбрал специалиста, у которого было большое желание пополнить портфолио хорошим логотипом. У тех, кто делает много логотипов, уже есть отработанная схема: делаем 3 варианта, можно вносить столько-то правок. Дизайнер, которого нашел я, не просто включилась в работу, она присылала наброски, варианты, с благодарностью принимала всю обратную связь и возвращалась с новыми вариантами. У нас была работа на результат.Станислав Селезнев,маркетолог, ИТ-интегратор «Белый код»Первые наброскиПервые наброскиИзначально дизайнер создала множество вариантов, вместе с маркетологом они выбрали три, которые представили мне.Мне надо было определить основной вариант, и в этот момент появились сомнения. Ведь этот логотип — то, что будет с нами ближайшие годы. Через него с компанией «Белый код» будут знакомиться клиенты. Я посоветовалась с мужем, спросила мнения у коллег из других компаний, и появилась идея параллельно поработать еще с одним дизайнером. Мы договорились, что он сделает один вариант, а если не подойдет, то еще один.В этот момент фактически мы стали соревноваться, появились две команды. Хотя у меня не было особого отношения к «своему» дизайнеру, просто хотелось посмотреть разве подходы и выбрать лучший вариант. Спустя неделю мы получили логотип от нового дизайнера.Первый вариант другого дизайнера Он оказался слишком неформальным и чересчур милым. Не было ощущения серьезной компании. Решили попробовать еще раз. Второй лого мне понравился, но хотелось доработать. В итоге получили разные варианты.Еще один вариантВариант после доработки И вот настал решающий момент. Надо выбирать. Станислав настаивал на «своем» логотипе, аргументируя, что этот вариант выглядит современно, лаконично и отражает сразу все смыслы, при этом код первичен. Мне нравился тот последний вариант, который прислал «мой» дизайнер. Напряжение нарастало. Когда стало понятно, что сообща мы к решению не придем, отправились к коллективу. В общем чате устроили голосование за логотип.Голосование за логотип Победил вариант, который нравился мне. Правда, проголосовали не все. Вроде бы все решилось. Но прошло несколько дней, я набрала Станислава и сказала, что в итоге мы остановимся на том варианте, который продвигал он. Сегодня «Белый код» — это…  Почему так? Во-первых, аргумент Станислава, что логотип должен быть функциональным и отражать наш посыл, меня убедил. Во-вторых, когда я вижу, как кто-то из сотрудников искренне «болеет» за наше дело и хочет лучшего, я стараюсь это поощрять и поддерживать. Для Станислава это был хороший кейс по ребрендингу компании, а для меня — отличный результат и лояльность отдела маркетинга, который фанатеет от нашего нового стиля. Этап 3. Создание маскотаПосле полного ребрендинга для отдела маркетинга стояли новые задачи. Сфера ИТ довольно сложная, хотелось добавить простоты и легкости. Еще одна проблема — обложки для статей в блог. Каждый раз нам приходилось что-то выдумывать. Нужна была единая концепция, при этом интересная, привлекающая внимание и простая в реализации. Решили, что отличным инструментом станет маскот, которого мы сможем внедрять в контент и добавлять в мерч компании. Маскот — символ компании. Он помогает:повысить узнаваемость бренда,выделить компанию среди конкурентов,увеличить количество лояльных клиентов, вовлечь пользователей. Многие названия брендов мы можем отгадать, увидев лишь маскота. Например, кролик от Nesquik. Кстати, изначально его звали Quik Bunny (от англ. quick — быстрый). Намек на то, что сухие завтраки можно приготовить очень быстро. Также быстро, как бегают кролики.Название нашей компании – это игра слов «код» и «кот», поэтому вопроса, кто станет маскотом, не возникло. Конечно, белый кот! Решили, что сделать маскота будет не так уж сложно. Поэтому не стали обращаться к дизайнеру, а оставили задачу в отделе маркетинга. Тем более что там у нас свой начинающий дизайнер-маркетолог Тася. Думали, что закроем эту задачу за месяц, а в итоге на создание кота ушло где-то полгода. Коты появлялись и уходили, мы делали перерывы и снова брались за задачу.Первым прототипом стал котик Баг, со своей небольшой историей. Понятные формы, цвета, эмоции. Слишком простой для талисмана компании. «Знакомься — это Баг. Прототип талисмана компании. Это не конечный результат, а макет. На пузике у него пятнышко, напоминающее лого компании. Отличительная черта этого котика — сиреневые глаза и ещë пять пятнашек под левым глазом.Никто не любит баги, поэтому котенок скитался по паутине кода и забрëл к нам, потому что все баги мы берëм на себя, а клиенты получают \"чистые\" проекты)»На первый взгляд кот вышел слишком простым, его история получилась интереснее. Решили поэкспериментировать.  После истории с Багом взгляд пал на необычных котов с внешней особенностью. Они рисовались уже без истории, был важен сам образ.Мы обращались к нейросетям, получались космические котики.Но всё это было не то. Талисман компании должен запоминаться, при этом не отходить от изначальной концепции: толстый, милый, запоминающийся. Накануне Нового года мы выпустили мерч с новым логотипом. А мне захотелось еще и худи для детей. И если на одежде для взрослых можно было разместить просто название компании, то для детских худи хотелось чего-то забавного. Тогда отдел маркетинга сделал ещё один вариант кота. Тот самый милый и пухлый. Правда, для основного он всё равно не подходил, слишком много деталей.Этот образ упростили для корпоративных открыток. Кот запомнился многим, но все еще был сырым для маскота. Тут мы уже поняли, что проблема первого прототипа была в том, что он был в статике. Нужно было дорабатывать то, что его окружает, чтобы он стал живым.  Еще одна попытка изобразить кота была приурочена к Международному женскому дню. Формы стали более мягкими и тягучими, ведь все мы знаем, как коты могут поместиться в трехлитровую банку. Общим голосованием решили дорабатывать новогодний вариант. Последний образ и отбор внутри отдела дополнили картину. Мы объединили три последних варианта, так получился тот самый символ компании, который был нужен. Оставалось только доработать линии, добавить детали, которые будут его окружать, и придумать ближний и дальний план кота. Кота мы завели, но имени еще не было. В чат компании отправили итоговый вариант маскота и предложили коллегам накидать варианты. Вот несколько идей из чата:Абзац СнежокБагАйсВайсикВ итоге выбор сделали в пользу Айса — лаконичное и запоминающееся имя.  Конструктор кота: как мы упростили задачу по созданию контентаАйс быстро прижился в компании, хочется создавать с ним контент и добавлять кота в письма, статьи, посты, открытки. Тогда наш маркетолог Тася придумала гениальную вещь – «конструктор кота». Айс может показаться примитивным, но мы не дизайнерская студия, а Тася выполняет и другие задачи в маркетинге, мы не можем тратить много часов на создание картинок. Конструктор упростил этот этап. Мы относились к инструменту скептически, пока не увидели его в работе. «Конструктор кота» состоит из основных форм, поз и эмоций Айса. Когда нужно новое изображение, Тася собирает тело, хвост, лапы, глаза в одну картинку и немного дорабатывает в зависимости от идеи. Это своего рода паспорт кота. Тут прописаны все его особенности для будущих коллег отдела маркетинга, чтобы в контенте всегда был именно наш кот Айс.Сейчас мы внедряем Айса в различные маркетинговые активности.Изображения, созданные благодаря «Конструктору кота»Идея с брендированными стикерами давно ждала своего часа, и вот, когда появился талисман, мы начали работать над созданием стикерпака. За многими нашими стикерами скрывается внутренняя история.Например, один посвящен мне. На одном из созвонов с отделом маркетинга зависло изображение. Встреча была очень эмоциональная, и получился скриншот, который стал прототипом для стикера эмоции «гнев».Или другой пример — Айс с катаной. Отделу маркетинга нравится тематика ниндзя и восточных единоборств. Внутри отдела есть фраза «достать катану», это значит, что нужно показать своё мастерство и быстро закрыть задачу. С приходом кота катаны стали кОтанами, а еще появились два тематических стикера.Некоторые стикеры изображают популярные выражения. Угадали, какое мы зашифровали в этом варианте? Посмотреть все стикеры можно тут. А еще кот Айс любит участвовать в диалогах! Поэтому будет рад, если вы возьмëте его с собой на встречи в Телеграме. А постоянное место обитания Айса — блог нашего сайта. Там уже целый комикс с котом. И, конечно, Айс презентует много интересных статей! Кстати, еще один бонус — кот очень нравится клиентам и партнерам. Айс всегда вызывает улыбку, на сложных и серьезных встречах это плюс, обычно беседа после этого складывается лучше. Один раз я пошутила: «Ну что ж, коллеги, не будем тянуть нашего кота за хвост, мы уже готовы работать над вашей задачей». Можно сказать, что Айс помогает закрывать сделки! Так как в блоге сайта у нас получился целый комикс, то решили ввести еще одного персонажа – антагониста Айса. Его создание не заняло много времени: безумный взгляд, яркий цвет, хвост как провод и усы будто после удара током.Как ребрендинг повлиял на компанию и командуНа полный ребрендинг, создание маскота, переделку сайта у нас ушло 10 месяцев. Но потраченные усилия окупились. Во-первых, мы заметили, что нам самим стало проще строить коммуникацию с клиентами, не повторяя несколько раз: «БиПиСиЭй, пишется латинскими буквами, B как русская В…». Клиенты запоминают компанию быстрее, а недавно узнали, что между собой нас называют «коды». Во-вторых, фирменные презентации, дополнительные материалы, обновленный сайт — все это также влияет на общее впечатление. Мы получаем обратную связь и от партнеров, и от клиентов.В-третьих, вся эта работа запустила изменения и внутри компании. Мы выделили то направление, на которое делаем ставку, — интеграции с помощью шин данных. Сейчас Сергей проводит большой обзор российского рынка ESB. Уже вышел обзор «1С:Интеграция КОРП», сравнение «1С:Шины» и DATAREON Platform. На очереди «Интегра», Factor ESB, Entaxy и другие. Среди коллег я тоже провела опрос, чтобы понять, насколько для них эти изменения важны. Результаты на графике. 95% команды поддержало новое название, при этом то, как компания себя позиционирует, важно для половины сотрудников.После полного внешнего преображения компании, смены позиционирования и ниши к нам стали приходить другие клиенты: новые сферы, бóльшие обороты. Команда тоже растет. И я считаю, что это отличный результат. Конечно, был не только ребрендинг, но и большая внутренняя работа, поиски, изменения. И все же название корабля, на котором отправляешься в дальнее плавание, тоже важно. Хотя, возможно, не все со мной согласятся. Можем обсудить в комментариях!",
    "Установка Linux на Android: новые горизонты для разработчиков и энтузиастов": "Полноценный Linux на Android? Почему бы и нетВ мире мобильных технологий грядет очередная революция, которая может изменить подход к разработке и использованию приложений для Android. Google работает над интеграцией полноценной среды Linux в мобильную ОС. Это может не только упростить процесс создания софта, но и потенциально трансформировать мобильные устройства в полноценные рабочие станции.Работает ли Linux на AndroidДо недавнего времени запуск Linux на устройствах с Android был сложной задачей, требующей определенных навыков и часто связанной с риском нарушения гарантии устройства. Разработчики были вынуждены использовать различные обходные пути, такие как получение рут-прав или установка сторонних сервисов, что не всегда обеспечивало стабильную и безопасную среду для работы.Несмотря на существование решений вроде Termux, которые предоставляли ограниченный доступ к Linux-подобной среде, полноценная интеграция Linux в Android оставалась недостижимой мечтой для многих профессионалов. Однако ситуация кардинально меняется благодаря новой инициативе Google.Приложение \"Терминал\" для AndroidСейчас Linux на Android запускается только в ограниченном режимеПрямо сейчас Google активно работает над созданием нового приложения под названием \"Терминал\", которое призвано изменить работу с Linux на устройствах Android. Его упоминание было обнаружено в репозитории Android Open Source Project, и, судя по представленному там описанию, оно будет использовать передовые технологии виртуализации для создания изолированной среды Debian Linux на Android-устройствах.Ключевые особенности \"Терминала\":Использование Android Virtualization Framework (AVF) для создания виртуальной машины Debian.Полная изоляция Linux-среды от основной системы Android, что обеспечивает высокий уровень безопасности.Интеграция непосредственно в настройки Android, что упрощает доступ и управление.Возможность изменения размера виртуального диска для гибкой настройки рабочего пространства.Функция пересылки портов для удобной работы с сетевыми приложениями.Инструменты для восстановления разделов, обеспечивающие надежность и отказоустойчивость.Преимущества для разработчиков и экосистемы AndroidИнтеграция Linux в Android открывает ряд существенных преимуществ для разработчиков и пользователей всей экосистемы в целом.Прежде всего, это возможность создания и тестирования приложений непосредственно на мобильных устройствах. Такой подход значительно ускоряет процесс разработки и повышает качество конечного продукта. Разработчики смогут в режиме реального времени видеть, как их программы работают на целевых устройствах, что позволит оперативно вносить необходимые изменения и оптимизации.Кроме того, доступ к мощным инструментам разработки, характерным для Linux-среды, прямо на мобильном устройстве устраняет необходимость постоянного переключения между рабочими станциями и тестовыми устройствами. Это не только повышает удобство работы, но и потенциально увеличивает производительность разработчиков. Они смогут использовать привычные инструменты командной строки, системы контроля версий и другие средства разработки в любом месте и в любое время.Улучшение процесса отладки приложений в реальных условиях мобильного устройства – еще одно значительное преимущество. Разработчики получат возможность выявлять и устранять проблемы на ранних стадиях разработки, что существенно сократит время от идеи до выпуска готового продукта. Это особенно важно при работе с приложениями, которые активно взаимодействуют с аппаратными компонентами устройства или требуют специфических условий эксплуатации.Наличие полноценной Linux-среды на Android-устройствах открывает путь к созданию более сложных и функциональных приложений. Разработчики смогут использовать возможности обеих операционных систем, создавая гибридные решения, которые объединяют лучшие аспекты Android и Linux. Это может привести к появлению нового класса мобильных приложений, обладающих функциональностью, ранее доступной только на настольных компьютерах.Когда выйдет Terminal для AndroidРазработка прямо на смартфоне тоже имеет смыслХотя Google еще не объявила официальную дату выпуска приложения \"Терминал\", анализ текущей активности в репозитории AOSP позволяет предположить, что эта функциональность может появиться уже в следующей крупной версии Android. Многие эксперты ожидают, что полноценная интеграция Linux в Android может стать одной из ключевых особенностей Android 16, выход которой предварительно намечен на следующий год.Перспективы этой технологии выходят далеко за рамки простого удобства для разработчиков. Интеграция Linux в Android может стать катализатором для целого ряда инноваций в мобильной индустрии.Во-первых, это может привести к появлению нового класса мобильных устройств, которые будут позиционироваться как полноценные рабочие станции. Представьте смартфон или планшет, который при подключении к внешнему монитору и клавиатуре превращается в полноценный Linux-компьютер. Это может существенно изменить подход к мобильным офисам и удаленной работе, позволяя пользователям носить с собой полноценное рабочее окружение в кармане.Во-вторых, интеграция Linux может стать мощным стимулом для развития образовательных программ в области информационных технологий. Студенты и начинающие разработчики получат доступ к профессиональным инструментам разработки прямо на своих мобильных устройствах, что сделает обучение программированию более доступным и удобным.Кроме того, это открывает новые возможности для исследований и разработок в области искусственного интеллекта и машинного обучения на мобильных платформах. Наличие полноценной Linux-среды позволит запускать сложные алгоритмы и модели непосредственно на устройствах, что может привести к появлению более продвинутых и персонализированных мобильных приложений с элементами ИИ.В целом, интеграция Linux в Android – это не просто технический проект, но и стратегический шаг Google в направлении унификации различных платформ. Это может рассматриваться как часть более широкой стратегии по сближению Android и Chrome OS, что в перспективе может привести к созданию единой универсальной платформы для мобильных и настольных устройств.",
    "Как закрыть критерий «Членство в ассоциации» IT-специалисту для визы таланта": "Рассказываю в шагах, как вступить в профильную ассоциацию и усилить кейс для визы. Также в конце оставила подборку, которой сама пользуюсь. Отрываю от сердца.У каждой страны свои требования и условия программы, но критерий публичности есть у всех: в консульстве смотрят на материалы, подтверждающие, что вы — эксперт в своей отрасли и как-то влияете на нее. Допустим, что вы активно публикуете авторские колонки в СМИ, даете интервью журналистам и записываете подкасты. Хорошим и необходимым дополнением к кейсу будет членство в ассоциации по вашему профилю. И не в ноунейм ассоциации, а известной и престижной. Вот несколько причин, почему офицерам нужно доказать, что вы состоите в ассоциации: 1. Подтверждение профессионального статуса. Ассоциации часто отбирают членов на основе заслуг или рекомендаций, а не только за счет оплаты взносов. Это указывает на признание ваших навыков и опыта.2. Активное участие в сообществе. Визовые программы для талантов ориентированы на специалистов, которые не только выполняют свою работу, но и вносят вклад в развитие отрасли. Членство в ассоциации показывает, что вы участвуете в жизни профессионального сообщества и открыты для обмена знаниями.3. Доступ к ресурсам и передовым практикам. Члены профессиональных ассоциаций имеют доступ к последним исследованиям, отчетам и передовому опыту, что дает им преимущество: виза талантов направлена на привлечение тех, кто идет в ногу с тенденциями и готов вносить новшества.4. Глобальное признание. Членство в международных ассоциациях — это свидетельство, что ваши достижения признаны не только в вашей стране, но и на глобальном уровне. Это особенно важно для спецов в сфере IT, где ценятся стандарты и признание на мировом уровне.Какие документы нужны для подтверждения членстваДля подачи на визу потребуется собрать набор документов. Вот что важно подготовить:Копию членской карты или распечатка из онлайн-базы данных, где указано ваше имя как члена ассоциации.Письмо от ассоциации, подписанное ее представителем, которое подтверждает ваше членство и его условия.Скриншоты с сайта ассоциации или публикации в СМИ, где указаны критерии отбора новых членов. Это подтверждает, что ваше членство не получено случайным образом, а признано на основе заслуг.Публикации в СМИ, которые подчеркивают значимость и влияние ассоциации на развитие отрасли. Например, статьи, где описывается роль организации в установлении стандартов или продвижении лучших практик.Дополнительные материалы: если на сайте ассоциации есть список известных членов или опубликованы примеры их деятельности, сделайте скриншоты и приложите их к своему кейсу.Эти документы помогают создать убедительный пакет, который подчеркивает ваши достижения и участие в профессиональной среде. И уделите внимание рекомендательному письму: президент ассоциации обычно пишет рекомендацию для совета, ее тоже нужно приложить к общему кейсу. Как организовать вступление в ассоциацию самостоятельноЕсли вы решили действовать самим, а не через агентство, то начните с этих шагов: Шаг 1. Поиск подходящих ассоциацийНачните в Google, используя запросы со словами «ассоциация», «союз», «гильдия» + ваша специальность (например, «ассоциация для разработчиков» или «гильдия IT-аудиторов»). Обратите внимание как на локальные, так и на международные организации, так как многие из них продолжают принимать членов независимо от гражданства.Неплохо с поиском справляется ChatGPT: на запрос «ассоциации для продакт-менеджеров» он выдал конкретный список.Не забывайте про LinkedIn. У многих профессиональных сообществ там есть страницы, а на них — контакты руководителей. Главное правило при вступлении: не стесняйтесь представлять свои достижения и «продавать» себя как специалиста.Наши клиенты не раз получали рекомендательные письма от лидеров крупных ассоциаций, просто вежливо попросив об этом спустя всего неделю после вступления.Шаг 2. Изучение требований к вступлениюНекоторые ассоциации принимают новых участников только на основе рекомендаций или за достижения в области IT, что будет полезно для вашего кейса. Убедитесь, что выбранная организация предоставляет сертификаты, подтверждающие ваше членство, и известна в профессиональном сообществе.Шаг 3. Подготовка и подача документовЗаполните заявку, оплатите членский взнос и соберите все подтверждающие документы: письма, сертификаты, копии членских карт. Эти материалы позже понадобятся для подачи на визу.Шаг 4. Взаимодействие с руководствомНе стесняйтесь обратиться к представителям ассоциации для получения рекомендаций или помощи. Если ваши достижения были отмечены в сообществе, вам будет легче запросить письмо, подтверждающее ваш профессиональный вклад и статус. Мы не раз обращались к членам ассоциации: отправляли досье кандидата и получали рекомендательные письма. Как выбрать подходящую ассоциациюСамое главное — выбрать подходящую ассоциацию, которая котируется для визы и соответствует вашему профилю. А еще принимает участников не за деньги, а за достижения. Вам повезло, если вступите в эти. Особенно, если вы подаетесь на визу О-1 и EB-1: Association for Computing Machinery (ACM): одна из крупнейших ассоциаций в сфере вычислительных технологий и информатики.IEEE Computer Society: профессиональная организация для инженеров, разработчиков и специалистов в области IT и вычислительной техники.ISACA: международная организация для профессионалов в IT-аудите, управлении рисками и информационной безопасности.(ISC)²: организация, предоставляющая сертификацию и признание в области кибербезопасности.Также можно попробовать в другие: мы собрали подборку ассоциаций для разных IT-спецов как российские, так и зарубежные. Российские ассоциации в IT  Общие:РАЭК: https://raec.ru/ Ассоциация разработчиков программного обеспечения: https://arppsoft.ru/ Ассоциация руководителей служб информационной безопасности: https://aciso.ru/ Ассоциация профессионалов управления бизнес-процессами: https://abpmp.org.ru/ Российский союз IТ-директоров: https://rucio.ru/ Ассоциация дополненной и виртуальной реальности: https://ar-vr.org/ Ассоциация интернет-разработчиков: http://www.internet-association.ru/ Ассоциация участников отрасли центров обработки данных: https://dcunion.ru/ Ассоциация российских разработчиков и производителей электроники: https://arpe.ru/ Ассоциация интернета вещей: https://www.iotas.ru/ Для продакт- и проджект-менеджеров:Russian Project Management Association (СОВНЕТ): https://www.sovnet.ru Ассоциация Менеджеров России (АМР): https://amr.ru ProductCamp Russia https://productcamp.ru Проектный Альянс: https://pmalliance.ru PRODUCT SENSE: https://productsense.io/about  Для бэкенд- и фронтенд-разработчиков: HTML Academy: https://htmlacademy.ru PiterJS и MoscowJS: https://piterjs.org PiterPy и MoscowPython https://piterpy.comДля аналитиков: Data Science Society Russia: https://ods.ai Ассоциация Больших Данных: https://rubda.ru 3 XXXIII Ежегодное собрание Ассоциации «Аналитика»: https://aac-analitica.ru/xxxiii-ezhegodnoe-sobranie-assocziaczii-analitika.html Зарубежные ассоциации в IT Для продакт- и проджект-менеджеров:Product Management Institute (PMI): https://www.pmi.org/disciplined-agile/process/product-management Mind the Product: https://www.mindtheproduct.com Product School: https://productschool.com/training-for-teams Association of International Product Marketing and Management (AIPMM): https://aipmm.com Project Management Institute (PMI): https://www.pmi.org Для бэкенд- и фронтенд-разработчиков: he Front-End Developer Handbook by Frontend Masters: https://frontendmasters.com/blog/front-end-developer-handbook-2024/ Smashing Magazine Community: https://www.smashingmagazine.com/category/community/ Front-End Developers Slack: https://slofile.com/slack/frontenddevelopersBackend Development Community на Reddit: https://www.reddit.com/r/java/comments/pnkilt/backend_dev_communities/?rdt=43850 Backend Developer Meetups: https://www.meetup.com/topics/backend/ Backendless: https://backendless.com  Для аналитиков: https://odsc.com Data Science Society: https://odsc.com Association for Computing Machinery (ACM) — Special Interest Group on Knowledge Discovery and Data Mining (SIGKDD): https://www.acm.org/special-interest-groups/sigs/sigkdd  American Statistical Association (ASA): https://www.amstat.orgЕще бонусом: если вы тим-лид или у вас есть собственный проект, то можете рассмотреть эти. Они хорошо дополнят предыдущий список:Ассоциация независимых директоров: https://andirector.com/ Национальная ассоциация корпоративных директоров: https://corpdir.ru/ Ассоциация директоров по развитию: https://chiefstrategyofficer.ru/ Российская ассоциация специалистов по управлению проектами: https://www.sovnet.ru/ Ассоциация специалистов по стратегическому управлению: https://strategs.ru/ Сохраняйте подборку, чтобы не потерять. Если у вас остались вопросы, то можете задать в комментариях. Постараюсь помочь.",
    "Чтение на выходные: «Invent and Wander. Избранные статьи создателя Amazon Джеффа Безоса» Уолтера Айзексона": "Сборник лучших речей Джеффа Безоса под редакцией Уолтера Айзексона в рубрике. Бинго по качеству чтения, потому что обе персоны интересны сами по себе: Джефф — как предприниматель и личность, Уолтер — как биограф, книги которого никогда не бывает скучно читать.К слову о последнем, мы уже рекомендовали к прочтению на Хабре другие его работы: новинку про Илона Маска, бестселлер про Стива Джобса и уникальную по своему содержанию историю «гениев, хакеров и гиков совершили цифровую революцию». Если вы хотели выбрать себе книгу на ближайшее время и гарантированно получить удовольствие от изучения той или иной темы — смело выбирайте что-нибудь из списка.Книгу о Джеффе Безосе удобно читать фрагментами и в любом порядке глав. Единственное, что стоит сделать сразу и наверняка — уделить внимание введению от редактора. В авторском стиле Уолтер Айзексон раскрывает ключевые моменты биографии создателя Amazon — с теплотой и юмором. Некоторые из фактов встретятся в книге и позже — в других главах, где повествование идёт от лица Безоса.Главная мысль книги — о стремлении к инновациям и служении обществу. На примерах своих компаний Джефф показывает как важно создавать новое — то, что будет кардинально отличаться от уже существующих услуг, продуктов или возможностей. Процитируем: «Мы очень интересовались физическими магазинами в течение многих лет, но я всегда говорил, что нам хотелось бы иметь дифференцированное предложение, а не “у нас тоже”, потому что физические магазины сами прекрасно обслуживают покупателей. Если бы мы предложили продукт из серии “у нас тоже”, такое предложение не сработало. Наша культура гораздо лучше ориентируется в новаторстве и изобретательстве, и поэтому мы должны предложить нечто другое. Таким проектом стал Amazon Go. Это совсем другое».Что касается людей и общества, то здесь стоит отметить направленность Amazon на клиента и цель «быть самой клиентоориентированной компанией на Земле». Сосредоточенность на покупателях и их потребностях — то, что отличало бизнес Джеффа с самого начала, даже еще когда рабочее пространство располагалось в гараже арендованного дома в Сиэтле. И здесь же можно далеко не ходить от планеты Земля — на космические разработки Blue Origin также возложена гуманистическая миссия:  «Наша задача – проложить дорогу в космос, чтобы будущие поколения могли раскрыть свой творческий потенциал. Когда это станет возможным, когда для будущих космических предпринимателей будет создана необходимая инфраструктура, как для меня в 1994 году, когда я основал Amazon, вы увидите, что возможными станут удивительные вещи. Все случится быстро, я гарантирую. Люди становятся такими творческими, когда их ничто не ограничивает. Если нынешнее поколение построит дорогу в космос, создаст нужную инфраструктуру, то мы увидим тысячи будущих предпринимателей, строящих настоящую космическую индустрию, и я хочу вдохновить их. Видение кажется грандиозным, и так оно и есть. Да, начать нелегко и даже трудно, но я хочу вдохновить вас. Так что подумайте вот о чем: большие вещи начинаются с малого». Разумеется, говоря о бизнесе, можно сколько угодно рассуждать о финансах и выгодах, но в случае с харизматичным и прожженым предпринимателем Джеффом Безосом к словам прислушаться точно стоит.Обратим внимание на структуру книги: в ней есть введение от Уолтера Айзексона, первая «бизнесовая» часть, которая состоит из посланий акционерам, и вторая — про жизнь и работу. которая состоит из фрагментов выступлений и интервью. Редактор мастерски отобрал статьи на тему целеполагания, корпоративной культуры, бизнеса, изобретательства, талантов. Такое чтение знакомит с Джеффом Безосом и помогает узнать о нем много интересного, а ещё почерпнуть лайфхаки для своего дела или личной рутины. Если вы не следили за биографией техногиганта ранее, то провести выходные с книгой — отличный способ сложить представление об этом громко смеющемся и всемирно известном парне. Кстати, про смех тоже есть в книге.Хронология статей тянется от 1997 до 2019 года. Читателям может быть любопытно сравнить речи из разных эпох, которые пронизаны общей идеей. Возможно, в этом и секрет успеха Джеффа Безоса, который однажды решил играть вдолгую. Познакомьтесь с мыслями Безоса, чтобы вдохновиться или, наоборот, снять розовые очки: в книге есть и развеивания мифов.Бесплатный поиск, мониторинг и регистрация товарных знаков  и других объектов интеллектуальной собственности.Больше контента о сфере интеллектуальной собственности в нашем Telegram-канале",
    "Битва титанов: натив, кроссплатформа и PWA – ищем плюсы и минусы на каждом этапе разработки": "Привет, Хабр. Мы уже сравнивали натив и PWA в этой статье, но без кроссплатформы эта картина действительно была неполной. Поэтому мы запарились, разложили разработку на этапы и на каждом нашли честные плюсы и минусы каждой технологии. Погнали.Дисклеймер о кроссплатформеРазнообразие фреймворков чуть было не заставило нас проводить еще одно сравнение внутри сравнения. Поэтому мы оттолкнулись от двух: ReactNative (все-таки близок к вебу) и Flutter (кажется наиболее популярным в нашем инфополе). Итак, Flutter будет фигурировать в этом сравнении как наиболее релевантный по мнению команды, которая взялась проводить это исследование.  Дисклеймер о PWAМы в Clevertec работаем с финтехом, в том числе создаем банковские приложения: веб и нативные. В последние годы в нашей геозоне PWA стали мастхэвом для банков, которые столкнулись с проблемами в сторах. Мы сами разработали несколько PWA для банков, поэтому все аргументы добыты на практике.Идея и сбор требований  Здесь ничем не удивим, но первый этап разработке нельзя скипнуть. Трудозатраты здесь одинаковы для всех технологий. Отличия, обусловленные спецификой платформы, обычно несущественны в масштабах основной функциональности.  Сбор командыНатив. Пока выглядит так: нужны две команды, Android и iOS. Но Huawei, Xiaomi собираются создавать свои платформы и в обозримом будущем для таких случаев может понадобиться или больше команд, или дополнительные усилия со стороны одной из существующих, чтобы адаптировать приложение под новые потребности. Значит, и затраты будут возрастать. Это нужно учитывать.Flutter. Команда разработки одна, но нужно учитывать, что это специалисты с Dart. Найти их оказалось сложнее, чем мы предполагали. В подтверждение собрали информацию на HH.RU о количестве разработчиков на рынке и средних зарплатах. Доступных спецов по Flutter в десятки раз меньше, и стоить они могут дороже остальных.Кстати, с кроссплатформой на ReactNative будет проще: фреймворк похож на React, затраты на переобучение веб-разработчиков небольшие, даже если специфических специалистов нет.   PWA. Нужна одна команда веб-разработчиков. Причем независимо от фреймворка. Прогрессивное веб-приложение можно строить на любом. Поэтому такую команду собрать проще и она с большой вероятностью обойдется дешевле, чем Flutter.  Проектирование интерфейса  Натив должен учитывать гайдлайны платформы, и по-другому приложение не пропустят маркеты. То есть сама архитектура натива определяет интерфейс.В то же время нативные приложения самые быстрые. Кроссплатформа и PWA в этом плане проще. Интерфейс проектируется один раз. И если Flutter все же должен учитывать особенности нативных платформ, то в вебе все компоненты общие.Вместе с тем все не нативное – это выбор между упрощением кода и сохранением всех фишек пользовательского опыта. Что делать, например, с разницей жестов “домой” и “назад”, которые понятны пользователям Android и iOS?Тренд на унификацию пользовательского опыта уже заметен у гигантов. Мобайл и десктоп, натив и PWA уже сейчас вообще не отличимы, например у Вк, Х (экс Twitter). Разработка  Натив. Все объективно сложнее, чем у остальных: две разные кодовые базы, разные системы непрерывной интеграции из-за разных пайплайнов сборки, разные процессы публикации в маркетах. Но жирный плюс: максимум возможностей использовать аппаратные фичи устройств.Кроссплатформа. Разработка намного проще, один код, общий пайплайн. Но уже меньше возможностей взаимодействовать с устройствами. Хотя и гораздо больший потенциал в этом, чем у PWA.PWA. Все так же проще кодовой базой, но еще меньше возможностей в работе с функциями устройств. Но нет и не будет в ближайшее время:фоновой работы (не получится воспроизводить медиа в фоне и отслеживать геолокацию, например)возможности создать виджеты на рабочем столеинтеграции с нативными базами смартфона (мультимедиа, контакты)Если примерить на наш опыт, то в банковских приложениях эти функции не критичны. А проблемы шеринга файлов и контактов, работы с камерой и другие успешно решаются с помощью Web API и хороших разработчиков. Статья об этом уже написана, загляните: Web APIs, которые функционально приближают веб-приложения к нативнымЕсть еще один вопрос – скорость разработки. Снова на практическом примере из финтеха.С PWA реально выйти в релиз за 3-4 месяца. За счет скорости сбора команды, меньших усилий на тестирование и без ожидания проверок в сторах. С нативными приложениями наш минимальный путь до релиза занимал 6 месяцев. Когда показатель time-to-market критически важен, это может стать сильным аргументом.Впереди этапы тестирования, обновления и поддержки и самое интересное – оценка стоимости. Об этом расскажем в следующей части уже скоро.Если ждать не хочется, мы собрали основные пункты сравнения на этой доске. Мы с командой потратили не один час на обсуждение этих сравнений и немало спорили. Если хочется поспорить с нами – ждем в комментариях, призовем коллективный разум для ответа.",
    "Новые схемы мошенников — теперь они используют ИИ": "Звонки из банка в прошлом. Мошенники теперь идут на более наглые действия — с помощью искусственного интеллекта. Разберёмся, как они используют нейросети и какие хитрости помогут распознать их уловки. Шантаж дипфейкомДипфейк (он же Deepfake) — это фейковый контент, который люди создают с помощью ИИ. Можно создать его с видео: например, скопировать лицо человека с фотографий в его соцсетях и обучить на них нейросеть. А затем от лица жертвы сгенерировать нецензурные или экстремистские действия. Или сделать фотоконтент неприемлемого характера.Обычно мошенники угрожают отправить родственникам, друзьям или полицейским эти материалы и взамен просят много денег. Чтобы этого не произошло с вами, предупредите близких о том, что такая технология очень популярна. И если вы окажетесь в чём-то замешаны, они должны связаться с вами и сразу проверить, правда это или нет. Ещё больше примеров мы приводили в одной из наших статей про дипфейки. Уже существуют приложения, в которых пользователь может раздеть на фото кого угодноКопирование голоса Раньше преступник звонил жертве от лица её родственника и говорил, что тот попал в ДТП. После чего просил срочно перевести деньги — на лечение или чтобы избежать уголовной ответственности. Заподозрить мошенничество было легко из-за другого голоса. Теперь же злоумышленники могут скопировать голос близкого и позвонить вам от его имени, чтобы вымогать деньги. Например, есть история, как другу написал его товарищ и попросил в долг большую сумму денег. Как он сказал, зарплату задержали, и ему не хватало на ежемесячный взнос по кредиту за автомобиль.Друг заподозрил что-то неладное, но мошенник прислал голосовое сообщение, в котором действительно был голос товарища, и сомнений уже не было. Деньги были переведены.Как уже потом выяснилось, товарищ летел из другого города, пока всё происходило. Но этого времени мошеннику хватило, чтобы развести людей. Придумайте кодовое слово для родственников на случай, если кто-то и им позвонит вашим голосом.Скрин из диалога друга с его «товарищем»Несуществующие товары на маркетплейсах С помощью нейросетей люди делают целые фотосессии для своих товаров, а затем оформляют как карточку товара и загружают на маркетплейсы. Многие продавцы так увлеклись, что сгенерировали фотографии несуществующих товаров, их названия и описания. Иногда в моду входят явно фальшивые товары — семена, из которых якобы вырастет цветок с изображением мордочки кота или цветок, похожий на птицу с ярким окрасом. Пример фейкового товара на маркетплейсеЗлоумышленники на Amazon частенько проворачивают такую схему. Но, видимо, настолько бестолково, что их выдает фраза в названиях карточки из ChatGPT: «Извините, но я не могу выполнить запрос. Он противоречит политике OpenAI».Сам Amazon утверждает, что проверяет продавцов и карточки, но гарантии не даёт никто. Продавец может принять у вас заказ, увести в мессенджер, получить деньги и затем со своего аккаунта отменить отправку товара. Так это проворачивают на Wildberries.Недавно российский маркетплейс заявил, что мошенники всё чаще создают фальшивые страницы, чтобы обмануть покупателей. После получения заказа они просят связаться через мессенджер и присылают ссылку для оплаты на сторонних платформах. После получения денег мошенники бесследно исчезают.Пример нового вида мошенничестваФейковая девушкаМошенники могут притворяться парнями или девушками с сайтов знакомств. Этот метод обмана давно всем известен, но сейчас его популярность опять растёт благодаря нейросети LoveGPT. Мошенник пересылает нейросети сообщения от жертвы, а в ответ получает кокетливые фразы от ИИ. Используя это, он втирается в доверие к человеку и выманивает у него важную информацию или деньги.Другой вариант — мошенник генерирует фотографию несуществующего человека, знакомится онлайн и назначает свидание. После просит купить билеты в кино, кидает ссылку на фишинговый сайт, а когда жертва переводит средства, исчезает. Поддельные документыНаверное, это самый наглый способ обмана. На сайте OnlyFake можно создавать фотографии документов: паспорта или водительских прав 26 стран мира. Достаточно лишь заполнить шаблон фотографией любого человека и его данными, а затем нейросеть всё обработает сама. Снимки получаются максимально достоверными и позволяют проходить проверки на криптобиржах. А стоит такая услуга $15, около 1300 ₽. Суть в том, что мошенники могут украсть чужие данные, взять фото из соцсетей для регистрации в онлайн-казино, сервисах для аренды автомобилей, оформления микрозаймов. А вы потом со скрипом будете доказывать свою невиновность. Пример поддельного документа. Мошенник добавляет личную информацию и фото в шаблонТеперь вы узнали все новые схемы мошенничества и готовы быть начеку. Делитесь статьёй с друзьями и близкими, чтобы и их предупредить об опасности. До скорых встреч!"
}